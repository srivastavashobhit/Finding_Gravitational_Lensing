{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71628a45-c630-41ca-9378-15e9fa4ffeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow-addons==0.17.1\n",
      "  Downloading tensorflow_addons-0.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 17.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow-addons==0.17.1) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /global/u2/l/lebrian/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages (from tensorflow-addons==0.17.1) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from packaging->tensorflow-addons==0.17.1) (3.0.9)\n",
      "Installing collected packages: tensorflow-addons\n",
      "  Attempting uninstall: tensorflow-addons\n",
      "    Found existing installation: tensorflow-addons 0.18.0\n",
      "    Uninstalling tensorflow-addons-0.18.0:\n",
      "      Successfully uninstalled tensorflow-addons-0.18.0\n",
      "Successfully installed tensorflow-addons-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-addons==0.17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1aeeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow==2.9.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (2.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (0.26.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (1.1.0)\n",
      "Requirement already satisfied: packaging in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (3.19.4)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (14.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (4.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (1.43.0)\n",
      "Requirement already satisfied: setuptools in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (61.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (1.22.4)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorflow==2.9.0) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.9.0) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2022.5.18.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from packaging->tensorflow==2.9.0) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60084de-8f07-4c6e-beb2-0ae555b769d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout, Activation, ReLU, Conv2D, Add, GlobalMaxPool2D, GlobalAveragePooling2D, MaxPool2D, Flatten, Softmax, Cropping2D, Lambda, BatchNormalization as BatchNorm, Reshape, LeakyReLU, Conv2DTranspose, PReLU, RandomZoom\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import sklearn.model_selection\n",
    "\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07ac360-2a41-4c39-b311-09ed8f91db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct  4 13:44:13 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:03:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    52W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:82:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  On   | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    51W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80e10a6-c622-49ff-a26b-00835f3e69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_unit1(inp, a, b, block_id, layer_id, activation=\"elu\",):\n",
    "    Nonlinearity = lambda name: Activation(activation=activation, name=name)\n",
    "\n",
    "    bn1 = BatchNorm(name=f\"{block_id}/{layer_id}/bn1\")(inp)\n",
    "    elu1 = Nonlinearity(name=f\"{block_id}/{layer_id}/activation1\")(bn1)\n",
    "    conv1 = Conv2D(filters=a, kernel_size=(1,1), name=f\"{block_id}/{layer_id}/conv1\")(elu1)\n",
    "\n",
    "    bn2 = BatchNorm(name=f\"{block_id}/{layer_id}/bn2\")(conv1)\n",
    "    elu2 = Nonlinearity(name=f\"{block_id}/{layer_id}/activation2\")(bn2)\n",
    "    conv2 = Conv2D(filters=a, kernel_size=(3,3), padding=\"same\", name=f\"{block_id}/{layer_id}/conv2\")(elu2)\n",
    "\n",
    "    bn3 = BatchNorm(name=f\"{block_id}/{layer_id}/bn3\")(conv2)\n",
    "    elu3 = Nonlinearity(name=f\"{block_id}/{layer_id}/activation3\")(bn3)\n",
    "    conv3 = Conv2D(filters=b, kernel_size=(1,1), name=f\"{block_id}/{layer_id}/conv3\")(elu3)\n",
    "\n",
    "    return Add(name=f\"{block_id}/{layer_id}/add\")([inp, conv3])\n",
    "\n",
    "def res_unit2(inp, a, b, block_id, layer_id, activation=\"elu\"):\n",
    "    Nonlinearity = lambda name: Activation(activation=activation, name=name)\n",
    "\n",
    "    bn = BatchNorm(name=f\"{block_id}/{layer_id}/bn0\")(inp)\n",
    "    elu = Nonlinearity(name=f\"{block_id}/{layer_id}/activation0\")(bn)\n",
    "\n",
    "    shortcut = Conv2D(filters=b, kernel_size=(1,1), strides=2, name=f\"{block_id}/{layer_id}/shortcut-conv\")(elu)\n",
    "\n",
    "    conv0 = Conv2D(filters=a, kernel_size=(1,1), strides=2, name=f\"{block_id}/{layer_id}/conv0\")(elu)\n",
    "\n",
    "    bn1 = BatchNorm(name=f\"{block_id}/{layer_id}/bn1\")(conv0)\n",
    "    elu1 = Nonlinearity(name=f\"{block_id}/{layer_id}/activation1\")(bn1)\n",
    "    conv1 = Conv2D(filters=a, kernel_size=(3,3), padding=\"same\", name=f\"{block_id}/{layer_id}/conv1\")(elu1)\n",
    "\n",
    "    bn2 = BatchNorm(name=f\"{block_id}/{layer_id}/bn2\")(conv1)\n",
    "    elu2 = Nonlinearity(name=f\"{block_id}/{layer_id}/activation2\")(bn2)\n",
    "    conv2 = Conv2D(filters=b, kernel_size=(1,1), name=f\"{block_id}/{layer_id}/conv2\")(elu2)\n",
    "\n",
    "    return Add(name=f\"{block_id}/{layer_id}/add\")([shortcut, conv2])\n",
    "\n",
    "def create_model(shape=(101,101,3), activation=\"elu\"):\n",
    "    img = Input(shape=shape, name=\"img\")\n",
    "    zoom = RandomZoom((-0.2, .2), (-0.2, .2))(img)\n",
    "    conv1 = Conv2D(filters=32, kernel_size=(7,7), name=\"0/0/conv\")(zoom)\n",
    "    elu1 = Activation(activation=activation, name=f\"0/0/activation\")(conv1)\n",
    "    bn1 = BatchNorm(name=\"0/0/bn\")(elu1)\n",
    "\n",
    "    layer1_1 = res_unit1(bn1, 16, 32, 1, 1, activation=activation)\n",
    "    layer1_2 = res_unit1(layer1_1, 16, 32, 1, 2, activation=activation)\n",
    "    layer1_3 = res_unit1(layer1_2, 16, 32, 1, 3, activation=activation)\n",
    "    shield1 = Conv2D(filters=32, kernel_size=(1,1), name=\"1/shield\")(layer1_3)\n",
    "\n",
    "    layer2_1 = res_unit2(shield1, 32, 64, 2, 1, activation=activation)\n",
    "    layer2_2 = res_unit1(layer2_1, 32, 64, 2, 2, activation=activation)\n",
    "    layer2_3 = res_unit1(layer2_2, 32, 64, 2, 3, activation=activation)\n",
    "    shield2 = Conv2D(filters=32, kernel_size=(1,1), name=\"2/shield\")(layer2_3)\n",
    "\n",
    "    layer3_1 = res_unit2(shield2, 32, 64, 3, 1, activation=activation)\n",
    "    layer3_2 = res_unit1(layer3_1, 32, 64, 3, 2, activation=activation)\n",
    "    layer3_3 = res_unit1(layer3_2, 32, 64, 3, 3, activation=activation)\n",
    "    shield3 = Conv2D(filters=32, kernel_size=(1,1), name=\"3/shield\")(layer3_3)\n",
    "\n",
    "    layer4_1 = res_unit2(shield3, 32, 64, 4, 1, activation=activation)\n",
    "    layer4_2 = res_unit1(layer4_1, 32, 64, 4, 2, activation=activation)\n",
    "    layer4_3 = res_unit1(layer4_2, 32, 64, 4, 3, activation=activation)\n",
    "    shield4 = Conv2D(filters=32, kernel_size=(1,1), name=\"4/shield\")(layer4_3)\n",
    "\n",
    "    layer5_1 = res_unit2(shield4, 32, 64, 5, 1, activation=activation)\n",
    "    layer5_2 = res_unit1(layer5_1, 32, 64, 5, 2, activation=activation)\n",
    "    layer5_3 = res_unit1(layer5_2, 32, 64, 5, 3, activation=activation)\n",
    "\n",
    "    average = GlobalAveragePooling2D()(layer5_3)\n",
    "    flatten = Flatten()(average)\n",
    "    out = Dense(1, activation=\"sigmoid\")(flatten)\n",
    "    return Model(inputs=[img], outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6170d47e-81e1-4837-9191-8493f56ce40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(lr0 = 5e-4):\n",
    "    metrics = tf.keras.metrics\n",
    "    model = create_model(activation = \"relu\")\n",
    "    m = [metrics.AUC(num_thresholds=500), metrics.Precision(), metrics.Recall()]\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr0),\n",
    "        metrics = m\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a1296c-9ee1-4d5c-b7c8-9958459f3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.load(\"/global/cfs/projectdirs/cosmo/work/users/xhuang/dataset/TS_33_set/TS33/data/train_x.npy\")\n",
    "ytrain = np.load(\"/global/cfs/projectdirs/cosmo/work/users/xhuang/dataset/TS_33_set/TS33/data/train_y.npy\").reshape(-1, 1)\n",
    "xval = np.load(\"/global/cfs/projectdirs/cosmo/work/users/xhuang/dataset/TS_33_set/TS33/data/val_x.npy\")\n",
    "yval = np.load(\"/global/cfs/projectdirs/cosmo/work/users/xhuang/dataset/TS_33_set/TS33/data/val_y.npy\").reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c02372d-7cbb-4261-86c4-b758fa82ec74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46582, 101, 101, 3), (46582, 1), (19963, 101, 101, 3), (19963, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape,ytrain.shape,xval.shape,yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe2b15f-e536-48ff-abe8-18fe21598b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 13:44:18.160918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-04 13:44:20.198852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38270 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2022-10-04 13:44:20.202055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38270 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2022-10-04 13:44:20.203322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38270 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:82:00.0, compute capability: 8.0\n",
      "2022-10-04 13:44:20.204591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38270 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops = tf.distribute.NcclAllReduce())\n",
    "lr0 = 5e-4\n",
    "with strategy.scope():\n",
    "    model = get_compiled_model(lr0 = lr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "752fd4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ff62536-78f8-49f2-bd64-e643121daec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_per_replica = 128\n",
    "bs = batch_size_per_replica * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6c6a034-c7c0-4b4a-8462-166d4d1f3767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    x = tf.image.random_flip_left_right(tf.image.random_flip_up_down(x))\n",
    "    #x = tf.keras.preprocessing.image.random_zoom(x, zoom_range = (0.2, 0.2), fill_mode = 'reflect')\n",
    "    \n",
    "    rg = tf.random.uniform(shape=[],minval=0, maxval=2 * np.pi, dtype=tf.float32)\n",
    "    x = tfa.image.rotate(x, angles=rg, fill_mode = 'reflect')\n",
    "    return x, y\n",
    "\n",
    "# Disable AutoShard.\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "\n",
    "train = (tf.data.Dataset.from_tensor_slices((xtrain, ytrain))\n",
    "        .shuffle(len(ytrain), reshuffle_each_iteration=True, seed=42) \n",
    "        .repeat()\n",
    "        .batch(bs)\n",
    "        .map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)).with_options(options)\n",
    "\n",
    "validate = (tf.data.Dataset.from_tensor_slices((xval, yval))\n",
    "        .shuffle(len(yval))\n",
    "        .repeat()\n",
    "        .batch(bs)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)).with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e198388a-b9d3-4a87-aa32-6d8ea5477b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_f(epoch):\n",
    "    if epoch < 80:\n",
    "        return lr0\n",
    "    else:\n",
    "        return lr0/5\n",
    "\n",
    "checkpoint = ModelCheckpoint('G:/Data/Model 1.h5', monitor='val_auc', save_best_only=True, mode='max', verbose=1)\n",
    "csv_logger = CSVLogger('G:/Data/Model 1.csv', separator=',', append=True)\n",
    "lr_schedule = LearningRateScheduler(lr_f, verbose=1)\n",
    "cbs = [checkpoint, csv_logger, lr_schedule]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39ef4f31-30ba-4413-b47b-8acb05eab5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5c3940b-b182-4e1f-b03f-aee4c188bc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 1/5\n",
      "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 13:45:04.134185: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8302\n",
      "2022-10-04 13:45:04.308802: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8302\n",
      "2022-10-04 13:45:04.423973: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8302\n",
      "2022-10-04 13:45:04.561282: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8302\n",
      "2022-10-04 13:45:07.997717: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - ETA: 0s - loss: 0.1570 - auc: 0.7265 - precision: 0.0278 - recall: 0.0088\n",
      "Epoch 1: val_auc improved from -inf to 0.65597, saving model to G:/Data/Model 1.h5\n",
      "90/90 [==============================] - 59s 194ms/step - loss: 0.1570 - auc: 0.7265 - precision: 0.0278 - recall: 0.0088 - val_loss: 0.1326 - val_auc: 0.6560 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 2/5\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0823 - auc: 0.9235 - precision: 0.6644 - recall: 0.2150\n",
      "Epoch 2: val_auc improved from 0.65597 to 0.83426, saving model to G:/Data/Model 1.h5\n",
      "90/90 [==============================] - 13s 143ms/step - loss: 0.0823 - auc: 0.9235 - precision: 0.6644 - recall: 0.2150 - val_loss: 0.1698 - val_auc: 0.8343 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 3/5\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0722 - auc: 0.9450 - precision: 0.6750 - recall: 0.3193\n",
      "Epoch 3: val_auc did not improve from 0.83426\n",
      "90/90 [==============================] - 12s 138ms/step - loss: 0.0722 - auc: 0.9450 - precision: 0.6750 - recall: 0.3193 - val_loss: 0.1422 - val_auc: 0.8098 - val_precision: 1.0000 - val_recall: 0.0017 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 4/5\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0633 - auc: 0.9586 - precision: 0.7294 - recall: 0.4214\n",
      "Epoch 4: val_auc improved from 0.83426 to 0.84018, saving model to G:/Data/Model 1.h5\n",
      "90/90 [==============================] - 13s 144ms/step - loss: 0.0633 - auc: 0.9586 - precision: 0.7294 - recall: 0.4214 - val_loss: 0.1318 - val_auc: 0.8402 - val_precision: 0.5604 - val_recall: 0.0887 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/5\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0563 - auc: 0.9693 - precision: 0.7455 - recall: 0.4842\n",
      "Epoch 5: val_auc did not improve from 0.84018\n",
      "90/90 [==============================] - 12s 138ms/step - loss: 0.0563 - auc: 0.9693 - precision: 0.7455 - recall: 0.4842 - val_loss: 0.1256 - val_auc: 0.8128 - val_precision: 0.2891 - val_recall: 0.0646 - lr: 5.0000e-04\n",
      "112.41503443708643\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start = time.perf_counter()\n",
    "\n",
    "model.fit(train, validation_data=validate, epochs=num_epochs, steps_per_epoch=len(ytrain)//bs, callbacks=cbs, verbose=1, batch_size=bs, validation_steps=len(yval)//bs)\n",
    "\n",
    "time_end = time.perf_counter()\n",
    "\n",
    "print(time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b108157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554d0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b49282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "389d753b-3681-4441-aab7-ce5c5359291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results = \"shielded_model_TS33_gelu.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91a17d6d-b8b0-4695-ab9f-9483fa6988be",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'shielded_model_TS33_gelu.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m largest \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m metric][:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))]\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m metric],label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'shielded_model_TS33_gelu.csv'"
     ]
    }
   ],
   "source": [
    "metric = \"_2\"\n",
    "df = pd.read_csv(path_results)\n",
    "largest = [max(df[\"val_auc\" + metric][:i+1]) for i in range(len(df))]\n",
    "plt.plot(df[\"auc\" + metric],label='train')\n",
    "plt.plot(df[\"val_auc\" + metric], label='val')\n",
    "plt.plot(largest, label='max')\n",
    "plt.legend()\n",
    "plt.ylim(0.95,1)\n",
    "plt.show()\n",
    "\n",
    "auc = max(df[\"val_auc\" + metric])\n",
    "print(f\"{auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e585fd6-3d53-4a60-8e3c-6b290c9b64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"val_loss\"])\n",
    "plt.plot(df[\"loss\"])\n",
    "plt.ylim(top=max(df[\"loss\"]), bottom=0)\n",
    "plt.show()\n",
    "val_loss = min(df[\"val_loss\"])\n",
    "print(f\"{val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
