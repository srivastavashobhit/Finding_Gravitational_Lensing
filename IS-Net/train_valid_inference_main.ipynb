{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309bb1fd-0bad-4621-bd31-b9726f8734f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "batch size:  8\n",
      "--- create training dataloader ---\n",
      "------------------------------ train --------------------------------\n",
      "--->>> train  dataset  0 / 1   GS-AMP-TR-1 <<<---\n",
      "-im- GS-AMP-TR-1 /global/cfs/projectdirs/cosmo/work/users/usf_cs690_2022_fall/galaxy_simulated/ArcAlwaysPresent/train/images :  7992\n",
      "-gt- GS-AMP-TR-1 /global/cfs/projectdirs/cosmo/work/users/usf_cs690_2022_fall/galaxy_simulated/ArcAlwaysPresent/train/arcs :  7992\n",
      "1  train dataloaders created\n",
      "--- create valid dataloader ---\n",
      "------------------------------ valid --------------------------------\n",
      "--->>> valid  dataset  0 / 1   GS-AMP-VD-1 <<<---\n",
      "-im- GS-AMP-VD-1 /global/cfs/projectdirs/cosmo/work/users/usf_cs690_2022_fall/galaxy_simulated/ArcAlwaysPresent/valid/images :  965\n",
      "-gt- GS-AMP-VD-1 /global/cfs/projectdirs/cosmo/work/users/usf_cs690_2022_fall/galaxy_simulated/ArcAlwaysPresent/valid/arcs :  965\n",
      "1  valid dataloaders created\n",
      "--- build model ---\n",
      "--- define optimizer ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/s/ssriv/.local/perlmutter/3.9-anaconda-2021.11/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>IS-Net-test - [epoch:   1/2000, batch:     8/ 7992, ite: 1] train loss: 4.153378, tar: 0.852210, time-per-iter: 5.251681 s, time_read: 0.136873\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    16/ 7992, ite: 2] train loss: 3.414789, tar: 0.731471, time-per-iter: 0.087694 s, time_read: 0.000999\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    24/ 7992, ite: 3] train loss: 2.926354, tar: 0.633531, time-per-iter: 0.084782 s, time_read: 0.002051\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    32/ 7992, ite: 4] train loss: 2.621691, tar: 0.560698, time-per-iter: 0.086556 s, time_read: 0.004227\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    40/ 7992, ite: 5] train loss: 2.391840, tar: 0.500335, time-per-iter: 0.081472 s, time_read: 0.000941\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    48/ 7992, ite: 6] train loss: 2.204189, tar: 0.449797, time-per-iter: 0.081639 s, time_read: 0.000794\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    56/ 7992, ite: 7] train loss: 2.058385, tar: 0.408321, time-per-iter: 0.083686 s, time_read: 0.002512\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    64/ 7992, ite: 8] train loss: 1.936068, tar: 0.374847, time-per-iter: 0.082763 s, time_read: 0.000859\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    72/ 7992, ite: 9] train loss: 1.842478, tar: 0.348379, time-per-iter: 0.082989 s, time_read: 0.000796\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    80/ 7992, ite: 10] train loss: 1.763554, tar: 0.326471, time-per-iter: 0.084510 s, time_read: 0.001773\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    88/ 7992, ite: 11] train loss: 1.698473, tar: 0.308737, time-per-iter: 0.083585 s, time_read: 0.001905\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:    96/ 7992, ite: 12] train loss: 1.635928, tar: 0.292018, time-per-iter: 0.083816 s, time_read: 0.001913\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   104/ 7992, ite: 13] train loss: 1.579978, tar: 0.278374, time-per-iter: 0.083972 s, time_read: 0.001649\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   112/ 7992, ite: 14] train loss: 1.533782, tar: 0.266634, time-per-iter: 0.083470 s, time_read: 0.001731\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   120/ 7992, ite: 15] train loss: 1.483769, tar: 0.254756, time-per-iter: 0.084009 s, time_read: 0.001882\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   128/ 7992, ite: 16] train loss: 1.441497, tar: 0.244779, time-per-iter: 0.084467 s, time_read: 0.001954\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   136/ 7992, ite: 17] train loss: 1.410272, tar: 0.236643, time-per-iter: 0.084434 s, time_read: 0.001763\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   144/ 7992, ite: 18] train loss: 1.375030, tar: 0.228753, time-per-iter: 0.083593 s, time_read: 0.001633\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   152/ 7992, ite: 19] train loss: 1.347802, tar: 0.221539, time-per-iter: 0.083123 s, time_read: 0.001733\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   160/ 7992, ite: 20] train loss: 1.326421, tar: 0.216389, time-per-iter: 0.083148 s, time_read: 0.001866\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   168/ 7992, ite: 21] train loss: 1.300257, tar: 0.210054, time-per-iter: 0.083719 s, time_read: 0.001660\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   176/ 7992, ite: 22] train loss: 1.279758, tar: 0.205227, time-per-iter: 0.083611 s, time_read: 0.001687\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   184/ 7992, ite: 23] train loss: 1.256584, tar: 0.199745, time-per-iter: 0.082751 s, time_read: 0.001993\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   192/ 7992, ite: 24] train loss: 1.233532, tar: 0.194176, time-per-iter: 0.082975 s, time_read: 0.001742\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   200/ 7992, ite: 25] train loss: 1.214521, tar: 0.189368, time-per-iter: 0.082958 s, time_read: 0.001638\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   208/ 7992, ite: 26] train loss: 1.195380, tar: 0.184497, time-per-iter: 0.083443 s, time_read: 0.001742\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   216/ 7992, ite: 27] train loss: 1.175982, tar: 0.179587, time-per-iter: 0.084166 s, time_read: 0.001814\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   224/ 7992, ite: 28] train loss: 1.157165, tar: 0.175135, time-per-iter: 0.083980 s, time_read: 0.001811\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   232/ 7992, ite: 29] train loss: 1.140786, tar: 0.170709, time-per-iter: 0.082616 s, time_read: 0.001663\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   240/ 7992, ite: 30] train loss: 1.127757, tar: 0.167752, time-per-iter: 0.082942 s, time_read: 0.001736\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   248/ 7992, ite: 31] train loss: 1.116547, tar: 0.165425, time-per-iter: 0.083336 s, time_read: 0.001797\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   256/ 7992, ite: 32] train loss: 1.106596, tar: 0.163636, time-per-iter: 0.084145 s, time_read: 0.002092\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   264/ 7992, ite: 33] train loss: 1.096531, tar: 0.161378, time-per-iter: 0.082073 s, time_read: 0.001844\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   272/ 7992, ite: 34] train loss: 1.085451, tar: 0.159268, time-per-iter: 0.083720 s, time_read: 0.001629\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   280/ 7992, ite: 35] train loss: 1.076307, tar: 0.157127, time-per-iter: 0.085446 s, time_read: 0.002387\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   288/ 7992, ite: 36] train loss: 1.067716, tar: 0.154979, time-per-iter: 0.083848 s, time_read: 0.001821\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   296/ 7992, ite: 37] train loss: 1.057428, tar: 0.152686, time-per-iter: 0.082941 s, time_read: 0.001605\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   304/ 7992, ite: 38] train loss: 1.048130, tar: 0.150296, time-per-iter: 0.082782 s, time_read: 0.001776\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   312/ 7992, ite: 39] train loss: 1.040437, tar: 0.148392, time-per-iter: 0.083187 s, time_read: 0.001798\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   320/ 7992, ite: 40] train loss: 1.034265, tar: 0.147028, time-per-iter: 0.084167 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   328/ 7992, ite: 41] train loss: 1.025106, tar: 0.144850, time-per-iter: 0.083120 s, time_read: 0.001809\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   336/ 7992, ite: 42] train loss: 1.016741, tar: 0.142817, time-per-iter: 0.082350 s, time_read: 0.001657\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   344/ 7992, ite: 43] train loss: 1.007503, tar: 0.140516, time-per-iter: 0.083557 s, time_read: 0.001804\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   352/ 7992, ite: 44] train loss: 1.001026, tar: 0.138965, time-per-iter: 0.083269 s, time_read: 0.001967\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   360/ 7992, ite: 45] train loss: 0.992494, tar: 0.136839, time-per-iter: 0.083032 s, time_read: 0.001720\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   368/ 7992, ite: 46] train loss: 0.983981, tar: 0.134719, time-per-iter: 0.083226 s, time_read: 0.001643\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   376/ 7992, ite: 47] train loss: 0.977130, tar: 0.133047, time-per-iter: 0.082280 s, time_read: 0.001863\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   384/ 7992, ite: 48] train loss: 0.969713, tar: 0.131269, time-per-iter: 0.082389 s, time_read: 0.001993\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   392/ 7992, ite: 49] train loss: 0.963888, tar: 0.129760, time-per-iter: 0.082914 s, time_read: 0.001656\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   400/ 7992, ite: 50] train loss: 0.957949, tar: 0.128164, time-per-iter: 0.082886 s, time_read: 0.001780\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   408/ 7992, ite: 51] train loss: 0.951080, tar: 0.126456, time-per-iter: 0.083568 s, time_read: 0.001869\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   416/ 7992, ite: 52] train loss: 0.945600, tar: 0.125168, time-per-iter: 0.084172 s, time_read: 0.001976\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   424/ 7992, ite: 53] train loss: 0.939673, tar: 0.123681, time-per-iter: 0.083503 s, time_read: 0.001803\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   432/ 7992, ite: 54] train loss: 0.934709, tar: 0.122537, time-per-iter: 0.083410 s, time_read: 0.001659\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   440/ 7992, ite: 55] train loss: 0.928981, tar: 0.121201, time-per-iter: 0.083094 s, time_read: 0.001845\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   448/ 7992, ite: 56] train loss: 0.924192, tar: 0.120036, time-per-iter: 0.084162 s, time_read: 0.001847\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   456/ 7992, ite: 57] train loss: 0.919315, tar: 0.119037, time-per-iter: 0.083404 s, time_read: 0.001730\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   464/ 7992, ite: 58] train loss: 0.914805, tar: 0.118056, time-per-iter: 0.085255 s, time_read: 0.001678\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   472/ 7992, ite: 59] train loss: 0.911305, tar: 0.117402, time-per-iter: 0.083796 s, time_read: 0.001895\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   480/ 7992, ite: 60] train loss: 0.906071, tar: 0.116126, time-per-iter: 0.083839 s, time_read: 0.001729\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   488/ 7992, ite: 61] train loss: 0.901727, tar: 0.115271, time-per-iter: 0.082463 s, time_read: 0.001643\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   496/ 7992, ite: 62] train loss: 0.896511, tar: 0.114094, time-per-iter: 0.082551 s, time_read: 0.001803\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   504/ 7992, ite: 63] train loss: 0.892839, tar: 0.113387, time-per-iter: 0.084934 s, time_read: 0.001968\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   512/ 7992, ite: 64] train loss: 0.888819, tar: 0.112578, time-per-iter: 0.083670 s, time_read: 0.001993\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   520/ 7992, ite: 65] train loss: 0.883866, tar: 0.111460, time-per-iter: 0.083254 s, time_read: 0.001781\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   528/ 7992, ite: 66] train loss: 0.880452, tar: 0.110687, time-per-iter: 0.083916 s, time_read: 0.001703\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   536/ 7992, ite: 67] train loss: 0.876181, tar: 0.109776, time-per-iter: 0.083912 s, time_read: 0.002012\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   544/ 7992, ite: 68] train loss: 0.872511, tar: 0.108988, time-per-iter: 0.083159 s, time_read: 0.002105\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   552/ 7992, ite: 69] train loss: 0.868448, tar: 0.108162, time-per-iter: 0.083506 s, time_read: 0.001697\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   560/ 7992, ite: 70] train loss: 0.865416, tar: 0.107395, time-per-iter: 0.083121 s, time_read: 0.001649\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   568/ 7992, ite: 71] train loss: 0.861375, tar: 0.106473, time-per-iter: 0.082525 s, time_read: 0.001861\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   576/ 7992, ite: 72] train loss: 0.859150, tar: 0.106215, time-per-iter: 0.082970 s, time_read: 0.001800\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   584/ 7992, ite: 73] train loss: 0.857829, tar: 0.105851, time-per-iter: 0.082285 s, time_read: 0.001707\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   592/ 7992, ite: 74] train loss: 0.854122, tar: 0.105073, time-per-iter: 0.083020 s, time_read: 0.001694\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   600/ 7992, ite: 75] train loss: 0.850938, tar: 0.104401, time-per-iter: 0.082696 s, time_read: 0.001806\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   608/ 7992, ite: 76] train loss: 0.847472, tar: 0.103649, time-per-iter: 0.083694 s, time_read: 0.001728\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   616/ 7992, ite: 77] train loss: 0.844240, tar: 0.102946, time-per-iter: 0.082915 s, time_read: 0.001802\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   624/ 7992, ite: 78] train loss: 0.840303, tar: 0.102162, time-per-iter: 0.083325 s, time_read: 0.001683\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   632/ 7992, ite: 79] train loss: 0.837285, tar: 0.101445, time-per-iter: 0.083247 s, time_read: 0.001777\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   640/ 7992, ite: 80] train loss: 0.836118, tar: 0.101135, time-per-iter: 0.082959 s, time_read: 0.002016\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   648/ 7992, ite: 81] train loss: 0.834125, tar: 0.100655, time-per-iter: 0.082434 s, time_read: 0.001802\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   656/ 7992, ite: 82] train loss: 0.831084, tar: 0.100021, time-per-iter: 0.082446 s, time_read: 0.001680\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   664/ 7992, ite: 83] train loss: 0.828183, tar: 0.099418, time-per-iter: 0.082801 s, time_read: 0.001845\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   672/ 7992, ite: 84] train loss: 0.825595, tar: 0.098889, time-per-iter: 0.083030 s, time_read: 0.001826\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   680/ 7992, ite: 85] train loss: 0.823424, tar: 0.098376, time-per-iter: 0.084468 s, time_read: 0.001685\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   688/ 7992, ite: 86] train loss: 0.821218, tar: 0.097914, time-per-iter: 0.081422 s, time_read: 0.001821\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   696/ 7992, ite: 87] train loss: 0.818380, tar: 0.097288, time-per-iter: 0.082778 s, time_read: 0.001705\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   704/ 7992, ite: 88] train loss: 0.816134, tar: 0.096789, time-per-iter: 0.083166 s, time_read: 0.001832\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   712/ 7992, ite: 89] train loss: 0.813711, tar: 0.096356, time-per-iter: 0.083426 s, time_read: 0.001833\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   720/ 7992, ite: 90] train loss: 0.810530, tar: 0.095618, time-per-iter: 0.083145 s, time_read: 0.001788\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   728/ 7992, ite: 91] train loss: 0.809442, tar: 0.095435, time-per-iter: 0.082765 s, time_read: 0.001867\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   736/ 7992, ite: 92] train loss: 0.808340, tar: 0.095294, time-per-iter: 0.082877 s, time_read: 0.001953\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   744/ 7992, ite: 93] train loss: 0.805894, tar: 0.094797, time-per-iter: 0.083186 s, time_read: 0.001790\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   752/ 7992, ite: 94] train loss: 0.803049, tar: 0.094225, time-per-iter: 0.083356 s, time_read: 0.001768\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   760/ 7992, ite: 95] train loss: 0.800264, tar: 0.093652, time-per-iter: 0.082695 s, time_read: 0.002020\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   768/ 7992, ite: 96] train loss: 0.797583, tar: 0.093115, time-per-iter: 0.080470 s, time_read: 0.001900\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   776/ 7992, ite: 97] train loss: 0.795345, tar: 0.092650, time-per-iter: 0.082719 s, time_read: 0.001752\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   784/ 7992, ite: 98] train loss: 0.793441, tar: 0.092350, time-per-iter: 0.082331 s, time_read: 0.001842\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   792/ 7992, ite: 99] train loss: 0.791130, tar: 0.091913, time-per-iter: 0.082204 s, time_read: 0.001742\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   800/ 7992, ite: 100] train loss: 0.788429, tar: 0.091366, time-per-iter: 0.082467 s, time_read: 0.001934\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   808/ 7992, ite: 101] train loss: 0.785642, tar: 0.090787, time-per-iter: 0.081402 s, time_read: 0.001807\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   816/ 7992, ite: 102] train loss: 0.783163, tar: 0.090254, time-per-iter: 0.082987 s, time_read: 0.001784\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   824/ 7992, ite: 103] train loss: 0.782906, tar: 0.090228, time-per-iter: 0.083726 s, time_read: 0.001832\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   832/ 7992, ite: 104] train loss: 0.780481, tar: 0.089724, time-per-iter: 0.085292 s, time_read: 0.001878\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   840/ 7992, ite: 105] train loss: 0.779562, tar: 0.089516, time-per-iter: 0.084312 s, time_read: 0.001825\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   848/ 7992, ite: 106] train loss: 0.777772, tar: 0.089193, time-per-iter: 0.084901 s, time_read: 0.001773\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   856/ 7992, ite: 107] train loss: 0.775641, tar: 0.088824, time-per-iter: 0.084389 s, time_read: 0.001889\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   864/ 7992, ite: 108] train loss: 0.773570, tar: 0.088498, time-per-iter: 0.083006 s, time_read: 0.001787\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   872/ 7992, ite: 109] train loss: 0.772146, tar: 0.088205, time-per-iter: 0.083663 s, time_read: 0.001742\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   880/ 7992, ite: 110] train loss: 0.770451, tar: 0.087894, time-per-iter: 0.081365 s, time_read: 0.001775\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   888/ 7992, ite: 111] train loss: 0.769241, tar: 0.087685, time-per-iter: 0.081673 s, time_read: 0.001675\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   896/ 7992, ite: 112] train loss: 0.766983, tar: 0.087216, time-per-iter: 0.082703 s, time_read: 0.001842\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   904/ 7992, ite: 113] train loss: 0.768032, tar: 0.087665, time-per-iter: 0.082314 s, time_read: 0.001775\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   912/ 7992, ite: 114] train loss: 0.766818, tar: 0.087460, time-per-iter: 0.082979 s, time_read: 0.001743\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   920/ 7992, ite: 115] train loss: 0.765811, tar: 0.087267, time-per-iter: 0.083073 s, time_read: 0.001729\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   928/ 7992, ite: 116] train loss: 0.764108, tar: 0.086926, time-per-iter: 0.082735 s, time_read: 0.001890\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   936/ 7992, ite: 117] train loss: 0.762239, tar: 0.086496, time-per-iter: 0.082263 s, time_read: 0.001655\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   944/ 7992, ite: 118] train loss: 0.760009, tar: 0.086028, time-per-iter: 0.083222 s, time_read: 0.001798\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   952/ 7992, ite: 119] train loss: 0.758272, tar: 0.085741, time-per-iter: 0.082822 s, time_read: 0.001838\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   960/ 7992, ite: 120] train loss: 0.756506, tar: 0.085389, time-per-iter: 0.083488 s, time_read: 0.001795\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   968/ 7992, ite: 121] train loss: 0.755039, tar: 0.085108, time-per-iter: 0.083108 s, time_read: 0.001749\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   976/ 7992, ite: 122] train loss: 0.753301, tar: 0.084761, time-per-iter: 0.083164 s, time_read: 0.001796\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   984/ 7992, ite: 123] train loss: 0.751292, tar: 0.084365, time-per-iter: 0.082443 s, time_read: 0.001865\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:   992/ 7992, ite: 124] train loss: 0.749520, tar: 0.084029, time-per-iter: 0.082496 s, time_read: 0.001803\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1000/ 7992, ite: 125] train loss: 0.749324, tar: 0.084049, time-per-iter: 0.082397 s, time_read: 0.001728\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1008/ 7992, ite: 126] train loss: 0.748660, tar: 0.083912, time-per-iter: 0.083890 s, time_read: 0.001926\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1016/ 7992, ite: 127] train loss: 0.747380, tar: 0.083669, time-per-iter: 0.083448 s, time_read: 0.001797\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1024/ 7992, ite: 128] train loss: 0.746312, tar: 0.083481, time-per-iter: 0.083659 s, time_read: 0.001793\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1032/ 7992, ite: 129] train loss: 0.745278, tar: 0.083273, time-per-iter: 0.082575 s, time_read: 0.001614\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1040/ 7992, ite: 130] train loss: 0.743887, tar: 0.082982, time-per-iter: 0.082375 s, time_read: 0.001604\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1048/ 7992, ite: 131] train loss: 0.742813, tar: 0.082747, time-per-iter: 0.082796 s, time_read: 0.001851\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1056/ 7992, ite: 132] train loss: 0.741011, tar: 0.082377, time-per-iter: 0.082926 s, time_read: 0.001674\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1064/ 7992, ite: 133] train loss: 0.739545, tar: 0.082149, time-per-iter: 0.083026 s, time_read: 0.001632\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1072/ 7992, ite: 134] train loss: 0.738622, tar: 0.082027, time-per-iter: 0.082936 s, time_read: 0.001778\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1080/ 7992, ite: 135] train loss: 0.738189, tar: 0.081899, time-per-iter: 0.082782 s, time_read: 0.001665\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1088/ 7992, ite: 136] train loss: 0.736848, tar: 0.081620, time-per-iter: 0.083860 s, time_read: 0.001842\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1096/ 7992, ite: 137] train loss: 0.735509, tar: 0.081405, time-per-iter: 0.082893 s, time_read: 0.001762\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1104/ 7992, ite: 138] train loss: 0.734442, tar: 0.081230, time-per-iter: 0.082682 s, time_read: 0.001703\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1112/ 7992, ite: 139] train loss: 0.733818, tar: 0.081131, time-per-iter: 0.082762 s, time_read: 0.001759\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1120/ 7992, ite: 140] train loss: 0.732553, tar: 0.080849, time-per-iter: 0.083575 s, time_read: 0.001862\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1128/ 7992, ite: 141] train loss: 0.731249, tar: 0.080614, time-per-iter: 0.083382 s, time_read: 0.001703\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1136/ 7992, ite: 142] train loss: 0.730656, tar: 0.080518, time-per-iter: 0.083090 s, time_read: 0.001633\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1144/ 7992, ite: 143] train loss: 0.729421, tar: 0.080265, time-per-iter: 0.082807 s, time_read: 0.001816\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1152/ 7992, ite: 144] train loss: 0.728189, tar: 0.080004, time-per-iter: 0.082723 s, time_read: 0.001946\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1160/ 7992, ite: 145] train loss: 0.726605, tar: 0.079649, time-per-iter: 0.083457 s, time_read: 0.001694\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1168/ 7992, ite: 146] train loss: 0.725004, tar: 0.079375, time-per-iter: 0.082838 s, time_read: 0.001705\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1176/ 7992, ite: 147] train loss: 0.723798, tar: 0.079117, time-per-iter: 0.084004 s, time_read: 0.002113\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1184/ 7992, ite: 148] train loss: 0.723156, tar: 0.078982, time-per-iter: 0.083328 s, time_read: 0.001920\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1192/ 7992, ite: 149] train loss: 0.722283, tar: 0.078815, time-per-iter: 0.082346 s, time_read: 0.001810\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1200/ 7992, ite: 150] train loss: 0.721565, tar: 0.078652, time-per-iter: 0.083897 s, time_read: 0.001665\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1208/ 7992, ite: 151] train loss: 0.720430, tar: 0.078454, time-per-iter: 0.084347 s, time_read: 0.002238\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1216/ 7992, ite: 152] train loss: 0.719371, tar: 0.078267, time-per-iter: 0.084031 s, time_read: 0.001869\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1224/ 7992, ite: 153] train loss: 0.718302, tar: 0.078043, time-per-iter: 0.082308 s, time_read: 0.001590\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1232/ 7992, ite: 154] train loss: 0.717269, tar: 0.077784, time-per-iter: 0.081948 s, time_read: 0.001662\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1240/ 7992, ite: 155] train loss: 0.716128, tar: 0.077544, time-per-iter: 0.082992 s, time_read: 0.001834\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1248/ 7992, ite: 156] train loss: 0.715456, tar: 0.077398, time-per-iter: 0.083230 s, time_read: 0.001768\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1256/ 7992, ite: 157] train loss: 0.714674, tar: 0.077167, time-per-iter: 0.083594 s, time_read: 0.001845\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1264/ 7992, ite: 158] train loss: 0.713458, tar: 0.076912, time-per-iter: 0.085489 s, time_read: 0.001874\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1272/ 7992, ite: 159] train loss: 0.712362, tar: 0.076660, time-per-iter: 0.084647 s, time_read: 0.001982\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1280/ 7992, ite: 160] train loss: 0.711374, tar: 0.076424, time-per-iter: 0.083898 s, time_read: 0.001842\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1288/ 7992, ite: 161] train loss: 0.710173, tar: 0.076150, time-per-iter: 0.084695 s, time_read: 0.001786\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1296/ 7992, ite: 162] train loss: 0.709325, tar: 0.075982, time-per-iter: 0.083285 s, time_read: 0.001784\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1304/ 7992, ite: 163] train loss: 0.708529, tar: 0.075808, time-per-iter: 0.084296 s, time_read: 0.001781\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1312/ 7992, ite: 164] train loss: 0.707403, tar: 0.075541, time-per-iter: 0.083055 s, time_read: 0.001832\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1320/ 7992, ite: 165] train loss: 0.706306, tar: 0.075281, time-per-iter: 0.083475 s, time_read: 0.001632\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1328/ 7992, ite: 166] train loss: 0.704945, tar: 0.074998, time-per-iter: 0.083407 s, time_read: 0.001677\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1336/ 7992, ite: 167] train loss: 0.704051, tar: 0.074835, time-per-iter: 0.083252 s, time_read: 0.001758\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1344/ 7992, ite: 168] train loss: 0.702688, tar: 0.074577, time-per-iter: 0.081743 s, time_read: 0.001801\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1352/ 7992, ite: 169] train loss: 0.701515, tar: 0.074352, time-per-iter: 0.083883 s, time_read: 0.001777\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1360/ 7992, ite: 170] train loss: 0.700315, tar: 0.074094, time-per-iter: 0.084355 s, time_read: 0.001653\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1368/ 7992, ite: 171] train loss: 0.699475, tar: 0.073954, time-per-iter: 0.084736 s, time_read: 0.002299\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1376/ 7992, ite: 172] train loss: 0.698375, tar: 0.073707, time-per-iter: 0.085718 s, time_read: 0.002323\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1384/ 7992, ite: 173] train loss: 0.697547, tar: 0.073619, time-per-iter: 0.084874 s, time_read: 0.001785\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1392/ 7992, ite: 174] train loss: 0.696492, tar: 0.073369, time-per-iter: 0.085689 s, time_read: 0.001715\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1400/ 7992, ite: 175] train loss: 0.695488, tar: 0.073160, time-per-iter: 0.084333 s, time_read: 0.002102\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1408/ 7992, ite: 176] train loss: 0.694254, tar: 0.072892, time-per-iter: 0.083572 s, time_read: 0.001975\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1416/ 7992, ite: 177] train loss: 0.693052, tar: 0.072648, time-per-iter: 0.084530 s, time_read: 0.001742\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1424/ 7992, ite: 178] train loss: 0.691890, tar: 0.072416, time-per-iter: 0.084906 s, time_read: 0.001785\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1432/ 7992, ite: 179] train loss: 0.690762, tar: 0.072184, time-per-iter: 0.084635 s, time_read: 0.001883\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1440/ 7992, ite: 180] train loss: 0.690275, tar: 0.072098, time-per-iter: 0.083629 s, time_read: 0.001967\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1448/ 7992, ite: 181] train loss: 0.689495, tar: 0.071942, time-per-iter: 0.084026 s, time_read: 0.001719\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1456/ 7992, ite: 182] train loss: 0.688672, tar: 0.071740, time-per-iter: 0.084856 s, time_read: 0.001656\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1464/ 7992, ite: 183] train loss: 0.687613, tar: 0.071499, time-per-iter: 0.084728 s, time_read: 0.001766\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1472/ 7992, ite: 184] train loss: 0.687118, tar: 0.071494, time-per-iter: 0.085143 s, time_read: 0.002089\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1480/ 7992, ite: 185] train loss: 0.686012, tar: 0.071282, time-per-iter: 0.083275 s, time_read: 0.001787\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1488/ 7992, ite: 186] train loss: 0.685077, tar: 0.071080, time-per-iter: 0.083813 s, time_read: 0.001760\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1496/ 7992, ite: 187] train loss: 0.684115, tar: 0.070861, time-per-iter: 0.085884 s, time_read: 0.002335\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1504/ 7992, ite: 188] train loss: 0.683030, tar: 0.070639, time-per-iter: 0.084396 s, time_read: 0.002141\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1512/ 7992, ite: 189] train loss: 0.682037, tar: 0.070424, time-per-iter: 0.084367 s, time_read: 0.001724\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1520/ 7992, ite: 190] train loss: 0.680947, tar: 0.070222, time-per-iter: 0.084232 s, time_read: 0.001644\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1528/ 7992, ite: 191] train loss: 0.680083, tar: 0.070044, time-per-iter: 0.083440 s, time_read: 0.001832\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1536/ 7992, ite: 192] train loss: 0.679121, tar: 0.069876, time-per-iter: 0.082933 s, time_read: 0.001806\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1544/ 7992, ite: 193] train loss: 0.677966, tar: 0.069677, time-per-iter: 0.083214 s, time_read: 0.001699\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1552/ 7992, ite: 194] train loss: 0.676963, tar: 0.069492, time-per-iter: 0.083154 s, time_read: 0.001812\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1560/ 7992, ite: 195] train loss: 0.675981, tar: 0.069289, time-per-iter: 0.085036 s, time_read: 0.001927\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1568/ 7992, ite: 196] train loss: 0.675078, tar: 0.069094, time-per-iter: 0.085021 s, time_read: 0.001825\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1576/ 7992, ite: 197] train loss: 0.674315, tar: 0.068957, time-per-iter: 0.083692 s, time_read: 0.001752\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1584/ 7992, ite: 198] train loss: 0.673579, tar: 0.068841, time-per-iter: 0.083187 s, time_read: 0.001696\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1592/ 7992, ite: 199] train loss: 0.672725, tar: 0.068648, time-per-iter: 0.083150 s, time_read: 0.001758\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1600/ 7992, ite: 200] train loss: 0.671935, tar: 0.068455, time-per-iter: 0.083881 s, time_read: 0.002079\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1608/ 7992, ite: 201] train loss: 0.672309, tar: 0.068485, time-per-iter: 0.082907 s, time_read: 0.001792\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1616/ 7992, ite: 202] train loss: 0.671477, tar: 0.068341, time-per-iter: 0.083959 s, time_read: 0.001645\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1624/ 7992, ite: 203] train loss: 0.670723, tar: 0.068181, time-per-iter: 0.083302 s, time_read: 0.001908\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1632/ 7992, ite: 204] train loss: 0.669888, tar: 0.068014, time-per-iter: 0.082663 s, time_read: 0.001745\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1640/ 7992, ite: 205] train loss: 0.669287, tar: 0.067888, time-per-iter: 0.083502 s, time_read: 0.001693\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1648/ 7992, ite: 206] train loss: 0.668805, tar: 0.067801, time-per-iter: 0.082472 s, time_read: 0.001821\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1656/ 7992, ite: 207] train loss: 0.667994, tar: 0.067677, time-per-iter: 0.083444 s, time_read: 0.001669\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1664/ 7992, ite: 208] train loss: 0.667016, tar: 0.067480, time-per-iter: 0.083773 s, time_read: 0.001805\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1672/ 7992, ite: 209] train loss: 0.666037, tar: 0.067278, time-per-iter: 0.083467 s, time_read: 0.001663\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1680/ 7992, ite: 210] train loss: 0.665401, tar: 0.067134, time-per-iter: 0.082900 s, time_read: 0.001688\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1688/ 7992, ite: 211] train loss: 0.664659, tar: 0.067002, time-per-iter: 0.082937 s, time_read: 0.001740\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1696/ 7992, ite: 212] train loss: 0.664183, tar: 0.066882, time-per-iter: 0.082960 s, time_read: 0.001949\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1704/ 7992, ite: 213] train loss: 0.663565, tar: 0.066787, time-per-iter: 0.082765 s, time_read: 0.001692\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1712/ 7992, ite: 214] train loss: 0.662865, tar: 0.066641, time-per-iter: 0.084009 s, time_read: 0.001641\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1720/ 7992, ite: 215] train loss: 0.662250, tar: 0.066487, time-per-iter: 0.083429 s, time_read: 0.001869\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1728/ 7992, ite: 216] train loss: 0.661431, tar: 0.066335, time-per-iter: 0.081267 s, time_read: 0.001776\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1736/ 7992, ite: 217] train loss: 0.660774, tar: 0.066211, time-per-iter: 0.081365 s, time_read: 0.001684\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1744/ 7992, ite: 218] train loss: 0.660093, tar: 0.066101, time-per-iter: 0.083336 s, time_read: 0.001875\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1752/ 7992, ite: 219] train loss: 0.659505, tar: 0.065985, time-per-iter: 0.084272 s, time_read: 0.001929\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1760/ 7992, ite: 220] train loss: 0.659012, tar: 0.065904, time-per-iter: 0.083237 s, time_read: 0.001767\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1768/ 7992, ite: 221] train loss: 0.658441, tar: 0.065774, time-per-iter: 0.082275 s, time_read: 0.001763\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1776/ 7992, ite: 222] train loss: 0.657779, tar: 0.065650, time-per-iter: 0.082125 s, time_read: 0.001607\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1784/ 7992, ite: 223] train loss: 0.657092, tar: 0.065525, time-per-iter: 0.082947 s, time_read: 0.001808\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1792/ 7992, ite: 224] train loss: 0.656720, tar: 0.065500, time-per-iter: 0.082953 s, time_read: 0.001836\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1800/ 7992, ite: 225] train loss: 0.656504, tar: 0.065504, time-per-iter: 0.081508 s, time_read: 0.001665\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1808/ 7992, ite: 226] train loss: 0.655652, tar: 0.065316, time-per-iter: 0.082649 s, time_read: 0.001678\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1816/ 7992, ite: 227] train loss: 0.655010, tar: 0.065201, time-per-iter: 0.083597 s, time_read: 0.001804\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1824/ 7992, ite: 228] train loss: 0.654193, tar: 0.065046, time-per-iter: 0.082572 s, time_read: 0.001764\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1832/ 7992, ite: 229] train loss: 0.653589, tar: 0.064938, time-per-iter: 0.083548 s, time_read: 0.001788\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1840/ 7992, ite: 230] train loss: 0.653550, tar: 0.064973, time-per-iter: 0.083081 s, time_read: 0.001839\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1848/ 7992, ite: 231] train loss: 0.653131, tar: 0.064890, time-per-iter: 0.082906 s, time_read: 0.001711\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1856/ 7992, ite: 232] train loss: 0.652462, tar: 0.064745, time-per-iter: 0.084445 s, time_read: 0.001779\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1864/ 7992, ite: 233] train loss: 0.651863, tar: 0.064637, time-per-iter: 0.082839 s, time_read: 0.001766\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1872/ 7992, ite: 234] train loss: 0.651326, tar: 0.064564, time-per-iter: 0.082711 s, time_read: 0.001817\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1880/ 7992, ite: 235] train loss: 0.651075, tar: 0.064498, time-per-iter: 0.082360 s, time_read: 0.001744\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1888/ 7992, ite: 236] train loss: 0.650565, tar: 0.064358, time-per-iter: 0.082219 s, time_read: 0.001868\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1896/ 7992, ite: 237] train loss: 0.650151, tar: 0.064256, time-per-iter: 0.083726 s, time_read: 0.001812\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1904/ 7992, ite: 238] train loss: 0.649707, tar: 0.064188, time-per-iter: 0.083156 s, time_read: 0.001746\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1912/ 7992, ite: 239] train loss: 0.649108, tar: 0.064047, time-per-iter: 0.082373 s, time_read: 0.001874\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1920/ 7992, ite: 240] train loss: 0.648507, tar: 0.063922, time-per-iter: 0.081746 s, time_read: 0.001817\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1928/ 7992, ite: 241] train loss: 0.648215, tar: 0.063856, time-per-iter: 0.083685 s, time_read: 0.001761\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1936/ 7992, ite: 242] train loss: 0.648269, tar: 0.063949, time-per-iter: 0.084050 s, time_read: 0.001760\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1944/ 7992, ite: 243] train loss: 0.647541, tar: 0.063793, time-per-iter: 0.083402 s, time_read: 0.001818\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1952/ 7992, ite: 244] train loss: 0.647132, tar: 0.063748, time-per-iter: 0.082454 s, time_read: 0.001753\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1960/ 7992, ite: 245] train loss: 0.646538, tar: 0.063632, time-per-iter: 0.082986 s, time_read: 0.001726\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1968/ 7992, ite: 246] train loss: 0.646024, tar: 0.063553, time-per-iter: 0.083628 s, time_read: 0.001811\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1976/ 7992, ite: 247] train loss: 0.645720, tar: 0.063510, time-per-iter: 0.083608 s, time_read: 0.001783\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1984/ 7992, ite: 248] train loss: 0.645342, tar: 0.063430, time-per-iter: 0.082678 s, time_read: 0.001953\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  1992/ 7992, ite: 249] train loss: 0.644615, tar: 0.063299, time-per-iter: 0.083524 s, time_read: 0.001621\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2000/ 7992, ite: 250] train loss: 0.643985, tar: 0.063173, time-per-iter: 0.083968 s, time_read: 0.001759\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2008/ 7992, ite: 251] train loss: 0.643843, tar: 0.063150, time-per-iter: 0.086090 s, time_read: 0.001756\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2016/ 7992, ite: 252] train loss: 0.643279, tar: 0.063034, time-per-iter: 0.084842 s, time_read: 0.002110\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2024/ 7992, ite: 253] train loss: 0.642857, tar: 0.062931, time-per-iter: 0.084854 s, time_read: 0.001806\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2032/ 7992, ite: 254] train loss: 0.642482, tar: 0.062864, time-per-iter: 0.085106 s, time_read: 0.001810\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2040/ 7992, ite: 255] train loss: 0.641876, tar: 0.062744, time-per-iter: 0.084065 s, time_read: 0.002039\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2048/ 7992, ite: 256] train loss: 0.641343, tar: 0.062612, time-per-iter: 0.084344 s, time_read: 0.001841\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2056/ 7992, ite: 257] train loss: 0.641103, tar: 0.062556, time-per-iter: 0.084014 s, time_read: 0.001873\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2064/ 7992, ite: 258] train loss: 0.640468, tar: 0.062430, time-per-iter: 0.083676 s, time_read: 0.001677\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2072/ 7992, ite: 259] train loss: 0.639809, tar: 0.062300, time-per-iter: 0.084123 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2080/ 7992, ite: 260] train loss: 0.639310, tar: 0.062200, time-per-iter: 0.084605 s, time_read: 0.002128\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2088/ 7992, ite: 261] train loss: 0.638641, tar: 0.062058, time-per-iter: 0.083528 s, time_read: 0.001678\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2096/ 7992, ite: 262] train loss: 0.638026, tar: 0.061929, time-per-iter: 0.083987 s, time_read: 0.001667\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2104/ 7992, ite: 263] train loss: 0.637836, tar: 0.061889, time-per-iter: 0.083885 s, time_read: 0.002001\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2112/ 7992, ite: 264] train loss: 0.637250, tar: 0.061759, time-per-iter: 0.083160 s, time_read: 0.001871\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2120/ 7992, ite: 265] train loss: 0.636660, tar: 0.061653, time-per-iter: 0.083044 s, time_read: 0.001634\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2128/ 7992, ite: 266] train loss: 0.636023, tar: 0.061499, time-per-iter: 0.083538 s, time_read: 0.001677\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2136/ 7992, ite: 267] train loss: 0.635978, tar: 0.061487, time-per-iter: 0.083755 s, time_read: 0.001826\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2144/ 7992, ite: 268] train loss: 0.635573, tar: 0.061386, time-per-iter: 0.083845 s, time_read: 0.001858\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2152/ 7992, ite: 269] train loss: 0.634917, tar: 0.061239, time-per-iter: 0.081876 s, time_read: 0.001738\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2160/ 7992, ite: 270] train loss: 0.634287, tar: 0.061125, time-per-iter: 0.083336 s, time_read: 0.001675\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2168/ 7992, ite: 271] train loss: 0.633716, tar: 0.060996, time-per-iter: 0.082843 s, time_read: 0.001797\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2176/ 7992, ite: 272] train loss: 0.633169, tar: 0.060872, time-per-iter: 0.082616 s, time_read: 0.001892\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2184/ 7992, ite: 273] train loss: 0.632775, tar: 0.060780, time-per-iter: 0.082749 s, time_read: 0.001704\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2192/ 7992, ite: 274] train loss: 0.632131, tar: 0.060670, time-per-iter: 0.083582 s, time_read: 0.001644\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2200/ 7992, ite: 275] train loss: 0.631681, tar: 0.060572, time-per-iter: 0.083532 s, time_read: 0.001780\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2208/ 7992, ite: 276] train loss: 0.631187, tar: 0.060463, time-per-iter: 0.083880 s, time_read: 0.001837\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2216/ 7992, ite: 277] train loss: 0.630731, tar: 0.060341, time-per-iter: 0.084494 s, time_read: 0.001728\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2224/ 7992, ite: 278] train loss: 0.630550, tar: 0.060291, time-per-iter: 0.084043 s, time_read: 0.001734\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2232/ 7992, ite: 279] train loss: 0.630011, tar: 0.060173, time-per-iter: 0.083342 s, time_read: 0.001765\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2240/ 7992, ite: 280] train loss: 0.629711, tar: 0.060126, time-per-iter: 0.083490 s, time_read: 0.001812\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2248/ 7992, ite: 281] train loss: 0.629482, tar: 0.060091, time-per-iter: 0.083473 s, time_read: 0.002015\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2256/ 7992, ite: 282] train loss: 0.628907, tar: 0.059966, time-per-iter: 0.082572 s, time_read: 0.001795\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2264/ 7992, ite: 283] train loss: 0.628719, tar: 0.059905, time-per-iter: 0.082825 s, time_read: 0.001736\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2272/ 7992, ite: 284] train loss: 0.628409, tar: 0.059823, time-per-iter: 0.082647 s, time_read: 0.001870\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2280/ 7992, ite: 285] train loss: 0.627982, tar: 0.059757, time-per-iter: 0.082738 s, time_read: 0.001723\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2288/ 7992, ite: 286] train loss: 0.627754, tar: 0.059714, time-per-iter: 0.083135 s, time_read: 0.001677\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2296/ 7992, ite: 287] train loss: 0.627352, tar: 0.059648, time-per-iter: 0.082320 s, time_read: 0.001895\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2304/ 7992, ite: 288] train loss: 0.626714, tar: 0.059523, time-per-iter: 0.081728 s, time_read: 0.001815\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2312/ 7992, ite: 289] train loss: 0.626155, tar: 0.059396, time-per-iter: 0.082933 s, time_read: 0.001781\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2320/ 7992, ite: 290] train loss: 0.625596, tar: 0.059278, time-per-iter: 0.083333 s, time_read: 0.001649\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2328/ 7992, ite: 291] train loss: 0.625130, tar: 0.059224, time-per-iter: 0.082154 s, time_read: 0.001750\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2336/ 7992, ite: 292] train loss: 0.624614, tar: 0.059101, time-per-iter: 0.083533 s, time_read: 0.001803\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2344/ 7992, ite: 293] train loss: 0.624330, tar: 0.059056, time-per-iter: 0.083320 s, time_read: 0.001799\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2352/ 7992, ite: 294] train loss: 0.623828, tar: 0.058955, time-per-iter: 0.083915 s, time_read: 0.001750\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2360/ 7992, ite: 295] train loss: 0.623290, tar: 0.058860, time-per-iter: 0.085617 s, time_read: 0.001819\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2368/ 7992, ite: 296] train loss: 0.622780, tar: 0.058756, time-per-iter: 0.083505 s, time_read: 0.002090\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2376/ 7992, ite: 297] train loss: 0.622243, tar: 0.058646, time-per-iter: 0.082628 s, time_read: 0.001756\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2384/ 7992, ite: 298] train loss: 0.621713, tar: 0.058534, time-per-iter: 0.083584 s, time_read: 0.001704\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2392/ 7992, ite: 299] train loss: 0.621416, tar: 0.058481, time-per-iter: 0.083581 s, time_read: 0.001811\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2400/ 7992, ite: 300] train loss: 0.621014, tar: 0.058402, time-per-iter: 0.082843 s, time_read: 0.001886\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2408/ 7992, ite: 301] train loss: 0.620653, tar: 0.058347, time-per-iter: 0.083623 s, time_read: 0.001740\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2416/ 7992, ite: 302] train loss: 0.620087, tar: 0.058249, time-per-iter: 0.082369 s, time_read: 0.001879\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2424/ 7992, ite: 303] train loss: 0.619643, tar: 0.058163, time-per-iter: 0.083373 s, time_read: 0.001737\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2432/ 7992, ite: 304] train loss: 0.619363, tar: 0.058077, time-per-iter: 0.083112 s, time_read: 0.001834\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2440/ 7992, ite: 305] train loss: 0.619223, tar: 0.058060, time-per-iter: 0.084220 s, time_read: 0.001850\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2448/ 7992, ite: 306] train loss: 0.618726, tar: 0.057952, time-per-iter: 0.082792 s, time_read: 0.001818\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2456/ 7992, ite: 307] train loss: 0.618778, tar: 0.057982, time-per-iter: 0.084437 s, time_read: 0.001930\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2464/ 7992, ite: 308] train loss: 0.618278, tar: 0.057889, time-per-iter: 0.083774 s, time_read: 0.002198\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2472/ 7992, ite: 309] train loss: 0.617886, tar: 0.057802, time-per-iter: 0.083171 s, time_read: 0.001816\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2480/ 7992, ite: 310] train loss: 0.617609, tar: 0.057724, time-per-iter: 0.083328 s, time_read: 0.001698\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2488/ 7992, ite: 311] train loss: 0.617384, tar: 0.057678, time-per-iter: 0.082072 s, time_read: 0.001793\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2496/ 7992, ite: 312] train loss: 0.616970, tar: 0.057576, time-per-iter: 0.082373 s, time_read: 0.002007\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2504/ 7992, ite: 313] train loss: 0.616544, tar: 0.057475, time-per-iter: 0.082904 s, time_read: 0.001700\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2512/ 7992, ite: 314] train loss: 0.616098, tar: 0.057367, time-per-iter: 0.082221 s, time_read: 0.001791\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2520/ 7992, ite: 315] train loss: 0.615687, tar: 0.057269, time-per-iter: 0.082965 s, time_read: 0.001951\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2528/ 7992, ite: 316] train loss: 0.615316, tar: 0.057187, time-per-iter: 0.082873 s, time_read: 0.001819\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2536/ 7992, ite: 317] train loss: 0.614930, tar: 0.057094, time-per-iter: 0.083350 s, time_read: 0.001801\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2544/ 7992, ite: 318] train loss: 0.614520, tar: 0.057005, time-per-iter: 0.083928 s, time_read: 0.001663\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2552/ 7992, ite: 319] train loss: 0.614083, tar: 0.056914, time-per-iter: 0.083450 s, time_read: 0.001881\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2560/ 7992, ite: 320] train loss: 0.613772, tar: 0.056840, time-per-iter: 0.083079 s, time_read: 0.001988\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2568/ 7992, ite: 321] train loss: 0.613431, tar: 0.056774, time-per-iter: 0.083736 s, time_read: 0.001725\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2576/ 7992, ite: 322] train loss: 0.613138, tar: 0.056701, time-per-iter: 0.083941 s, time_read: 0.001730\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2584/ 7992, ite: 323] train loss: 0.613388, tar: 0.056799, time-per-iter: 0.083700 s, time_read: 0.002187\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2592/ 7992, ite: 324] train loss: 0.612852, tar: 0.056702, time-per-iter: 0.083261 s, time_read: 0.001796\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2600/ 7992, ite: 325] train loss: 0.612423, tar: 0.056614, time-per-iter: 0.084367 s, time_read: 0.001680\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2608/ 7992, ite: 326] train loss: 0.612097, tar: 0.056556, time-per-iter: 0.083803 s, time_read: 0.001783\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2616/ 7992, ite: 327] train loss: 0.611755, tar: 0.056469, time-per-iter: 0.094002 s, time_read: 0.012201\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2624/ 7992, ite: 328] train loss: 0.611639, tar: 0.056452, time-per-iter: 0.084637 s, time_read: 0.001876\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2632/ 7992, ite: 329] train loss: 0.611090, tar: 0.056354, time-per-iter: 0.083236 s, time_read: 0.001783\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2640/ 7992, ite: 330] train loss: 0.610723, tar: 0.056280, time-per-iter: 0.082594 s, time_read: 0.001710\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2648/ 7992, ite: 331] train loss: 0.610403, tar: 0.056209, time-per-iter: 0.083766 s, time_read: 0.001792\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2656/ 7992, ite: 332] train loss: 0.609991, tar: 0.056129, time-per-iter: 0.083637 s, time_read: 0.001898\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2664/ 7992, ite: 333] train loss: 0.609757, tar: 0.056083, time-per-iter: 0.083812 s, time_read: 0.001763\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2672/ 7992, ite: 334] train loss: 0.609409, tar: 0.055998, time-per-iter: 0.084225 s, time_read: 0.001718\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2680/ 7992, ite: 335] train loss: 0.609149, tar: 0.055932, time-per-iter: 0.082608 s, time_read: 0.001931\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2688/ 7992, ite: 336] train loss: 0.608792, tar: 0.055848, time-per-iter: 0.082707 s, time_read: 0.001822\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2696/ 7992, ite: 337] train loss: 0.608513, tar: 0.055776, time-per-iter: 0.082825 s, time_read: 0.001713\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2704/ 7992, ite: 338] train loss: 0.608133, tar: 0.055697, time-per-iter: 0.084051 s, time_read: 0.001785\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2712/ 7992, ite: 339] train loss: 0.607805, tar: 0.055621, time-per-iter: 0.083248 s, time_read: 0.001765\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2720/ 7992, ite: 340] train loss: 0.607484, tar: 0.055580, time-per-iter: 0.084202 s, time_read: 0.001817\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2728/ 7992, ite: 341] train loss: 0.607102, tar: 0.055505, time-per-iter: 0.081762 s, time_read: 0.001884\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2736/ 7992, ite: 342] train loss: 0.606719, tar: 0.055429, time-per-iter: 0.082828 s, time_read: 0.001678\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2744/ 7992, ite: 343] train loss: 0.606627, tar: 0.055429, time-per-iter: 0.083130 s, time_read: 0.001858\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2752/ 7992, ite: 344] train loss: 0.606245, tar: 0.055346, time-per-iter: 0.084563 s, time_read: 0.001894\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2760/ 7992, ite: 345] train loss: 0.606066, tar: 0.055318, time-per-iter: 0.082892 s, time_read: 0.001774\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2768/ 7992, ite: 346] train loss: 0.605798, tar: 0.055236, time-per-iter: 0.083503 s, time_read: 0.001630\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2776/ 7992, ite: 347] train loss: 0.605525, tar: 0.055173, time-per-iter: 0.082915 s, time_read: 0.001869\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2784/ 7992, ite: 348] train loss: 0.605461, tar: 0.055147, time-per-iter: 0.083328 s, time_read: 0.001843\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2792/ 7992, ite: 349] train loss: 0.605140, tar: 0.055070, time-per-iter: 0.083222 s, time_read: 0.001759\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2800/ 7992, ite: 350] train loss: 0.604821, tar: 0.054997, time-per-iter: 0.081683 s, time_read: 0.001773\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2808/ 7992, ite: 351] train loss: 0.604506, tar: 0.054935, time-per-iter: 0.082245 s, time_read: 0.001827\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2816/ 7992, ite: 352] train loss: 0.604279, tar: 0.054866, time-per-iter: 0.083723 s, time_read: 0.001921\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2824/ 7992, ite: 353] train loss: 0.603962, tar: 0.054808, time-per-iter: 0.083261 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2832/ 7992, ite: 354] train loss: 0.603729, tar: 0.054738, time-per-iter: 0.082913 s, time_read: 0.001730\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2840/ 7992, ite: 355] train loss: 0.603430, tar: 0.054666, time-per-iter: 0.082452 s, time_read: 0.001752\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2848/ 7992, ite: 356] train loss: 0.603084, tar: 0.054587, time-per-iter: 0.082992 s, time_read: 0.002012\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2856/ 7992, ite: 357] train loss: 0.602668, tar: 0.054507, time-per-iter: 0.083189 s, time_read: 0.001702\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2864/ 7992, ite: 358] train loss: 0.602334, tar: 0.054434, time-per-iter: 0.082857 s, time_read: 0.001676\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2872/ 7992, ite: 359] train loss: 0.602271, tar: 0.054423, time-per-iter: 0.081582 s, time_read: 0.001866\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2880/ 7992, ite: 360] train loss: 0.601893, tar: 0.054345, time-per-iter: 0.081085 s, time_read: 0.001855\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2888/ 7992, ite: 361] train loss: 0.601687, tar: 0.054290, time-per-iter: 0.083028 s, time_read: 0.001752\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2896/ 7992, ite: 362] train loss: 0.601346, tar: 0.054226, time-per-iter: 0.083324 s, time_read: 0.001818\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2904/ 7992, ite: 363] train loss: 0.601099, tar: 0.054183, time-per-iter: 0.083550 s, time_read: 0.001811\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2912/ 7992, ite: 364] train loss: 0.600763, tar: 0.054101, time-per-iter: 0.082161 s, time_read: 0.001807\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2920/ 7992, ite: 365] train loss: 0.600321, tar: 0.054021, time-per-iter: 0.080660 s, time_read: 0.001864\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2928/ 7992, ite: 366] train loss: 0.600000, tar: 0.053957, time-per-iter: 0.082674 s, time_read: 0.001682\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2936/ 7992, ite: 367] train loss: 0.599727, tar: 0.053897, time-per-iter: 0.083159 s, time_read: 0.001856\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2944/ 7992, ite: 368] train loss: 0.599424, tar: 0.053837, time-per-iter: 0.083397 s, time_read: 0.001834\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2952/ 7992, ite: 369] train loss: 0.599084, tar: 0.053773, time-per-iter: 0.081534 s, time_read: 0.001674\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2960/ 7992, ite: 370] train loss: 0.598684, tar: 0.053693, time-per-iter: 0.083032 s, time_read: 0.001774\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2968/ 7992, ite: 371] train loss: 0.598331, tar: 0.053611, time-per-iter: 0.083373 s, time_read: 0.001868\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2976/ 7992, ite: 372] train loss: 0.597999, tar: 0.053533, time-per-iter: 0.083297 s, time_read: 0.001831\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2984/ 7992, ite: 373] train loss: 0.597735, tar: 0.053474, time-per-iter: 0.082843 s, time_read: 0.001827\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  2992/ 7992, ite: 374] train loss: 0.597372, tar: 0.053405, time-per-iter: 0.081701 s, time_read: 0.002033\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3000/ 7992, ite: 375] train loss: 0.597010, tar: 0.053327, time-per-iter: 0.082790 s, time_read: 0.001733\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3008/ 7992, ite: 376] train loss: 0.596697, tar: 0.053245, time-per-iter: 0.082764 s, time_read: 0.001822\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3016/ 7992, ite: 377] train loss: 0.596341, tar: 0.053177, time-per-iter: 0.083156 s, time_read: 0.001880\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3024/ 7992, ite: 378] train loss: 0.596064, tar: 0.053125, time-per-iter: 0.082938 s, time_read: 0.001677\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3032/ 7992, ite: 379] train loss: 0.595726, tar: 0.053043, time-per-iter: 0.083144 s, time_read: 0.001794\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3040/ 7992, ite: 380] train loss: 0.595349, tar: 0.052954, time-per-iter: 0.083449 s, time_read: 0.001956\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3048/ 7992, ite: 381] train loss: 0.595702, tar: 0.053044, time-per-iter: 0.083562 s, time_read: 0.001731\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3056/ 7992, ite: 382] train loss: 0.595468, tar: 0.053016, time-per-iter: 0.083853 s, time_read: 0.002028\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3064/ 7992, ite: 383] train loss: 0.595131, tar: 0.052933, time-per-iter: 0.082913 s, time_read: 0.002273\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3072/ 7992, ite: 384] train loss: 0.594845, tar: 0.052848, time-per-iter: 0.083053 s, time_read: 0.001857\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3080/ 7992, ite: 385] train loss: 0.594479, tar: 0.052776, time-per-iter: 0.083332 s, time_read: 0.001728\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3088/ 7992, ite: 386] train loss: 0.594264, tar: 0.052735, time-per-iter: 0.082795 s, time_read: 0.001738\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3096/ 7992, ite: 387] train loss: 0.593875, tar: 0.052656, time-per-iter: 0.084222 s, time_read: 0.002289\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3104/ 7992, ite: 388] train loss: 0.593600, tar: 0.052601, time-per-iter: 0.082951 s, time_read: 0.001969\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3112/ 7992, ite: 389] train loss: 0.593286, tar: 0.052544, time-per-iter: 0.083124 s, time_read: 0.001792\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3120/ 7992, ite: 390] train loss: 0.592961, tar: 0.052476, time-per-iter: 0.083712 s, time_read: 0.001729\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3128/ 7992, ite: 391] train loss: 0.592711, tar: 0.052411, time-per-iter: 0.083000 s, time_read: 0.001806\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3136/ 7992, ite: 392] train loss: 0.592375, tar: 0.052338, time-per-iter: 0.082839 s, time_read: 0.001884\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3144/ 7992, ite: 393] train loss: 0.592081, tar: 0.052284, time-per-iter: 0.082591 s, time_read: 0.001789\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3152/ 7992, ite: 394] train loss: 0.591682, tar: 0.052218, time-per-iter: 0.083581 s, time_read: 0.001739\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3160/ 7992, ite: 395] train loss: 0.591599, tar: 0.052181, time-per-iter: 0.082836 s, time_read: 0.001745\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3168/ 7992, ite: 396] train loss: 0.591378, tar: 0.052142, time-per-iter: 0.083125 s, time_read: 0.001910\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3176/ 7992, ite: 397] train loss: 0.591135, tar: 0.052090, time-per-iter: 0.083301 s, time_read: 0.001754\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3184/ 7992, ite: 398] train loss: 0.590779, tar: 0.052014, time-per-iter: 0.085934 s, time_read: 0.001822\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3192/ 7992, ite: 399] train loss: 0.590396, tar: 0.051940, time-per-iter: 0.084394 s, time_read: 0.001818\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3200/ 7992, ite: 400] train loss: 0.590605, tar: 0.052053, time-per-iter: 0.085800 s, time_read: 0.001922\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3208/ 7992, ite: 401] train loss: 0.590611, tar: 0.052054, time-per-iter: 0.083210 s, time_read: 0.001953\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3216/ 7992, ite: 402] train loss: 0.590329, tar: 0.051990, time-per-iter: 0.083147 s, time_read: 0.001740\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3224/ 7992, ite: 403] train loss: 0.590108, tar: 0.051953, time-per-iter: 0.083585 s, time_read: 0.001755\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3232/ 7992, ite: 404] train loss: 0.589991, tar: 0.051921, time-per-iter: 0.083425 s, time_read: 0.001914\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3240/ 7992, ite: 405] train loss: 0.589766, tar: 0.051893, time-per-iter: 0.083838 s, time_read: 0.001900\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3248/ 7992, ite: 406] train loss: 0.589537, tar: 0.051833, time-per-iter: 0.083240 s, time_read: 0.001721\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3256/ 7992, ite: 407] train loss: 0.589514, tar: 0.051828, time-per-iter: 0.082210 s, time_read: 0.001919\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3264/ 7992, ite: 408] train loss: 0.589239, tar: 0.051765, time-per-iter: 0.081563 s, time_read: 0.001868\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3272/ 7992, ite: 409] train loss: 0.588982, tar: 0.051713, time-per-iter: 0.080581 s, time_read: 0.001690\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3280/ 7992, ite: 410] train loss: 0.588664, tar: 0.051647, time-per-iter: 0.082087 s, time_read: 0.001768\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3288/ 7992, ite: 411] train loss: 0.588345, tar: 0.051597, time-per-iter: 0.083238 s, time_read: 0.001817\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3296/ 7992, ite: 412] train loss: 0.588062, tar: 0.051535, time-per-iter: 0.082950 s, time_read: 0.001899\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3304/ 7992, ite: 413] train loss: 0.587741, tar: 0.051473, time-per-iter: 0.082303 s, time_read: 0.001740\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3312/ 7992, ite: 414] train loss: 0.587381, tar: 0.051398, time-per-iter: 0.082954 s, time_read: 0.001888\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3320/ 7992, ite: 415] train loss: 0.587093, tar: 0.051331, time-per-iter: 0.083857 s, time_read: 0.001739\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3328/ 7992, ite: 416] train loss: 0.586883, tar: 0.051287, time-per-iter: 0.086504 s, time_read: 0.001910\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3336/ 7992, ite: 417] train loss: 0.586572, tar: 0.051227, time-per-iter: 0.084909 s, time_read: 0.001678\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3344/ 7992, ite: 418] train loss: 0.586495, tar: 0.051218, time-per-iter: 0.083655 s, time_read: 0.001810\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3352/ 7992, ite: 419] train loss: 0.586166, tar: 0.051158, time-per-iter: 0.082824 s, time_read: 0.001860\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3360/ 7992, ite: 420] train loss: 0.586054, tar: 0.051122, time-per-iter: 0.082926 s, time_read: 0.001817\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3368/ 7992, ite: 421] train loss: 0.585821, tar: 0.051084, time-per-iter: 0.082787 s, time_read: 0.001949\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3376/ 7992, ite: 422] train loss: 0.585604, tar: 0.051055, time-per-iter: 0.082176 s, time_read: 0.001926\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3384/ 7992, ite: 423] train loss: 0.585256, tar: 0.051003, time-per-iter: 0.083122 s, time_read: 0.001806\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3392/ 7992, ite: 424] train loss: 0.585042, tar: 0.050953, time-per-iter: 0.083597 s, time_read: 0.001928\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3400/ 7992, ite: 425] train loss: 0.584804, tar: 0.050912, time-per-iter: 0.083383 s, time_read: 0.001894\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3408/ 7992, ite: 426] train loss: 0.584455, tar: 0.050851, time-per-iter: 0.082988 s, time_read: 0.001764\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3416/ 7992, ite: 427] train loss: 0.584248, tar: 0.050804, time-per-iter: 0.082896 s, time_read: 0.001796\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3424/ 7992, ite: 428] train loss: 0.583955, tar: 0.050755, time-per-iter: 0.082962 s, time_read: 0.001964\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3432/ 7992, ite: 429] train loss: 0.583907, tar: 0.050742, time-per-iter: 0.083489 s, time_read: 0.001900\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3440/ 7992, ite: 430] train loss: 0.583594, tar: 0.050682, time-per-iter: 0.083418 s, time_read: 0.001723\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3448/ 7992, ite: 431] train loss: 0.583577, tar: 0.050668, time-per-iter: 0.082928 s, time_read: 0.001934\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3456/ 7992, ite: 432] train loss: 0.583273, tar: 0.050605, time-per-iter: 0.080646 s, time_read: 0.001836\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3464/ 7992, ite: 433] train loss: 0.582953, tar: 0.050533, time-per-iter: 0.083018 s, time_read: 0.001765\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3472/ 7992, ite: 434] train loss: 0.582710, tar: 0.050466, time-per-iter: 0.083358 s, time_read: 0.001818\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3480/ 7992, ite: 435] train loss: 0.582438, tar: 0.050402, time-per-iter: 0.082620 s, time_read: 0.001789\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3488/ 7992, ite: 436] train loss: 0.582151, tar: 0.050341, time-per-iter: 0.082803 s, time_read: 0.002068\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3496/ 7992, ite: 437] train loss: 0.581909, tar: 0.050274, time-per-iter: 0.080987 s, time_read: 0.001774\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3504/ 7992, ite: 438] train loss: 0.581649, tar: 0.050212, time-per-iter: 0.083329 s, time_read: 0.001738\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3512/ 7992, ite: 439] train loss: 0.581538, tar: 0.050196, time-per-iter: 0.083058 s, time_read: 0.001792\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3520/ 7992, ite: 440] train loss: 0.581202, tar: 0.050125, time-per-iter: 0.083315 s, time_read: 0.001882\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3528/ 7992, ite: 441] train loss: 0.581316, tar: 0.050153, time-per-iter: 0.081720 s, time_read: 0.001811\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3536/ 7992, ite: 442] train loss: 0.581096, tar: 0.050095, time-per-iter: 0.081676 s, time_read: 0.001710\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3544/ 7992, ite: 443] train loss: 0.580926, tar: 0.050069, time-per-iter: 0.083050 s, time_read: 0.001920\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3552/ 7992, ite: 444] train loss: 0.580628, tar: 0.050017, time-per-iter: 0.083243 s, time_read: 0.001920\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3560/ 7992, ite: 445] train loss: 0.580396, tar: 0.049987, time-per-iter: 0.082799 s, time_read: 0.001779\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3568/ 7992, ite: 446] train loss: 0.580576, tar: 0.050060, time-per-iter: 0.081477 s, time_read: 0.001769\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3576/ 7992, ite: 447] train loss: 0.580475, tar: 0.050024, time-per-iter: 0.083305 s, time_read: 0.001844\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3584/ 7992, ite: 448] train loss: 0.580302, tar: 0.049988, time-per-iter: 0.083801 s, time_read: 0.001778\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3592/ 7992, ite: 449] train loss: 0.580110, tar: 0.049943, time-per-iter: 0.083674 s, time_read: 0.001848\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3600/ 7992, ite: 450] train loss: 0.579842, tar: 0.049885, time-per-iter: 0.083148 s, time_read: 0.001688\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3608/ 7992, ite: 451] train loss: 0.579564, tar: 0.049830, time-per-iter: 0.081562 s, time_read: 0.001812\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3616/ 7992, ite: 452] train loss: 0.579552, tar: 0.049846, time-per-iter: 0.083377 s, time_read: 0.001943\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3624/ 7992, ite: 453] train loss: 0.579273, tar: 0.049791, time-per-iter: 0.083515 s, time_read: 0.001741\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3632/ 7992, ite: 454] train loss: 0.579202, tar: 0.049795, time-per-iter: 0.084246 s, time_read: 0.001786\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3640/ 7992, ite: 455] train loss: 0.579054, tar: 0.049747, time-per-iter: 0.082723 s, time_read: 0.001805\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3648/ 7992, ite: 456] train loss: 0.578903, tar: 0.049702, time-per-iter: 0.081842 s, time_read: 0.001838\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3656/ 7992, ite: 457] train loss: 0.578705, tar: 0.049663, time-per-iter: 0.083109 s, time_read: 0.001766\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3664/ 7992, ite: 458] train loss: 0.578433, tar: 0.049620, time-per-iter: 0.082451 s, time_read: 0.001743\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3672/ 7992, ite: 459] train loss: 0.578132, tar: 0.049556, time-per-iter: 0.082559 s, time_read: 0.001744\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3680/ 7992, ite: 460] train loss: 0.577880, tar: 0.049499, time-per-iter: 0.083669 s, time_read: 0.001925\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3688/ 7992, ite: 461] train loss: 0.577613, tar: 0.049449, time-per-iter: 0.083752 s, time_read: 0.001793\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3696/ 7992, ite: 462] train loss: 0.577331, tar: 0.049399, time-per-iter: 0.084967 s, time_read: 0.001774\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3704/ 7992, ite: 463] train loss: 0.577297, tar: 0.049386, time-per-iter: 0.083520 s, time_read: 0.002186\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3712/ 7992, ite: 464] train loss: 0.577861, tar: 0.049519, time-per-iter: 0.083459 s, time_read: 0.002004\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3720/ 7992, ite: 465] train loss: 0.577695, tar: 0.049481, time-per-iter: 0.083627 s, time_read: 0.001767\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3728/ 7992, ite: 466] train loss: 0.577520, tar: 0.049463, time-per-iter: 0.085115 s, time_read: 0.001778\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3736/ 7992, ite: 467] train loss: 0.577325, tar: 0.049434, time-per-iter: 0.084202 s, time_read: 0.002246\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3744/ 7992, ite: 468] train loss: 0.577098, tar: 0.049384, time-per-iter: 0.084392 s, time_read: 0.002432\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3752/ 7992, ite: 469] train loss: 0.577009, tar: 0.049353, time-per-iter: 0.084056 s, time_read: 0.001802\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3760/ 7992, ite: 470] train loss: 0.576845, tar: 0.049311, time-per-iter: 0.084249 s, time_read: 0.001834\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3768/ 7992, ite: 471] train loss: 0.576640, tar: 0.049269, time-per-iter: 0.084046 s, time_read: 0.001917\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3776/ 7992, ite: 472] train loss: 0.576623, tar: 0.049272, time-per-iter: 0.084234 s, time_read: 0.001939\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3784/ 7992, ite: 473] train loss: 0.576781, tar: 0.049309, time-per-iter: 0.084131 s, time_read: 0.001832\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3792/ 7992, ite: 474] train loss: 0.576691, tar: 0.049295, time-per-iter: 0.084941 s, time_read: 0.001750\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3800/ 7992, ite: 475] train loss: 0.576634, tar: 0.049293, time-per-iter: 0.084191 s, time_read: 0.001834\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3808/ 7992, ite: 476] train loss: 0.576484, tar: 0.049264, time-per-iter: 0.084888 s, time_read: 0.002725\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3816/ 7992, ite: 477] train loss: 0.576286, tar: 0.049210, time-per-iter: 0.083820 s, time_read: 0.001752\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3824/ 7992, ite: 478] train loss: 0.576174, tar: 0.049188, time-per-iter: 0.084184 s, time_read: 0.001709\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3832/ 7992, ite: 479] train loss: 0.576024, tar: 0.049149, time-per-iter: 0.084439 s, time_read: 0.001947\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3840/ 7992, ite: 480] train loss: 0.575751, tar: 0.049107, time-per-iter: 0.084559 s, time_read: 0.002135\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3848/ 7992, ite: 481] train loss: 0.575497, tar: 0.049049, time-per-iter: 0.084231 s, time_read: 0.001745\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3856/ 7992, ite: 482] train loss: 0.575296, tar: 0.049018, time-per-iter: 0.083685 s, time_read: 0.001763\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3864/ 7992, ite: 483] train loss: 0.575221, tar: 0.049010, time-per-iter: 0.083157 s, time_read: 0.001899\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3872/ 7992, ite: 484] train loss: 0.575139, tar: 0.048995, time-per-iter: 0.086743 s, time_read: 0.002206\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3880/ 7992, ite: 485] train loss: 0.575180, tar: 0.049020, time-per-iter: 0.084209 s, time_read: 0.001836\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3888/ 7992, ite: 486] train loss: 0.575036, tar: 0.048992, time-per-iter: 0.084382 s, time_read: 0.001712\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3896/ 7992, ite: 487] train loss: 0.574831, tar: 0.048956, time-per-iter: 0.084845 s, time_read: 0.001982\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3904/ 7992, ite: 488] train loss: 0.574639, tar: 0.048918, time-per-iter: 0.084958 s, time_read: 0.002305\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3912/ 7992, ite: 489] train loss: 0.574601, tar: 0.048925, time-per-iter: 0.083971 s, time_read: 0.001718\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3920/ 7992, ite: 490] train loss: 0.574412, tar: 0.048876, time-per-iter: 0.084434 s, time_read: 0.001707\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3928/ 7992, ite: 491] train loss: 0.574234, tar: 0.048838, time-per-iter: 0.084210 s, time_read: 0.001997\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3936/ 7992, ite: 492] train loss: 0.574066, tar: 0.048796, time-per-iter: 0.084765 s, time_read: 0.001911\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3944/ 7992, ite: 493] train loss: 0.573834, tar: 0.048768, time-per-iter: 0.084906 s, time_read: 0.001797\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3952/ 7992, ite: 494] train loss: 0.573642, tar: 0.048721, time-per-iter: 0.082684 s, time_read: 0.001921\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3960/ 7992, ite: 495] train loss: 0.573511, tar: 0.048688, time-per-iter: 0.083068 s, time_read: 0.001722\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3968/ 7992, ite: 496] train loss: 0.573358, tar: 0.048652, time-per-iter: 0.084128 s, time_read: 0.001869\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3976/ 7992, ite: 497] train loss: 0.573402, tar: 0.048671, time-per-iter: 0.083820 s, time_read: 0.001755\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3984/ 7992, ite: 498] train loss: 0.573252, tar: 0.048650, time-per-iter: 0.082622 s, time_read: 0.001878\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  3992/ 7992, ite: 499] train loss: 0.573055, tar: 0.048599, time-per-iter: 0.082669 s, time_read: 0.001832\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4000/ 7992, ite: 500] train loss: 0.572899, tar: 0.048567, time-per-iter: 0.083273 s, time_read: 0.001876\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4008/ 7992, ite: 501] train loss: 0.572712, tar: 0.048527, time-per-iter: 0.083896 s, time_read: 0.001785\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4016/ 7992, ite: 502] train loss: 0.572592, tar: 0.048492, time-per-iter: 0.083347 s, time_read: 0.001834\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4024/ 7992, ite: 503] train loss: 0.572447, tar: 0.048450, time-per-iter: 0.081736 s, time_read: 0.001939\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4032/ 7992, ite: 504] train loss: 0.572193, tar: 0.048402, time-per-iter: 0.080737 s, time_read: 0.001862\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4040/ 7992, ite: 505] train loss: 0.572123, tar: 0.048385, time-per-iter: 0.083686 s, time_read: 0.001791\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4048/ 7992, ite: 506] train loss: 0.571899, tar: 0.048343, time-per-iter: 0.083225 s, time_read: 0.001889\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4056/ 7992, ite: 507] train loss: 0.571761, tar: 0.048311, time-per-iter: 0.082729 s, time_read: 0.001801\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4064/ 7992, ite: 508] train loss: 0.571727, tar: 0.048296, time-per-iter: 0.082570 s, time_read: 0.001880\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4072/ 7992, ite: 509] train loss: 0.571589, tar: 0.048262, time-per-iter: 0.081429 s, time_read: 0.001800\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4080/ 7992, ite: 510] train loss: 0.571676, tar: 0.048281, time-per-iter: 0.083626 s, time_read: 0.001654\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4088/ 7992, ite: 511] train loss: 0.571607, tar: 0.048266, time-per-iter: 0.083185 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4096/ 7992, ite: 512] train loss: 0.571456, tar: 0.048226, time-per-iter: 0.082356 s, time_read: 0.001930\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4104/ 7992, ite: 513] train loss: 0.571340, tar: 0.048187, time-per-iter: 0.082689 s, time_read: 0.001711\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4112/ 7992, ite: 514] train loss: 0.571115, tar: 0.048152, time-per-iter: 0.084433 s, time_read: 0.001708\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4120/ 7992, ite: 515] train loss: 0.570961, tar: 0.048123, time-per-iter: 0.083908 s, time_read: 0.001882\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4128/ 7992, ite: 516] train loss: 0.570855, tar: 0.048115, time-per-iter: 0.083711 s, time_read: 0.001994\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4136/ 7992, ite: 517] train loss: 0.570613, tar: 0.048055, time-per-iter: 0.084080 s, time_read: 0.001731\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4144/ 7992, ite: 518] train loss: 0.570644, tar: 0.048071, time-per-iter: 0.082232 s, time_read: 0.001799\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4152/ 7992, ite: 519] train loss: 0.570469, tar: 0.048033, time-per-iter: 0.083070 s, time_read: 0.002032\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4160/ 7992, ite: 520] train loss: 0.570303, tar: 0.047997, time-per-iter: 0.083071 s, time_read: 0.001778\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4168/ 7992, ite: 521] train loss: 0.570071, tar: 0.047953, time-per-iter: 0.083861 s, time_read: 0.001805\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4176/ 7992, ite: 522] train loss: 0.569859, tar: 0.047900, time-per-iter: 0.082658 s, time_read: 0.001655\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4184/ 7992, ite: 523] train loss: 0.569690, tar: 0.047866, time-per-iter: 0.083587 s, time_read: 0.001904\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4192/ 7992, ite: 524] train loss: 0.569427, tar: 0.047826, time-per-iter: 0.084039 s, time_read: 0.002094\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4200/ 7992, ite: 525] train loss: 0.569166, tar: 0.047775, time-per-iter: 0.082755 s, time_read: 0.001820\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4208/ 7992, ite: 526] train loss: 0.568946, tar: 0.047730, time-per-iter: 0.083877 s, time_read: 0.001755\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4216/ 7992, ite: 527] train loss: 0.568735, tar: 0.047700, time-per-iter: 0.082974 s, time_read: 0.001892\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4224/ 7992, ite: 528] train loss: 0.568541, tar: 0.047664, time-per-iter: 0.082855 s, time_read: 0.001791\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4232/ 7992, ite: 529] train loss: 0.568364, tar: 0.047622, time-per-iter: 0.082297 s, time_read: 0.001909\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4240/ 7992, ite: 530] train loss: 0.568269, tar: 0.047615, time-per-iter: 0.081440 s, time_read: 0.001789\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4248/ 7992, ite: 531] train loss: 0.568133, tar: 0.047574, time-per-iter: 0.081992 s, time_read: 0.001828\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4256/ 7992, ite: 532] train loss: 0.567923, tar: 0.047536, time-per-iter: 0.082915 s, time_read: 0.001724\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4264/ 7992, ite: 533] train loss: 0.567685, tar: 0.047495, time-per-iter: 0.083370 s, time_read: 0.001780\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4272/ 7992, ite: 534] train loss: 0.567430, tar: 0.047444, time-per-iter: 0.083417 s, time_read: 0.001738\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4280/ 7992, ite: 535] train loss: 0.567252, tar: 0.047400, time-per-iter: 0.082993 s, time_read: 0.001924\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4288/ 7992, ite: 536] train loss: 0.567031, tar: 0.047371, time-per-iter: 0.084745 s, time_read: 0.002540\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4296/ 7992, ite: 537] train loss: 0.566853, tar: 0.047337, time-per-iter: 0.083530 s, time_read: 0.001781\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4304/ 7992, ite: 538] train loss: 0.566793, tar: 0.047336, time-per-iter: 0.084603 s, time_read: 0.001769\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4312/ 7992, ite: 539] train loss: 0.566772, tar: 0.047340, time-per-iter: 0.083121 s, time_read: 0.001837\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4320/ 7992, ite: 540] train loss: 0.566573, tar: 0.047295, time-per-iter: 0.083054 s, time_read: 0.001977\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4328/ 7992, ite: 541] train loss: 0.566411, tar: 0.047265, time-per-iter: 0.084586 s, time_read: 0.001768\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4336/ 7992, ite: 542] train loss: 0.566285, tar: 0.047247, time-per-iter: 0.083611 s, time_read: 0.001878\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4344/ 7992, ite: 543] train loss: 0.566285, tar: 0.047230, time-per-iter: 0.083505 s, time_read: 0.001797\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4352/ 7992, ite: 544] train loss: 0.566405, tar: 0.047265, time-per-iter: 0.086214 s, time_read: 0.001880\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4360/ 7992, ite: 545] train loss: 0.566310, tar: 0.047267, time-per-iter: 0.083689 s, time_read: 0.001802\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4368/ 7992, ite: 546] train loss: 0.566114, tar: 0.047235, time-per-iter: 0.083632 s, time_read: 0.001799\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4376/ 7992, ite: 547] train loss: 0.565909, tar: 0.047192, time-per-iter: 0.083855 s, time_read: 0.001967\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4384/ 7992, ite: 548] train loss: 0.565791, tar: 0.047161, time-per-iter: 0.084268 s, time_read: 0.002018\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4392/ 7992, ite: 549] train loss: 0.565888, tar: 0.047187, time-per-iter: 0.083060 s, time_read: 0.001842\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4400/ 7992, ite: 550] train loss: 0.565695, tar: 0.047152, time-per-iter: 0.083728 s, time_read: 0.002210\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4408/ 7992, ite: 551] train loss: 0.565527, tar: 0.047118, time-per-iter: 0.083557 s, time_read: 0.002164\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4416/ 7992, ite: 552] train loss: 0.565312, tar: 0.047089, time-per-iter: 0.083386 s, time_read: 0.001849\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4424/ 7992, ite: 553] train loss: 0.565141, tar: 0.047050, time-per-iter: 0.082680 s, time_read: 0.001701\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4432/ 7992, ite: 554] train loss: 0.565046, tar: 0.047029, time-per-iter: 0.082813 s, time_read: 0.001897\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4440/ 7992, ite: 555] train loss: 0.564928, tar: 0.047016, time-per-iter: 0.083426 s, time_read: 0.001829\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4448/ 7992, ite: 556] train loss: 0.564783, tar: 0.046985, time-per-iter: 0.082793 s, time_read: 0.001903\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4456/ 7992, ite: 557] train loss: 0.564657, tar: 0.046961, time-per-iter: 0.080577 s, time_read: 0.001884\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4464/ 7992, ite: 558] train loss: 0.564587, tar: 0.046963, time-per-iter: 0.082983 s, time_read: 0.001828\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4472/ 7992, ite: 559] train loss: 0.564408, tar: 0.046926, time-per-iter: 0.083609 s, time_read: 0.001810\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4480/ 7992, ite: 560] train loss: 0.564268, tar: 0.046892, time-per-iter: 0.083712 s, time_read: 0.002115\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4488/ 7992, ite: 561] train loss: 0.564108, tar: 0.046867, time-per-iter: 0.081079 s, time_read: 0.001779\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4496/ 7992, ite: 562] train loss: 0.563895, tar: 0.046821, time-per-iter: 0.081542 s, time_read: 0.001868\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4504/ 7992, ite: 563] train loss: 0.563776, tar: 0.046797, time-per-iter: 0.082815 s, time_read: 0.002000\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4512/ 7992, ite: 564] train loss: 0.563556, tar: 0.046752, time-per-iter: 0.083092 s, time_read: 0.001812\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4520/ 7992, ite: 565] train loss: 0.563351, tar: 0.046700, time-per-iter: 0.083596 s, time_read: 0.001726\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4528/ 7992, ite: 566] train loss: 0.563181, tar: 0.046672, time-per-iter: 0.081053 s, time_read: 0.001812\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4536/ 7992, ite: 567] train loss: 0.562969, tar: 0.046628, time-per-iter: 0.082296 s, time_read: 0.001822\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4544/ 7992, ite: 568] train loss: 0.562811, tar: 0.046592, time-per-iter: 0.083107 s, time_read: 0.001829\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4552/ 7992, ite: 569] train loss: 0.562646, tar: 0.046551, time-per-iter: 0.082828 s, time_read: 0.001885\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4560/ 7992, ite: 570] train loss: 0.562434, tar: 0.046529, time-per-iter: 0.082365 s, time_read: 0.001868\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4568/ 7992, ite: 571] train loss: 0.562334, tar: 0.046497, time-per-iter: 0.081841 s, time_read: 0.001821\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4576/ 7992, ite: 572] train loss: 0.562162, tar: 0.046465, time-per-iter: 0.082966 s, time_read: 0.001969\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4584/ 7992, ite: 573] train loss: 0.561987, tar: 0.046444, time-per-iter: 0.083239 s, time_read: 0.001812\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4592/ 7992, ite: 574] train loss: 0.561807, tar: 0.046413, time-per-iter: 0.082656 s, time_read: 0.001665\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4600/ 7992, ite: 575] train loss: 0.561747, tar: 0.046399, time-per-iter: 0.082021 s, time_read: 0.001932\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4608/ 7992, ite: 576] train loss: 0.561679, tar: 0.046372, time-per-iter: 0.080701 s, time_read: 0.001842\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4616/ 7992, ite: 577] train loss: 0.561650, tar: 0.046378, time-per-iter: 0.083202 s, time_read: 0.001818\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4624/ 7992, ite: 578] train loss: 0.561451, tar: 0.046338, time-per-iter: 0.083305 s, time_read: 0.001874\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4632/ 7992, ite: 579] train loss: 0.561333, tar: 0.046310, time-per-iter: 0.082920 s, time_read: 0.001831\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4640/ 7992, ite: 580] train loss: 0.561170, tar: 0.046282, time-per-iter: 0.082072 s, time_read: 0.001886\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4648/ 7992, ite: 581] train loss: 0.561050, tar: 0.046248, time-per-iter: 0.081081 s, time_read: 0.001836\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4656/ 7992, ite: 582] train loss: 0.560920, tar: 0.046217, time-per-iter: 0.082106 s, time_read: 0.001758\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4664/ 7992, ite: 583] train loss: 0.560759, tar: 0.046178, time-per-iter: 0.083465 s, time_read: 0.001808\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4672/ 7992, ite: 584] train loss: 0.560565, tar: 0.046138, time-per-iter: 0.083245 s, time_read: 0.001998\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4680/ 7992, ite: 585] train loss: 0.560542, tar: 0.046127, time-per-iter: 0.081650 s, time_read: 0.001826\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4688/ 7992, ite: 586] train loss: 0.560441, tar: 0.046098, time-per-iter: 0.081231 s, time_read: 0.001725\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4696/ 7992, ite: 587] train loss: 0.560281, tar: 0.046058, time-per-iter: 0.083118 s, time_read: 0.001925\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4704/ 7992, ite: 588] train loss: 0.560145, tar: 0.046022, time-per-iter: 0.082893 s, time_read: 0.001896\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4712/ 7992, ite: 589] train loss: 0.560040, tar: 0.045999, time-per-iter: 0.083542 s, time_read: 0.001731\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4720/ 7992, ite: 590] train loss: 0.559869, tar: 0.045953, time-per-iter: 0.081702 s, time_read: 0.001818\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4728/ 7992, ite: 591] train loss: 0.559880, tar: 0.045953, time-per-iter: 0.083440 s, time_read: 0.001916\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4736/ 7992, ite: 592] train loss: 0.559677, tar: 0.045904, time-per-iter: 0.084070 s, time_read: 0.001789\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4744/ 7992, ite: 593] train loss: 0.559581, tar: 0.045893, time-per-iter: 0.082945 s, time_read: 0.001832\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4752/ 7992, ite: 594] train loss: 0.559398, tar: 0.045849, time-per-iter: 0.082904 s, time_read: 0.001652\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4760/ 7992, ite: 595] train loss: 0.559299, tar: 0.045837, time-per-iter: 0.083191 s, time_read: 0.001881\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4768/ 7992, ite: 596] train loss: 0.559247, tar: 0.045827, time-per-iter: 0.083522 s, time_read: 0.002039\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4776/ 7992, ite: 597] train loss: 0.559158, tar: 0.045806, time-per-iter: 0.083390 s, time_read: 0.001791\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4784/ 7992, ite: 598] train loss: 0.559019, tar: 0.045773, time-per-iter: 0.083879 s, time_read: 0.001759\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4792/ 7992, ite: 599] train loss: 0.558830, tar: 0.045730, time-per-iter: 0.083334 s, time_read: 0.001884\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4800/ 7992, ite: 600] train loss: 0.558625, tar: 0.045687, time-per-iter: 0.083333 s, time_read: 0.001835\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4808/ 7992, ite: 601] train loss: 0.558459, tar: 0.045650, time-per-iter: 0.083740 s, time_read: 0.001731\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4816/ 7992, ite: 602] train loss: 0.558258, tar: 0.045620, time-per-iter: 0.083430 s, time_read: 0.001762\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4824/ 7992, ite: 603] train loss: 0.558048, tar: 0.045577, time-per-iter: 0.083420 s, time_read: 0.001859\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4832/ 7992, ite: 604] train loss: 0.557913, tar: 0.045553, time-per-iter: 0.084247 s, time_read: 0.001868\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4840/ 7992, ite: 605] train loss: 0.557716, tar: 0.045508, time-per-iter: 0.084152 s, time_read: 0.001797\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4848/ 7992, ite: 606] train loss: 0.557608, tar: 0.045478, time-per-iter: 0.083139 s, time_read: 0.001794\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4856/ 7992, ite: 607] train loss: 0.557713, tar: 0.045502, time-per-iter: 0.083649 s, time_read: 0.002109\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4864/ 7992, ite: 608] train loss: 0.557516, tar: 0.045472, time-per-iter: 0.083754 s, time_read: 0.002246\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4872/ 7992, ite: 609] train loss: 0.557349, tar: 0.045441, time-per-iter: 0.083408 s, time_read: 0.001792\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4880/ 7992, ite: 610] train loss: 0.557166, tar: 0.045408, time-per-iter: 0.083640 s, time_read: 0.001753\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4888/ 7992, ite: 611] train loss: 0.556941, tar: 0.045371, time-per-iter: 0.083823 s, time_read: 0.001996\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4896/ 7992, ite: 612] train loss: 0.556776, tar: 0.045333, time-per-iter: 0.082843 s, time_read: 0.001849\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4904/ 7992, ite: 613] train loss: 0.556549, tar: 0.045292, time-per-iter: 0.083608 s, time_read: 0.001768\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4912/ 7992, ite: 614] train loss: 0.556516, tar: 0.045274, time-per-iter: 0.082626 s, time_read: 0.001739\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4920/ 7992, ite: 615] train loss: 0.556393, tar: 0.045248, time-per-iter: 0.084022 s, time_read: 0.001922\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4928/ 7992, ite: 616] train loss: 0.556225, tar: 0.045202, time-per-iter: 0.083770 s, time_read: 0.001915\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4936/ 7992, ite: 617] train loss: 0.556034, tar: 0.045164, time-per-iter: 0.083271 s, time_read: 0.001840\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4944/ 7992, ite: 618] train loss: 0.555826, tar: 0.045127, time-per-iter: 0.083278 s, time_read: 0.001683\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4952/ 7992, ite: 619] train loss: 0.555669, tar: 0.045091, time-per-iter: 0.083305 s, time_read: 0.001787\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4960/ 7992, ite: 620] train loss: 0.555561, tar: 0.045075, time-per-iter: 0.083729 s, time_read: 0.001951\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4968/ 7992, ite: 621] train loss: 0.555373, tar: 0.045035, time-per-iter: 0.082748 s, time_read: 0.001759\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4976/ 7992, ite: 622] train loss: 0.555271, tar: 0.045005, time-per-iter: 0.084701 s, time_read: 0.001879\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4984/ 7992, ite: 623] train loss: 0.555191, tar: 0.044976, time-per-iter: 0.083630 s, time_read: 0.001937\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  4992/ 7992, ite: 624] train loss: 0.555108, tar: 0.044971, time-per-iter: 0.082556 s, time_read: 0.001922\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5000/ 7992, ite: 625] train loss: 0.554883, tar: 0.044925, time-per-iter: 0.086222 s, time_read: 0.001662\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5008/ 7992, ite: 626] train loss: 0.554751, tar: 0.044901, time-per-iter: 0.086859 s, time_read: 0.001821\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5016/ 7992, ite: 627] train loss: 0.554588, tar: 0.044863, time-per-iter: 0.085118 s, time_read: 0.002046\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5024/ 7992, ite: 628] train loss: 0.554541, tar: 0.044842, time-per-iter: 0.086901 s, time_read: 0.001836\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5032/ 7992, ite: 629] train loss: 0.554345, tar: 0.044805, time-per-iter: 0.084947 s, time_read: 0.001918\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5040/ 7992, ite: 630] train loss: 0.554204, tar: 0.044784, time-per-iter: 0.086468 s, time_read: 0.001782\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5048/ 7992, ite: 631] train loss: 0.554037, tar: 0.044749, time-per-iter: 0.086152 s, time_read: 0.001988\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5056/ 7992, ite: 632] train loss: 0.553855, tar: 0.044706, time-per-iter: 0.086224 s, time_read: 0.002020\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5064/ 7992, ite: 633] train loss: 0.553736, tar: 0.044682, time-per-iter: 0.086265 s, time_read: 0.001805\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5072/ 7992, ite: 634] train loss: 0.553614, tar: 0.044649, time-per-iter: 0.086019 s, time_read: 0.001776\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5080/ 7992, ite: 635] train loss: 0.553545, tar: 0.044638, time-per-iter: 0.086144 s, time_read: 0.002061\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5088/ 7992, ite: 636] train loss: 0.553349, tar: 0.044595, time-per-iter: 0.086067 s, time_read: 0.002040\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5096/ 7992, ite: 637] train loss: 0.553176, tar: 0.044562, time-per-iter: 0.086997 s, time_read: 0.001852\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5104/ 7992, ite: 638] train loss: 0.552998, tar: 0.044520, time-per-iter: 0.086642 s, time_read: 0.001934\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5112/ 7992, ite: 639] train loss: 0.552883, tar: 0.044488, time-per-iter: 0.085905 s, time_read: 0.001859\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5120/ 7992, ite: 640] train loss: 0.552735, tar: 0.044444, time-per-iter: 0.086779 s, time_read: 0.001994\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5128/ 7992, ite: 641] train loss: 0.552556, tar: 0.044404, time-per-iter: 0.085997 s, time_read: 0.001814\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5136/ 7992, ite: 642] train loss: 0.552453, tar: 0.044374, time-per-iter: 0.086131 s, time_read: 0.001699\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5144/ 7992, ite: 643] train loss: 0.552293, tar: 0.044342, time-per-iter: 0.086122 s, time_read: 0.001906\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5152/ 7992, ite: 644] train loss: 0.552156, tar: 0.044315, time-per-iter: 0.086491 s, time_read: 0.002038\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5160/ 7992, ite: 645] train loss: 0.552103, tar: 0.044301, time-per-iter: 0.086091 s, time_read: 0.001762\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5168/ 7992, ite: 646] train loss: 0.551966, tar: 0.044280, time-per-iter: 0.086361 s, time_read: 0.001702\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5176/ 7992, ite: 647] train loss: 0.551793, tar: 0.044236, time-per-iter: 0.086055 s, time_read: 0.002034\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5184/ 7992, ite: 648] train loss: 0.551608, tar: 0.044196, time-per-iter: 0.085998 s, time_read: 0.001986\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5192/ 7992, ite: 649] train loss: 0.551459, tar: 0.044160, time-per-iter: 0.086130 s, time_read: 0.001704\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5200/ 7992, ite: 650] train loss: 0.551343, tar: 0.044146, time-per-iter: 0.083936 s, time_read: 0.001847\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5208/ 7992, ite: 651] train loss: 0.551176, tar: 0.044111, time-per-iter: 0.083961 s, time_read: 0.001790\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5216/ 7992, ite: 652] train loss: 0.551006, tar: 0.044068, time-per-iter: 0.084483 s, time_read: 0.002290\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5224/ 7992, ite: 653] train loss: 0.550878, tar: 0.044039, time-per-iter: 0.084916 s, time_read: 0.002041\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5232/ 7992, ite: 654] train loss: 0.550721, tar: 0.043999, time-per-iter: 0.084452 s, time_read: 0.001756\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5240/ 7992, ite: 655] train loss: 0.550632, tar: 0.043987, time-per-iter: 0.084015 s, time_read: 0.002092\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5248/ 7992, ite: 656] train loss: 0.550493, tar: 0.043955, time-per-iter: 0.082716 s, time_read: 0.001914\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5256/ 7992, ite: 657] train loss: 0.550435, tar: 0.043938, time-per-iter: 0.084434 s, time_read: 0.001786\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5264/ 7992, ite: 658] train loss: 0.550336, tar: 0.043922, time-per-iter: 0.085451 s, time_read: 0.001777\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5272/ 7992, ite: 659] train loss: 0.550137, tar: 0.043884, time-per-iter: 0.084128 s, time_read: 0.001967\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5280/ 7992, ite: 660] train loss: 0.549951, tar: 0.043843, time-per-iter: 0.082702 s, time_read: 0.001796\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5288/ 7992, ite: 661] train loss: 0.549820, tar: 0.043812, time-per-iter: 0.084695 s, time_read: 0.001731\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5296/ 7992, ite: 662] train loss: 0.549648, tar: 0.043770, time-per-iter: 0.084452 s, time_read: 0.001725\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5304/ 7992, ite: 663] train loss: 0.549598, tar: 0.043742, time-per-iter: 0.084749 s, time_read: 0.001860\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5312/ 7992, ite: 664] train loss: 0.549558, tar: 0.043736, time-per-iter: 0.084642 s, time_read: 0.001771\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5320/ 7992, ite: 665] train loss: 0.549388, tar: 0.043698, time-per-iter: 0.083825 s, time_read: 0.001785\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5328/ 7992, ite: 666] train loss: 0.549239, tar: 0.043670, time-per-iter: 0.083301 s, time_read: 0.001703\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5336/ 7992, ite: 667] train loss: 0.549075, tar: 0.043630, time-per-iter: 0.084874 s, time_read: 0.001961\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5344/ 7992, ite: 668] train loss: 0.548921, tar: 0.043595, time-per-iter: 0.084002 s, time_read: 0.002417\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5352/ 7992, ite: 669] train loss: 0.548742, tar: 0.043558, time-per-iter: 0.083733 s, time_read: 0.001841\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5360/ 7992, ite: 670] train loss: 0.548583, tar: 0.043528, time-per-iter: 0.083889 s, time_read: 0.001742\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5368/ 7992, ite: 671] train loss: 0.548475, tar: 0.043500, time-per-iter: 0.083843 s, time_read: 0.001886\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5376/ 7992, ite: 672] train loss: 0.548307, tar: 0.043462, time-per-iter: 0.083230 s, time_read: 0.001869\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5384/ 7992, ite: 673] train loss: 0.548126, tar: 0.043422, time-per-iter: 0.082848 s, time_read: 0.001681\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5392/ 7992, ite: 674] train loss: 0.547907, tar: 0.043379, time-per-iter: 0.082399 s, time_read: 0.001726\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5400/ 7992, ite: 675] train loss: 0.547741, tar: 0.043355, time-per-iter: 0.083909 s, time_read: 0.002127\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5408/ 7992, ite: 676] train loss: 0.547539, tar: 0.043321, time-per-iter: 0.082931 s, time_read: 0.001864\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5416/ 7992, ite: 677] train loss: 0.547489, tar: 0.043303, time-per-iter: 0.084188 s, time_read: 0.001867\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5424/ 7992, ite: 678] train loss: 0.547494, tar: 0.043301, time-per-iter: 0.083510 s, time_read: 0.001675\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5432/ 7992, ite: 679] train loss: 0.547492, tar: 0.043312, time-per-iter: 0.084639 s, time_read: 0.001768\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5440/ 7992, ite: 680] train loss: 0.547396, tar: 0.043292, time-per-iter: 0.083677 s, time_read: 0.001907\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5448/ 7992, ite: 681] train loss: 0.547216, tar: 0.043252, time-per-iter: 0.082401 s, time_read: 0.001696\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5456/ 7992, ite: 682] train loss: 0.547168, tar: 0.043227, time-per-iter: 0.083139 s, time_read: 0.001665\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5464/ 7992, ite: 683] train loss: 0.547066, tar: 0.043218, time-per-iter: 0.083911 s, time_read: 0.001983\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5472/ 7992, ite: 684] train loss: 0.546951, tar: 0.043186, time-per-iter: 0.083993 s, time_read: 0.002258\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5480/ 7992, ite: 685] train loss: 0.546767, tar: 0.043158, time-per-iter: 0.083510 s, time_read: 0.001813\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5488/ 7992, ite: 686] train loss: 0.546648, tar: 0.043126, time-per-iter: 0.095732 s, time_read: 0.014450\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5496/ 7992, ite: 687] train loss: 0.546546, tar: 0.043105, time-per-iter: 0.084554 s, time_read: 0.002377\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5504/ 7992, ite: 688] train loss: 0.546352, tar: 0.043072, time-per-iter: 0.085749 s, time_read: 0.002267\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5512/ 7992, ite: 689] train loss: 0.546238, tar: 0.043048, time-per-iter: 0.084139 s, time_read: 0.001924\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5520/ 7992, ite: 690] train loss: 0.546081, tar: 0.043013, time-per-iter: 0.086498 s, time_read: 0.001936\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5528/ 7992, ite: 691] train loss: 0.545969, tar: 0.042985, time-per-iter: 0.085678 s, time_read: 0.001867\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5536/ 7992, ite: 692] train loss: 0.545923, tar: 0.042968, time-per-iter: 0.085109 s, time_read: 0.001991\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5544/ 7992, ite: 693] train loss: 0.545823, tar: 0.042948, time-per-iter: 0.084626 s, time_read: 0.001738\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5552/ 7992, ite: 694] train loss: 0.545700, tar: 0.042917, time-per-iter: 0.082780 s, time_read: 0.001797\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5560/ 7992, ite: 695] train loss: 0.545592, tar: 0.042891, time-per-iter: 0.083366 s, time_read: 0.001907\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5568/ 7992, ite: 696] train loss: 0.545390, tar: 0.042850, time-per-iter: 0.082756 s, time_read: 0.001839\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5576/ 7992, ite: 697] train loss: 0.545208, tar: 0.042816, time-per-iter: 0.083988 s, time_read: 0.001686\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5584/ 7992, ite: 698] train loss: 0.545225, tar: 0.042832, time-per-iter: 0.083839 s, time_read: 0.001844\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5592/ 7992, ite: 699] train loss: 0.545073, tar: 0.042805, time-per-iter: 0.083933 s, time_read: 0.001779\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5600/ 7992, ite: 700] train loss: 0.544920, tar: 0.042780, time-per-iter: 0.083602 s, time_read: 0.001989\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5608/ 7992, ite: 701] train loss: 0.544830, tar: 0.042768, time-per-iter: 0.083907 s, time_read: 0.001845\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5616/ 7992, ite: 702] train loss: 0.544675, tar: 0.042742, time-per-iter: 0.083769 s, time_read: 0.001720\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5624/ 7992, ite: 703] train loss: 0.544542, tar: 0.042716, time-per-iter: 0.084194 s, time_read: 0.001887\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5632/ 7992, ite: 704] train loss: 0.544390, tar: 0.042687, time-per-iter: 0.083503 s, time_read: 0.001904\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5640/ 7992, ite: 705] train loss: 0.544391, tar: 0.042683, time-per-iter: 0.083350 s, time_read: 0.001702\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5648/ 7992, ite: 706] train loss: 0.544309, tar: 0.042677, time-per-iter: 0.083805 s, time_read: 0.001755\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5656/ 7992, ite: 707] train loss: 0.544211, tar: 0.042660, time-per-iter: 0.083915 s, time_read: 0.001911\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5664/ 7992, ite: 708] train loss: 0.544136, tar: 0.042651, time-per-iter: 0.083157 s, time_read: 0.001880\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5672/ 7992, ite: 709] train loss: 0.543988, tar: 0.042612, time-per-iter: 0.082191 s, time_read: 0.001678\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5680/ 7992, ite: 710] train loss: 0.543775, tar: 0.042573, time-per-iter: 0.082689 s, time_read: 0.001855\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5688/ 7992, ite: 711] train loss: 0.543733, tar: 0.042561, time-per-iter: 0.083972 s, time_read: 0.001837\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5696/ 7992, ite: 712] train loss: 0.543630, tar: 0.042545, time-per-iter: 0.083575 s, time_read: 0.001885\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5704/ 7992, ite: 713] train loss: 0.543621, tar: 0.042539, time-per-iter: 0.081783 s, time_read: 0.001844\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5712/ 7992, ite: 714] train loss: 0.543609, tar: 0.042550, time-per-iter: 0.080262 s, time_read: 0.001693\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5720/ 7992, ite: 715] train loss: 0.543572, tar: 0.042542, time-per-iter: 0.082297 s, time_read: 0.001958\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5728/ 7992, ite: 716] train loss: 0.543485, tar: 0.042522, time-per-iter: 0.083586 s, time_read: 0.001963\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5736/ 7992, ite: 717] train loss: 0.543365, tar: 0.042496, time-per-iter: 0.083756 s, time_read: 0.001718\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5744/ 7992, ite: 718] train loss: 0.543259, tar: 0.042470, time-per-iter: 0.081553 s, time_read: 0.001697\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5752/ 7992, ite: 719] train loss: 0.543132, tar: 0.042444, time-per-iter: 0.082162 s, time_read: 0.001934\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5760/ 7992, ite: 720] train loss: 0.543165, tar: 0.042443, time-per-iter: 0.083470 s, time_read: 0.001854\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5768/ 7992, ite: 721] train loss: 0.543156, tar: 0.042439, time-per-iter: 0.083872 s, time_read: 0.001737\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5776/ 7992, ite: 722] train loss: 0.543143, tar: 0.042430, time-per-iter: 0.082998 s, time_read: 0.001735\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5784/ 7992, ite: 723] train loss: 0.542975, tar: 0.042398, time-per-iter: 0.082729 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5792/ 7992, ite: 724] train loss: 0.542881, tar: 0.042376, time-per-iter: 0.083831 s, time_read: 0.002094\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5800/ 7992, ite: 725] train loss: 0.542787, tar: 0.042355, time-per-iter: 0.083758 s, time_read: 0.002215\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5808/ 7992, ite: 726] train loss: 0.542707, tar: 0.042333, time-per-iter: 0.083546 s, time_read: 0.001831\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5816/ 7992, ite: 727] train loss: 0.542728, tar: 0.042337, time-per-iter: 0.083008 s, time_read: 0.001880\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5824/ 7992, ite: 728] train loss: 0.542621, tar: 0.042320, time-per-iter: 0.081616 s, time_read: 0.001918\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5832/ 7992, ite: 729] train loss: 0.542492, tar: 0.042288, time-per-iter: 0.083173 s, time_read: 0.001806\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5840/ 7992, ite: 730] train loss: 0.542360, tar: 0.042260, time-per-iter: 0.083400 s, time_read: 0.001815\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5848/ 7992, ite: 731] train loss: 0.542253, tar: 0.042232, time-per-iter: 0.081635 s, time_read: 0.001900\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5856/ 7992, ite: 732] train loss: 0.542110, tar: 0.042206, time-per-iter: 0.080764 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5864/ 7992, ite: 733] train loss: 0.542060, tar: 0.042196, time-per-iter: 0.082581 s, time_read: 0.001700\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5872/ 7992, ite: 734] train loss: 0.541932, tar: 0.042162, time-per-iter: 0.083151 s, time_read: 0.001880\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5880/ 7992, ite: 735] train loss: 0.541809, tar: 0.042133, time-per-iter: 0.083127 s, time_read: 0.001855\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5888/ 7992, ite: 736] train loss: 0.541637, tar: 0.042101, time-per-iter: 0.083279 s, time_read: 0.001862\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5896/ 7992, ite: 737] train loss: 0.541518, tar: 0.042073, time-per-iter: 0.081796 s, time_read: 0.001709\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5904/ 7992, ite: 738] train loss: 0.541411, tar: 0.042048, time-per-iter: 0.082059 s, time_read: 0.001752\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5912/ 7992, ite: 739] train loss: 0.541225, tar: 0.042015, time-per-iter: 0.082758 s, time_read: 0.001906\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5920/ 7992, ite: 740] train loss: 0.541150, tar: 0.042010, time-per-iter: 0.082565 s, time_read: 0.002066\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5928/ 7992, ite: 741] train loss: 0.541008, tar: 0.041981, time-per-iter: 0.083138 s, time_read: 0.001819\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5936/ 7992, ite: 742] train loss: 0.540893, tar: 0.041958, time-per-iter: 0.082566 s, time_read: 0.001655\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5944/ 7992, ite: 743] train loss: 0.540850, tar: 0.041942, time-per-iter: 0.083117 s, time_read: 0.001950\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5952/ 7992, ite: 744] train loss: 0.540732, tar: 0.041910, time-per-iter: 0.082184 s, time_read: 0.001845\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5960/ 7992, ite: 745] train loss: 0.540607, tar: 0.041896, time-per-iter: 0.083921 s, time_read: 0.001720\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5968/ 7992, ite: 746] train loss: 0.540494, tar: 0.041881, time-per-iter: 0.083847 s, time_read: 0.001888\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5976/ 7992, ite: 747] train loss: 0.540366, tar: 0.041858, time-per-iter: 0.083066 s, time_read: 0.001739\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5984/ 7992, ite: 748] train loss: 0.540249, tar: 0.041841, time-per-iter: 0.082381 s, time_read: 0.001821\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  5992/ 7992, ite: 749] train loss: 0.540152, tar: 0.041816, time-per-iter: 0.083367 s, time_read: 0.001833\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6000/ 7992, ite: 750] train loss: 0.540078, tar: 0.041796, time-per-iter: 0.083238 s, time_read: 0.001623\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6008/ 7992, ite: 751] train loss: 0.539951, tar: 0.041772, time-per-iter: 0.084162 s, time_read: 0.001804\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6016/ 7992, ite: 752] train loss: 0.539917, tar: 0.041759, time-per-iter: 0.083003 s, time_read: 0.001940\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6024/ 7992, ite: 753] train loss: 0.539788, tar: 0.041734, time-per-iter: 0.082398 s, time_read: 0.001699\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6032/ 7992, ite: 754] train loss: 0.539673, tar: 0.041710, time-per-iter: 0.083406 s, time_read: 0.001817\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6040/ 7992, ite: 755] train loss: 0.539569, tar: 0.041680, time-per-iter: 0.083978 s, time_read: 0.001880\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6048/ 7992, ite: 756] train loss: 0.539431, tar: 0.041653, time-per-iter: 0.084656 s, time_read: 0.001805\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6056/ 7992, ite: 757] train loss: 0.539293, tar: 0.041618, time-per-iter: 0.083013 s, time_read: 0.001717\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6064/ 7992, ite: 758] train loss: 0.539366, tar: 0.041635, time-per-iter: 0.083368 s, time_read: 0.001796\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6072/ 7992, ite: 759] train loss: 0.539268, tar: 0.041607, time-per-iter: 0.084054 s, time_read: 0.001860\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6080/ 7992, ite: 760] train loss: 0.539141, tar: 0.041580, time-per-iter: 0.084003 s, time_read: 0.001753\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6088/ 7992, ite: 761] train loss: 0.539030, tar: 0.041561, time-per-iter: 0.083034 s, time_read: 0.001798\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6096/ 7992, ite: 762] train loss: 0.538928, tar: 0.041544, time-per-iter: 0.081610 s, time_read: 0.001684\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6104/ 7992, ite: 763] train loss: 0.538757, tar: 0.041515, time-per-iter: 0.083601 s, time_read: 0.001781\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6112/ 7992, ite: 764] train loss: 0.538663, tar: 0.041497, time-per-iter: 0.084268 s, time_read: 0.001888\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6120/ 7992, ite: 765] train loss: 0.538597, tar: 0.041478, time-per-iter: 0.083244 s, time_read: 0.001747\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6128/ 7992, ite: 766] train loss: 0.538748, tar: 0.041497, time-per-iter: 0.082373 s, time_read: 0.001671\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6136/ 7992, ite: 767] train loss: 0.538624, tar: 0.041466, time-per-iter: 0.082622 s, time_read: 0.001966\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6144/ 7992, ite: 768] train loss: 0.538503, tar: 0.041443, time-per-iter: 0.083310 s, time_read: 0.001819\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6152/ 7992, ite: 769] train loss: 0.538441, tar: 0.041431, time-per-iter: 0.084352 s, time_read: 0.001758\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6160/ 7992, ite: 770] train loss: 0.538384, tar: 0.041419, time-per-iter: 0.084127 s, time_read: 0.001742\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6168/ 7992, ite: 771] train loss: 0.538311, tar: 0.041397, time-per-iter: 0.082273 s, time_read: 0.001775\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6176/ 7992, ite: 772] train loss: 0.538252, tar: 0.041383, time-per-iter: 0.082013 s, time_read: 0.001860\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6184/ 7992, ite: 773] train loss: 0.538106, tar: 0.041358, time-per-iter: 0.083811 s, time_read: 0.001828\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6192/ 7992, ite: 774] train loss: 0.538045, tar: 0.041335, time-per-iter: 0.082712 s, time_read: 0.001741\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6200/ 7992, ite: 775] train loss: 0.537976, tar: 0.041314, time-per-iter: 0.083669 s, time_read: 0.001802\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6208/ 7992, ite: 776] train loss: 0.537863, tar: 0.041290, time-per-iter: 0.083132 s, time_read: 0.001920\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6216/ 7992, ite: 777] train loss: 0.537772, tar: 0.041269, time-per-iter: 0.082844 s, time_read: 0.001909\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6224/ 7992, ite: 778] train loss: 0.537611, tar: 0.041238, time-per-iter: 0.083611 s, time_read: 0.001829\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6232/ 7992, ite: 779] train loss: 0.537463, tar: 0.041212, time-per-iter: 0.083445 s, time_read: 0.001878\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6240/ 7992, ite: 780] train loss: 0.537372, tar: 0.041199, time-per-iter: 0.083306 s, time_read: 0.001786\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6248/ 7992, ite: 781] train loss: 0.537280, tar: 0.041182, time-per-iter: 0.082952 s, time_read: 0.001730\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6256/ 7992, ite: 782] train loss: 0.537202, tar: 0.041162, time-per-iter: 0.082933 s, time_read: 0.001756\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6264/ 7992, ite: 783] train loss: 0.537236, tar: 0.041167, time-per-iter: 0.083299 s, time_read: 0.001940\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6272/ 7992, ite: 784] train loss: 0.537137, tar: 0.041151, time-per-iter: 0.083845 s, time_read: 0.002291\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6280/ 7992, ite: 785] train loss: 0.537061, tar: 0.041132, time-per-iter: 0.083862 s, time_read: 0.001882\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6288/ 7992, ite: 786] train loss: 0.536997, tar: 0.041114, time-per-iter: 0.084131 s, time_read: 0.001681\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6296/ 7992, ite: 787] train loss: 0.536891, tar: 0.041093, time-per-iter: 0.083683 s, time_read: 0.001875\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6304/ 7992, ite: 788] train loss: 0.536734, tar: 0.041071, time-per-iter: 0.083844 s, time_read: 0.001926\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6312/ 7992, ite: 789] train loss: 0.536712, tar: 0.041061, time-per-iter: 0.083777 s, time_read: 0.001727\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6320/ 7992, ite: 790] train loss: 0.536625, tar: 0.041042, time-per-iter: 0.083020 s, time_read: 0.001746\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6328/ 7992, ite: 791] train loss: 0.536477, tar: 0.041019, time-per-iter: 0.084892 s, time_read: 0.001953\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6336/ 7992, ite: 792] train loss: 0.536355, tar: 0.041002, time-per-iter: 0.084002 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6344/ 7992, ite: 793] train loss: 0.536311, tar: 0.040998, time-per-iter: 0.082818 s, time_read: 0.001754\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6352/ 7992, ite: 794] train loss: 0.536209, tar: 0.040982, time-per-iter: 0.084000 s, time_read: 0.001794\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6360/ 7992, ite: 795] train loss: 0.536121, tar: 0.040966, time-per-iter: 0.084083 s, time_read: 0.001880\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6368/ 7992, ite: 796] train loss: 0.536069, tar: 0.040961, time-per-iter: 0.083460 s, time_read: 0.001836\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6376/ 7992, ite: 797] train loss: 0.535975, tar: 0.040950, time-per-iter: 0.083296 s, time_read: 0.001686\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6384/ 7992, ite: 798] train loss: 0.535903, tar: 0.040929, time-per-iter: 0.082911 s, time_read: 0.001738\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6392/ 7992, ite: 799] train loss: 0.535824, tar: 0.040914, time-per-iter: 0.083764 s, time_read: 0.001895\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6400/ 7992, ite: 800] train loss: 0.535715, tar: 0.040895, time-per-iter: 0.083473 s, time_read: 0.002502\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6408/ 7992, ite: 801] train loss: 0.535585, tar: 0.040872, time-per-iter: 0.083863 s, time_read: 0.001761\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6416/ 7992, ite: 802] train loss: 0.535578, tar: 0.040872, time-per-iter: 0.083696 s, time_read: 0.001735\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6424/ 7992, ite: 803] train loss: 0.535547, tar: 0.040868, time-per-iter: 0.083340 s, time_read: 0.001955\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6432/ 7992, ite: 804] train loss: 0.535511, tar: 0.040855, time-per-iter: 0.083821 s, time_read: 0.001758\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6440/ 7992, ite: 805] train loss: 0.535360, tar: 0.040823, time-per-iter: 0.083146 s, time_read: 0.001752\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6448/ 7992, ite: 806] train loss: 0.535310, tar: 0.040808, time-per-iter: 0.083015 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6456/ 7992, ite: 807] train loss: 0.535229, tar: 0.040790, time-per-iter: 0.083761 s, time_read: 0.001967\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6464/ 7992, ite: 808] train loss: 0.535143, tar: 0.040774, time-per-iter: 0.083342 s, time_read: 0.002387\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6472/ 7992, ite: 809] train loss: 0.535075, tar: 0.040757, time-per-iter: 0.083340 s, time_read: 0.001870\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6480/ 7992, ite: 810] train loss: 0.534978, tar: 0.040733, time-per-iter: 0.083499 s, time_read: 0.001692\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6488/ 7992, ite: 811] train loss: 0.534877, tar: 0.040712, time-per-iter: 0.084177 s, time_read: 0.001785\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6496/ 7992, ite: 812] train loss: 0.534760, tar: 0.040689, time-per-iter: 0.084086 s, time_read: 0.001944\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6504/ 7992, ite: 813] train loss: 0.534679, tar: 0.040660, time-per-iter: 0.084171 s, time_read: 0.001680\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6512/ 7992, ite: 814] train loss: 0.534532, tar: 0.040630, time-per-iter: 0.082762 s, time_read: 0.001731\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6520/ 7992, ite: 815] train loss: 0.534447, tar: 0.040614, time-per-iter: 0.084047 s, time_read: 0.001990\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6528/ 7992, ite: 816] train loss: 0.534321, tar: 0.040593, time-per-iter: 0.083125 s, time_read: 0.001868\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6536/ 7992, ite: 817] train loss: 0.534208, tar: 0.040576, time-per-iter: 0.083327 s, time_read: 0.001768\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6544/ 7992, ite: 818] train loss: 0.534068, tar: 0.040546, time-per-iter: 0.083930 s, time_read: 0.001893\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6552/ 7992, ite: 819] train loss: 0.533943, tar: 0.040519, time-per-iter: 0.084687 s, time_read: 0.002069\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6560/ 7992, ite: 820] train loss: 0.533857, tar: 0.040499, time-per-iter: 0.082731 s, time_read: 0.001900\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6568/ 7992, ite: 821] train loss: 0.533755, tar: 0.040474, time-per-iter: 0.083293 s, time_read: 0.001898\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6576/ 7992, ite: 822] train loss: 0.533609, tar: 0.040446, time-per-iter: 0.083120 s, time_read: 0.001736\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6584/ 7992, ite: 823] train loss: 0.533464, tar: 0.040420, time-per-iter: 0.083887 s, time_read: 0.001779\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6592/ 7992, ite: 824] train loss: 0.533325, tar: 0.040391, time-per-iter: 0.082294 s, time_read: 0.001839\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6600/ 7992, ite: 825] train loss: 0.533203, tar: 0.040366, time-per-iter: 0.082798 s, time_read: 0.001658\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6608/ 7992, ite: 826] train loss: 0.533150, tar: 0.040343, time-per-iter: 0.082822 s, time_read: 0.001606\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6616/ 7992, ite: 827] train loss: 0.533147, tar: 0.040339, time-per-iter: 0.082590 s, time_read: 0.001895\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6624/ 7992, ite: 828] train loss: 0.533131, tar: 0.040335, time-per-iter: 0.083093 s, time_read: 0.001929\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6632/ 7992, ite: 829] train loss: 0.533097, tar: 0.040320, time-per-iter: 0.083129 s, time_read: 0.001814\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6640/ 7992, ite: 830] train loss: 0.532949, tar: 0.040295, time-per-iter: 0.083506 s, time_read: 0.001807\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6648/ 7992, ite: 831] train loss: 0.533008, tar: 0.040308, time-per-iter: 0.084424 s, time_read: 0.001820\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6656/ 7992, ite: 832] train loss: 0.532975, tar: 0.040295, time-per-iter: 0.083947 s, time_read: 0.001838\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6664/ 7992, ite: 833] train loss: 0.532897, tar: 0.040281, time-per-iter: 0.082904 s, time_read: 0.001812\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6672/ 7992, ite: 834] train loss: 0.532843, tar: 0.040273, time-per-iter: 0.081505 s, time_read: 0.001718\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6680/ 7992, ite: 835] train loss: 0.532750, tar: 0.040258, time-per-iter: 0.083773 s, time_read: 0.001822\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6688/ 7992, ite: 836] train loss: 0.532768, tar: 0.040260, time-per-iter: 0.084659 s, time_read: 0.001961\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6696/ 7992, ite: 837] train loss: 0.532625, tar: 0.040236, time-per-iter: 0.083483 s, time_read: 0.001965\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6704/ 7992, ite: 838] train loss: 0.532509, tar: 0.040218, time-per-iter: 0.084320 s, time_read: 0.001788\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6712/ 7992, ite: 839] train loss: 0.532445, tar: 0.040206, time-per-iter: 0.083081 s, time_read: 0.002551\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6720/ 7992, ite: 840] train loss: 0.532324, tar: 0.040183, time-per-iter: 0.082949 s, time_read: 0.001776\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6728/ 7992, ite: 841] train loss: 0.532235, tar: 0.040159, time-per-iter: 0.082841 s, time_read: 0.001795\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6736/ 7992, ite: 842] train loss: 0.532198, tar: 0.040153, time-per-iter: 0.081582 s, time_read: 0.001897\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6744/ 7992, ite: 843] train loss: 0.532156, tar: 0.040139, time-per-iter: 0.080259 s, time_read: 0.001785\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6752/ 7992, ite: 844] train loss: 0.532070, tar: 0.040129, time-per-iter: 0.080808 s, time_read: 0.001755\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6760/ 7992, ite: 845] train loss: 0.532088, tar: 0.040128, time-per-iter: 0.081342 s, time_read: 0.001935\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6768/ 7992, ite: 846] train loss: 0.531995, tar: 0.040113, time-per-iter: 0.081094 s, time_read: 0.001859\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6776/ 7992, ite: 847] train loss: 0.531882, tar: 0.040095, time-per-iter: 0.082215 s, time_read: 0.001799\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6784/ 7992, ite: 848] train loss: 0.531769, tar: 0.040072, time-per-iter: 0.079550 s, time_read: 0.001994\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6792/ 7992, ite: 849] train loss: 0.531705, tar: 0.040056, time-per-iter: 0.080930 s, time_read: 0.001735\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6800/ 7992, ite: 850] train loss: 0.531609, tar: 0.040037, time-per-iter: 0.081924 s, time_read: 0.001821\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6808/ 7992, ite: 851] train loss: 0.531482, tar: 0.040008, time-per-iter: 0.081173 s, time_read: 0.001850\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6816/ 7992, ite: 852] train loss: 0.531378, tar: 0.039985, time-per-iter: 0.081460 s, time_read: 0.001955\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6824/ 7992, ite: 853] train loss: 0.531274, tar: 0.039962, time-per-iter: 0.079922 s, time_read: 0.001704\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6832/ 7992, ite: 854] train loss: 0.531143, tar: 0.039933, time-per-iter: 0.081090 s, time_read: 0.001840\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6840/ 7992, ite: 855] train loss: 0.531028, tar: 0.039904, time-per-iter: 0.081735 s, time_read: 0.001798\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6848/ 7992, ite: 856] train loss: 0.530903, tar: 0.039879, time-per-iter: 0.082410 s, time_read: 0.001902\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6856/ 7992, ite: 857] train loss: 0.530823, tar: 0.039864, time-per-iter: 0.081173 s, time_read: 0.001819\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6864/ 7992, ite: 858] train loss: 0.530752, tar: 0.039860, time-per-iter: 0.078499 s, time_read: 0.001881\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6872/ 7992, ite: 859] train loss: 0.530630, tar: 0.039831, time-per-iter: 0.081791 s, time_read: 0.001880\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6880/ 7992, ite: 860] train loss: 0.530511, tar: 0.039805, time-per-iter: 0.081378 s, time_read: 0.001992\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6888/ 7992, ite: 861] train loss: 0.530401, tar: 0.039786, time-per-iter: 0.081363 s, time_read: 0.001862\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6896/ 7992, ite: 862] train loss: 0.530276, tar: 0.039758, time-per-iter: 0.081410 s, time_read: 0.001892\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6904/ 7992, ite: 863] train loss: 0.530241, tar: 0.039755, time-per-iter: 0.081739 s, time_read: 0.001883\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6912/ 7992, ite: 864] train loss: 0.530189, tar: 0.039739, time-per-iter: 0.081166 s, time_read: 0.001896\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6920/ 7992, ite: 865] train loss: 0.530086, tar: 0.039712, time-per-iter: 0.081797 s, time_read: 0.001876\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6928/ 7992, ite: 866] train loss: 0.529969, tar: 0.039684, time-per-iter: 0.081266 s, time_read: 0.001878\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6936/ 7992, ite: 867] train loss: 0.529847, tar: 0.039660, time-per-iter: 0.081293 s, time_read: 0.001874\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6944/ 7992, ite: 868] train loss: 0.529757, tar: 0.039644, time-per-iter: 0.081780 s, time_read: 0.001930\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6952/ 7992, ite: 869] train loss: 0.529713, tar: 0.039636, time-per-iter: 0.081149 s, time_read: 0.001882\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6960/ 7992, ite: 870] train loss: 0.529717, tar: 0.039637, time-per-iter: 0.080384 s, time_read: 0.001925\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6968/ 7992, ite: 871] train loss: 0.529663, tar: 0.039618, time-per-iter: 0.080796 s, time_read: 0.001904\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6976/ 7992, ite: 872] train loss: 0.529599, tar: 0.039594, time-per-iter: 0.080974 s, time_read: 0.001987\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6984/ 7992, ite: 873] train loss: 0.529486, tar: 0.039565, time-per-iter: 0.080519 s, time_read: 0.001734\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  6992/ 7992, ite: 874] train loss: 0.529387, tar: 0.039548, time-per-iter: 0.080048 s, time_read: 0.001770\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7000/ 7992, ite: 875] train loss: 0.529318, tar: 0.039535, time-per-iter: 0.081186 s, time_read: 0.001822\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7008/ 7992, ite: 876] train loss: 0.529220, tar: 0.039510, time-per-iter: 0.081266 s, time_read: 0.001932\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7016/ 7992, ite: 877] train loss: 0.529133, tar: 0.039495, time-per-iter: 0.081481 s, time_read: 0.001830\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7024/ 7992, ite: 878] train loss: 0.529030, tar: 0.039468, time-per-iter: 0.080302 s, time_read: 0.001835\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7032/ 7992, ite: 879] train loss: 0.528956, tar: 0.039448, time-per-iter: 0.081210 s, time_read: 0.001899\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7040/ 7992, ite: 880] train loss: 0.528964, tar: 0.039447, time-per-iter: 0.081640 s, time_read: 0.001921\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7048/ 7992, ite: 881] train loss: 0.528937, tar: 0.039436, time-per-iter: 0.081431 s, time_read: 0.001744\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7056/ 7992, ite: 882] train loss: 0.528831, tar: 0.039412, time-per-iter: 0.081630 s, time_read: 0.001711\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7064/ 7992, ite: 883] train loss: 0.528748, tar: 0.039387, time-per-iter: 0.081385 s, time_read: 0.001879\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7072/ 7992, ite: 884] train loss: 0.528640, tar: 0.039360, time-per-iter: 0.080613 s, time_read: 0.001826\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7080/ 7992, ite: 885] train loss: 0.528501, tar: 0.039331, time-per-iter: 0.082011 s, time_read: 0.001778\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7088/ 7992, ite: 886] train loss: 0.528451, tar: 0.039327, time-per-iter: 0.082678 s, time_read: 0.001823\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7096/ 7992, ite: 887] train loss: 0.528340, tar: 0.039303, time-per-iter: 0.081118 s, time_read: 0.001945\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7104/ 7992, ite: 888] train loss: 0.528323, tar: 0.039300, time-per-iter: 0.078981 s, time_read: 0.001810\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7112/ 7992, ite: 889] train loss: 0.528210, tar: 0.039283, time-per-iter: 0.080596 s, time_read: 0.001713\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7120/ 7992, ite: 890] train loss: 0.528077, tar: 0.039259, time-per-iter: 0.081669 s, time_read: 0.001923\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7128/ 7992, ite: 891] train loss: 0.527966, tar: 0.039238, time-per-iter: 0.081179 s, time_read: 0.001800\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7136/ 7992, ite: 892] train loss: 0.527880, tar: 0.039215, time-per-iter: 0.081346 s, time_read: 0.001743\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7144/ 7992, ite: 893] train loss: 0.527789, tar: 0.039195, time-per-iter: 0.080231 s, time_read: 0.001845\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7152/ 7992, ite: 894] train loss: 0.527802, tar: 0.039196, time-per-iter: 0.080647 s, time_read: 0.001771\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7160/ 7992, ite: 895] train loss: 0.527710, tar: 0.039171, time-per-iter: 0.081998 s, time_read: 0.001943\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7168/ 7992, ite: 896] train loss: 0.527600, tar: 0.039152, time-per-iter: 0.082694 s, time_read: 0.001977\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7176/ 7992, ite: 897] train loss: 0.527528, tar: 0.039128, time-per-iter: 0.082478 s, time_read: 0.001906\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7184/ 7992, ite: 898] train loss: 0.527441, tar: 0.039113, time-per-iter: 0.081609 s, time_read: 0.001795\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7192/ 7992, ite: 899] train loss: 0.527410, tar: 0.039109, time-per-iter: 0.082484 s, time_read: 0.001960\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7200/ 7992, ite: 900] train loss: 0.527323, tar: 0.039089, time-per-iter: 0.082030 s, time_read: 0.001938\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7208/ 7992, ite: 901] train loss: 0.527265, tar: 0.039069, time-per-iter: 0.083002 s, time_read: 0.001891\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7216/ 7992, ite: 902] train loss: 0.527257, tar: 0.039060, time-per-iter: 0.080651 s, time_read: 0.001730\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7224/ 7992, ite: 903] train loss: 0.527160, tar: 0.039049, time-per-iter: 0.081533 s, time_read: 0.001792\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7232/ 7992, ite: 904] train loss: 0.527121, tar: 0.039039, time-per-iter: 0.082077 s, time_read: 0.001864\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7240/ 7992, ite: 905] train loss: 0.527018, tar: 0.039017, time-per-iter: 0.082643 s, time_read: 0.001823\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7248/ 7992, ite: 906] train loss: 0.526954, tar: 0.039001, time-per-iter: 0.082221 s, time_read: 0.001811\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7256/ 7992, ite: 907] train loss: 0.526839, tar: 0.038986, time-per-iter: 0.081938 s, time_read: 0.001779\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7264/ 7992, ite: 908] train loss: 0.526784, tar: 0.038976, time-per-iter: 0.080882 s, time_read: 0.001910\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7272/ 7992, ite: 909] train loss: 0.526659, tar: 0.038952, time-per-iter: 0.081101 s, time_read: 0.001731\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7280/ 7992, ite: 910] train loss: 0.526578, tar: 0.038933, time-per-iter: 0.081260 s, time_read: 0.001830\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7288/ 7992, ite: 911] train loss: 0.526533, tar: 0.038926, time-per-iter: 0.081950 s, time_read: 0.002078\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7296/ 7992, ite: 912] train loss: 0.526506, tar: 0.038910, time-per-iter: 0.079281 s, time_read: 0.001850\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7304/ 7992, ite: 913] train loss: 0.526398, tar: 0.038890, time-per-iter: 0.081370 s, time_read: 0.001769\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7312/ 7992, ite: 914] train loss: 0.526273, tar: 0.038867, time-per-iter: 0.082206 s, time_read: 0.001972\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7320/ 7992, ite: 915] train loss: 0.526237, tar: 0.038862, time-per-iter: 0.081912 s, time_read: 0.001847\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7328/ 7992, ite: 916] train loss: 0.526131, tar: 0.038837, time-per-iter: 0.080873 s, time_read: 0.001851\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7336/ 7992, ite: 917] train loss: 0.526066, tar: 0.038817, time-per-iter: 0.079989 s, time_read: 0.001915\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7344/ 7992, ite: 918] train loss: 0.525987, tar: 0.038805, time-per-iter: 0.081187 s, time_read: 0.001858\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7352/ 7992, ite: 919] train loss: 0.525863, tar: 0.038779, time-per-iter: 0.081471 s, time_read: 0.001937\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7360/ 7992, ite: 920] train loss: 0.525855, tar: 0.038770, time-per-iter: 0.081710 s, time_read: 0.001965\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7368/ 7992, ite: 921] train loss: 0.525781, tar: 0.038743, time-per-iter: 0.081014 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7376/ 7992, ite: 922] train loss: 0.525668, tar: 0.038718, time-per-iter: 0.080222 s, time_read: 0.001722\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7384/ 7992, ite: 923] train loss: 0.525589, tar: 0.038706, time-per-iter: 0.081665 s, time_read: 0.001955\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7392/ 7992, ite: 924] train loss: 0.525538, tar: 0.038689, time-per-iter: 0.081746 s, time_read: 0.001949\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7400/ 7992, ite: 925] train loss: 0.525593, tar: 0.038705, time-per-iter: 0.081771 s, time_read: 0.001727\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7408/ 7992, ite: 926] train loss: 0.525482, tar: 0.038680, time-per-iter: 0.081569 s, time_read: 0.001843\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7416/ 7992, ite: 927] train loss: 0.525385, tar: 0.038661, time-per-iter: 0.080903 s, time_read: 0.001930\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7424/ 7992, ite: 928] train loss: 0.525337, tar: 0.038652, time-per-iter: 0.081352 s, time_read: 0.001835\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7432/ 7992, ite: 929] train loss: 0.525204, tar: 0.038626, time-per-iter: 0.081852 s, time_read: 0.001861\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7440/ 7992, ite: 930] train loss: 0.525236, tar: 0.038629, time-per-iter: 0.081451 s, time_read: 0.001688\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7448/ 7992, ite: 931] train loss: 0.525112, tar: 0.038602, time-per-iter: 0.081572 s, time_read: 0.001886\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7456/ 7992, ite: 932] train loss: 0.525011, tar: 0.038579, time-per-iter: 0.081414 s, time_read: 0.002178\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7464/ 7992, ite: 933] train loss: 0.524983, tar: 0.038575, time-per-iter: 0.081501 s, time_read: 0.001769\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7472/ 7992, ite: 934] train loss: 0.524999, tar: 0.038574, time-per-iter: 0.082006 s, time_read: 0.001836\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7480/ 7992, ite: 935] train loss: 0.524969, tar: 0.038566, time-per-iter: 0.081429 s, time_read: 0.001934\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7488/ 7992, ite: 936] train loss: 0.524858, tar: 0.038548, time-per-iter: 0.081149 s, time_read: 0.002060\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7496/ 7992, ite: 937] train loss: 0.524787, tar: 0.038533, time-per-iter: 0.082412 s, time_read: 0.001820\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7504/ 7992, ite: 938] train loss: 0.524698, tar: 0.038516, time-per-iter: 0.081655 s, time_read: 0.001867\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7512/ 7992, ite: 939] train loss: 0.524667, tar: 0.038507, time-per-iter: 0.082427 s, time_read: 0.001950\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7520/ 7992, ite: 940] train loss: 0.524550, tar: 0.038486, time-per-iter: 0.080485 s, time_read: 0.001827\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7528/ 7992, ite: 941] train loss: 0.524458, tar: 0.038467, time-per-iter: 0.082799 s, time_read: 0.001925\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7536/ 7992, ite: 942] train loss: 0.524435, tar: 0.038458, time-per-iter: 0.081439 s, time_read: 0.001688\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7544/ 7992, ite: 943] train loss: 0.524310, tar: 0.038434, time-per-iter: 0.082610 s, time_read: 0.001911\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7552/ 7992, ite: 944] train loss: 0.524219, tar: 0.038411, time-per-iter: 0.081040 s, time_read: 0.001769\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7560/ 7992, ite: 945] train loss: 0.524105, tar: 0.038385, time-per-iter: 0.081780 s, time_read: 0.001900\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7568/ 7992, ite: 946] train loss: 0.524125, tar: 0.038384, time-per-iter: 0.080717 s, time_read: 0.001795\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7576/ 7992, ite: 947] train loss: 0.524048, tar: 0.038365, time-per-iter: 0.081778 s, time_read: 0.001975\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7584/ 7992, ite: 948] train loss: 0.523982, tar: 0.038351, time-per-iter: 0.081316 s, time_read: 0.001919\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7592/ 7992, ite: 949] train loss: 0.523928, tar: 0.038334, time-per-iter: 0.082039 s, time_read: 0.001774\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7600/ 7992, ite: 950] train loss: 0.523816, tar: 0.038308, time-per-iter: 0.081620 s, time_read: 0.001809\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7608/ 7992, ite: 951] train loss: 0.523725, tar: 0.038285, time-per-iter: 0.081527 s, time_read: 0.002037\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7616/ 7992, ite: 952] train loss: 0.523669, tar: 0.038264, time-per-iter: 0.080719 s, time_read: 0.001942\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7624/ 7992, ite: 953] train loss: 0.523578, tar: 0.038244, time-per-iter: 0.080377 s, time_read: 0.001918\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7632/ 7992, ite: 954] train loss: 0.523487, tar: 0.038223, time-per-iter: 0.082477 s, time_read: 0.001844\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7640/ 7992, ite: 955] train loss: 0.523388, tar: 0.038204, time-per-iter: 0.083114 s, time_read: 0.002008\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7648/ 7992, ite: 956] train loss: 0.523370, tar: 0.038196, time-per-iter: 0.084493 s, time_read: 0.001844\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7656/ 7992, ite: 957] train loss: 0.523274, tar: 0.038174, time-per-iter: 0.083313 s, time_read: 0.001755\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7664/ 7992, ite: 958] train loss: 0.523189, tar: 0.038160, time-per-iter: 0.084195 s, time_read: 0.001757\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7672/ 7992, ite: 959] train loss: 0.523115, tar: 0.038155, time-per-iter: 0.084433 s, time_read: 0.002117\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7680/ 7992, ite: 960] train loss: 0.523095, tar: 0.038142, time-per-iter: 0.084358 s, time_read: 0.001870\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7688/ 7992, ite: 961] train loss: 0.523031, tar: 0.038125, time-per-iter: 0.089317 s, time_read: 0.002454\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7696/ 7992, ite: 962] train loss: 0.522943, tar: 0.038103, time-per-iter: 0.086964 s, time_read: 0.001976\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7704/ 7992, ite: 963] train loss: 0.522913, tar: 0.038093, time-per-iter: 0.087265 s, time_read: 0.002168\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7712/ 7992, ite: 964] train loss: 0.522811, tar: 0.038077, time-per-iter: 0.087641 s, time_read: 0.002038\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7720/ 7992, ite: 965] train loss: 0.522746, tar: 0.038061, time-per-iter: 0.086287 s, time_read: 0.002116\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7728/ 7992, ite: 966] train loss: 0.522746, tar: 0.038057, time-per-iter: 0.083594 s, time_read: 0.002066\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7736/ 7992, ite: 967] train loss: 0.522604, tar: 0.038036, time-per-iter: 0.083759 s, time_read: 0.001722\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7744/ 7992, ite: 968] train loss: 0.522510, tar: 0.038013, time-per-iter: 0.084152 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7752/ 7992, ite: 969] train loss: 0.522491, tar: 0.038007, time-per-iter: 0.084332 s, time_read: 0.001702\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7760/ 7992, ite: 970] train loss: 0.522440, tar: 0.038000, time-per-iter: 0.083953 s, time_read: 0.001839\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7768/ 7992, ite: 971] train loss: 0.522353, tar: 0.037980, time-per-iter: 0.083283 s, time_read: 0.001683\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7776/ 7992, ite: 972] train loss: 0.522364, tar: 0.037974, time-per-iter: 0.083290 s, time_read: 0.001671\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7784/ 7992, ite: 973] train loss: 0.522312, tar: 0.037959, time-per-iter: 0.084153 s, time_read: 0.001631\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7792/ 7992, ite: 974] train loss: 0.522246, tar: 0.037938, time-per-iter: 0.084361 s, time_read: 0.001733\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7800/ 7992, ite: 975] train loss: 0.522191, tar: 0.037924, time-per-iter: 0.083457 s, time_read: 0.001654\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7808/ 7992, ite: 976] train loss: 0.522171, tar: 0.037913, time-per-iter: 0.082770 s, time_read: 0.001605\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7816/ 7992, ite: 977] train loss: 0.522021, tar: 0.037891, time-per-iter: 0.083805 s, time_read: 0.001809\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7824/ 7992, ite: 978] train loss: 0.521953, tar: 0.037877, time-per-iter: 0.083592 s, time_read: 0.001624\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7832/ 7992, ite: 979] train loss: 0.521891, tar: 0.037868, time-per-iter: 0.083086 s, time_read: 0.001794\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7840/ 7992, ite: 980] train loss: 0.521837, tar: 0.037850, time-per-iter: 0.081114 s, time_read: 0.001730\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7848/ 7992, ite: 981] train loss: 0.521786, tar: 0.037833, time-per-iter: 0.083127 s, time_read: 0.001619\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7856/ 7992, ite: 982] train loss: 0.521718, tar: 0.037815, time-per-iter: 0.084137 s, time_read: 0.001907\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7864/ 7992, ite: 983] train loss: 0.521647, tar: 0.037801, time-per-iter: 0.083576 s, time_read: 0.001990\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7872/ 7992, ite: 984] train loss: 0.521612, tar: 0.037794, time-per-iter: 0.082607 s, time_read: 0.001864\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7880/ 7992, ite: 985] train loss: 0.521527, tar: 0.037785, time-per-iter: 0.086401 s, time_read: 0.001746\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7888/ 7992, ite: 986] train loss: 0.521461, tar: 0.037771, time-per-iter: 0.086365 s, time_read: 0.002072\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7896/ 7992, ite: 987] train loss: 0.521378, tar: 0.037752, time-per-iter: 0.086205 s, time_read: 0.001994\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7904/ 7992, ite: 988] train loss: 0.521315, tar: 0.037738, time-per-iter: 0.084860 s, time_read: 0.001808\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7912/ 7992, ite: 989] train loss: 0.521230, tar: 0.037726, time-per-iter: 0.083565 s, time_read: 0.001817\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7920/ 7992, ite: 990] train loss: 0.521191, tar: 0.037720, time-per-iter: 0.083813 s, time_read: 0.001631\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7928/ 7992, ite: 991] train loss: 0.521127, tar: 0.037707, time-per-iter: 0.085120 s, time_read: 0.001827\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7936/ 7992, ite: 992] train loss: 0.521074, tar: 0.037698, time-per-iter: 0.083387 s, time_read: 0.002123\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7944/ 7992, ite: 993] train loss: 0.521058, tar: 0.037695, time-per-iter: 0.083200 s, time_read: 0.001683\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7952/ 7992, ite: 994] train loss: 0.520991, tar: 0.037679, time-per-iter: 0.081454 s, time_read: 0.001996\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7960/ 7992, ite: 995] train loss: 0.520907, tar: 0.037661, time-per-iter: 0.082053 s, time_read: 0.001957\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7968/ 7992, ite: 996] train loss: 0.520887, tar: 0.037660, time-per-iter: 0.082473 s, time_read: 0.001798\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7976/ 7992, ite: 997] train loss: 0.520862, tar: 0.037649, time-per-iter: 0.081274 s, time_read: 0.001792\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7984/ 7992, ite: 998] train loss: 0.520794, tar: 0.037635, time-per-iter: 0.081181 s, time_read: 0.001757\n",
      ">>>IS-Net-test - [epoch:   1/2000, batch:  7992/ 7992, ite: 999] train loss: 0.520760, tar: 0.037621, time-per-iter: 0.080772 s, time_read: 0.001752\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:     8/ 7992, ite: 1000] train loss: 0.520732, tar: 0.037624, time-per-iter: 0.253104 s, time_read: 0.157370\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    16/ 7992, ite: 1001] train loss: 0.520645, tar: 0.037602, time-per-iter: 0.084821 s, time_read: 0.001401\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    24/ 7992, ite: 1002] train loss: 0.520576, tar: 0.037583, time-per-iter: 0.085797 s, time_read: 0.004310\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    32/ 7992, ite: 1003] train loss: 0.520487, tar: 0.037566, time-per-iter: 0.083912 s, time_read: 0.002721\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    40/ 7992, ite: 1004] train loss: 0.520415, tar: 0.037553, time-per-iter: 0.080525 s, time_read: 0.001399\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    48/ 7992, ite: 1005] train loss: 0.520373, tar: 0.037542, time-per-iter: 0.079973 s, time_read: 0.000922\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    56/ 7992, ite: 1006] train loss: 0.520363, tar: 0.037533, time-per-iter: 0.080666 s, time_read: 0.000802\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    64/ 7992, ite: 1007] train loss: 0.520290, tar: 0.037510, time-per-iter: 0.081655 s, time_read: 0.001853\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    72/ 7992, ite: 1008] train loss: 0.520213, tar: 0.037495, time-per-iter: 0.080440 s, time_read: 0.000806\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    80/ 7992, ite: 1009] train loss: 0.520117, tar: 0.037478, time-per-iter: 0.081247 s, time_read: 0.002365\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    88/ 7992, ite: 1010] train loss: 0.520111, tar: 0.037479, time-per-iter: 0.079770 s, time_read: 0.001819\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:    96/ 7992, ite: 1011] train loss: 0.519998, tar: 0.037457, time-per-iter: 0.083519 s, time_read: 0.001760\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   104/ 7992, ite: 1012] train loss: 0.519925, tar: 0.037446, time-per-iter: 0.082357 s, time_read: 0.002109\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   112/ 7992, ite: 1013] train loss: 0.519827, tar: 0.037430, time-per-iter: 0.080476 s, time_read: 0.001868\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   120/ 7992, ite: 1014] train loss: 0.519782, tar: 0.037421, time-per-iter: 0.080506 s, time_read: 0.001680\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   128/ 7992, ite: 1015] train loss: 0.519684, tar: 0.037402, time-per-iter: 0.081890 s, time_read: 0.001803\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   136/ 7992, ite: 1016] train loss: 0.519606, tar: 0.037388, time-per-iter: 0.081643 s, time_read: 0.001836\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   144/ 7992, ite: 1017] train loss: 0.519602, tar: 0.037395, time-per-iter: 0.083464 s, time_read: 0.001820\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   152/ 7992, ite: 1018] train loss: 0.519511, tar: 0.037377, time-per-iter: 0.081885 s, time_read: 0.001728\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   160/ 7992, ite: 1019] train loss: 0.519439, tar: 0.037359, time-per-iter: 0.082461 s, time_read: 0.001904\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   168/ 7992, ite: 1020] train loss: 0.519357, tar: 0.037344, time-per-iter: 0.084223 s, time_read: 0.001704\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   176/ 7992, ite: 1021] train loss: 0.519348, tar: 0.037346, time-per-iter: 0.084806 s, time_read: 0.001936\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   184/ 7992, ite: 1022] train loss: 0.519242, tar: 0.037323, time-per-iter: 0.083076 s, time_read: 0.001939\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   192/ 7992, ite: 1023] train loss: 0.519238, tar: 0.037331, time-per-iter: 0.084477 s, time_read: 0.001789\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   200/ 7992, ite: 1024] train loss: 0.519185, tar: 0.037315, time-per-iter: 0.083322 s, time_read: 0.001998\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   208/ 7992, ite: 1025] train loss: 0.519116, tar: 0.037301, time-per-iter: 0.084260 s, time_read: 0.002216\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   216/ 7992, ite: 1026] train loss: 0.519024, tar: 0.037284, time-per-iter: 0.084892 s, time_read: 0.002148\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   224/ 7992, ite: 1027] train loss: 0.518975, tar: 0.037274, time-per-iter: 0.081815 s, time_read: 0.001782\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   232/ 7992, ite: 1028] train loss: 0.518936, tar: 0.037265, time-per-iter: 0.081419 s, time_read: 0.002074\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   240/ 7992, ite: 1029] train loss: 0.518884, tar: 0.037257, time-per-iter: 0.083051 s, time_read: 0.002520\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   248/ 7992, ite: 1030] train loss: 0.518810, tar: 0.037245, time-per-iter: 0.082491 s, time_read: 0.001704\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   256/ 7992, ite: 1031] train loss: 0.518752, tar: 0.037238, time-per-iter: 0.082705 s, time_read: 0.001983\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   264/ 7992, ite: 1032] train loss: 0.518701, tar: 0.037227, time-per-iter: 0.081527 s, time_read: 0.001876\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   272/ 7992, ite: 1033] train loss: 0.518619, tar: 0.037206, time-per-iter: 0.083608 s, time_read: 0.001871\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   280/ 7992, ite: 1034] train loss: 0.518559, tar: 0.037186, time-per-iter: 0.082390 s, time_read: 0.002038\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   288/ 7992, ite: 1035] train loss: 0.518577, tar: 0.037186, time-per-iter: 0.082257 s, time_read: 0.001766\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   296/ 7992, ite: 1036] train loss: 0.518489, tar: 0.037167, time-per-iter: 0.080750 s, time_read: 0.001788\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   304/ 7992, ite: 1037] train loss: 0.518520, tar: 0.037166, time-per-iter: 0.080122 s, time_read: 0.001904\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   312/ 7992, ite: 1038] train loss: 0.518405, tar: 0.037144, time-per-iter: 0.080865 s, time_read: 0.001765\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   320/ 7992, ite: 1039] train loss: 0.518327, tar: 0.037129, time-per-iter: 0.081584 s, time_read: 0.001777\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   328/ 7992, ite: 1040] train loss: 0.518218, tar: 0.037107, time-per-iter: 0.081628 s, time_read: 0.001747\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   336/ 7992, ite: 1041] train loss: 0.518176, tar: 0.037097, time-per-iter: 0.080255 s, time_read: 0.001846\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   344/ 7992, ite: 1042] train loss: 0.518107, tar: 0.037086, time-per-iter: 0.080653 s, time_read: 0.001760\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   352/ 7992, ite: 1043] train loss: 0.518026, tar: 0.037065, time-per-iter: 0.081630 s, time_read: 0.001804\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   360/ 7992, ite: 1044] train loss: 0.517956, tar: 0.037045, time-per-iter: 0.081534 s, time_read: 0.001744\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   368/ 7992, ite: 1045] train loss: 0.517880, tar: 0.037025, time-per-iter: 0.081592 s, time_read: 0.001830\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   376/ 7992, ite: 1046] train loss: 0.517775, tar: 0.037009, time-per-iter: 0.080259 s, time_read: 0.001866\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   384/ 7992, ite: 1047] train loss: 0.517802, tar: 0.037018, time-per-iter: 0.082937 s, time_read: 0.001788\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   392/ 7992, ite: 1048] train loss: 0.517783, tar: 0.037017, time-per-iter: 0.084020 s, time_read: 0.001954\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   400/ 7992, ite: 1049] train loss: 0.517681, tar: 0.037003, time-per-iter: 0.083617 s, time_read: 0.001979\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   408/ 7992, ite: 1050] train loss: 0.517623, tar: 0.036988, time-per-iter: 0.080958 s, time_read: 0.001882\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   416/ 7992, ite: 1051] train loss: 0.517512, tar: 0.036969, time-per-iter: 0.080571 s, time_read: 0.001787\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   424/ 7992, ite: 1052] train loss: 0.517494, tar: 0.036964, time-per-iter: 0.081640 s, time_read: 0.001888\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   432/ 7992, ite: 1053] train loss: 0.517455, tar: 0.036952, time-per-iter: 0.080504 s, time_read: 0.001827\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   440/ 7992, ite: 1054] train loss: 0.517371, tar: 0.036934, time-per-iter: 0.081061 s, time_read: 0.001770\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   448/ 7992, ite: 1055] train loss: 0.517299, tar: 0.036918, time-per-iter: 0.081089 s, time_read: 0.001967\n",
      ">>>IS-Net-test - [epoch:   2/2000, batch:   456/ 7992, ite: 1056] train loss: 0.517299, tar: 0.036915, time-per-iter: 0.081448 s, time_read: 0.001950\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import time\n",
    "\n",
    "import torch, gc\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data_loader_cache import get_im_gt_name_dict, create_dataloaders, GOSRandomHFlip, GOSResize, GOSRandomCrop, GOSNormalize #GOSDatasetCache,\n",
    "from basics import  f1_mae_torch #normPRED, GOSPRF1ScoresCache,f1score_torch,\n",
    "from models import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def get_gt_encoder(train_dataloaders, train_datasets, valid_dataloaders, valid_datasets, hypar, train_dataloaders_val, train_datasets_val): #model_path, model_save_fre, max_ite=1000000):\n",
    "\n",
    "    # train_dataloaders, train_datasets = create_dataloaders(train_nm_im_gt_list,\n",
    "    #                                                      cache_size = hypar[\"cache_size\"],\n",
    "    #                                                      cache_boost = hypar[\"cache_boost_train\"],\n",
    "    #                                                      my_transforms = [\n",
    "    #                                                                      GOSRandomHFlip(),\n",
    "    #                                                                      # GOSResize(hypar[\"input_size\"]),\n",
    "    #                                                                      # GOSRandomCrop(hypar[\"crop_size\"]),\n",
    "    #                                                                       GOSNormalize([0.5,0.5,0.5],[1.0,1.0,1.0]),\n",
    "    #                                                                       ],\n",
    "    #                                                      batch_size = hypar[\"batch_size_train\"],\n",
    "    #                                                      shuffle = True)\n",
    "\n",
    "    torch.manual_seed(hypar[\"seed\"])\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(hypar[\"seed\"])\n",
    "\n",
    "    print(\"define gt encoder ...\")\n",
    "    net = ISNetGTEncoder() #UNETGTENCODERCombine()\n",
    "    ## load the existing model gt encoder\n",
    "    if(hypar[\"gt_encoder_model\"]!=\"\"):\n",
    "        model_path = hypar[\"model_path\"]+\"/\"+hypar[\"gt_encoder_model\"]\n",
    "        if torch.cuda.is_available():\n",
    "            net.load_state_dict(torch.load(model_path))\n",
    "            net.cuda()\n",
    "        else:\n",
    "            net.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n",
    "        print(\"gt encoder restored from the saved weights ...\")\n",
    "        return net ############\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "\n",
    "    print(\"--- define optimizer for GT Encoder---\")\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "    model_path = hypar[\"model_path\"]\n",
    "    model_save_fre = hypar[\"model_save_fre\"]\n",
    "    max_ite = hypar[\"max_ite\"]\n",
    "    batch_size_train = hypar[\"batch_size_train\"]\n",
    "    batch_size_valid = hypar[\"batch_size_valid\"]\n",
    "\n",
    "    if(not os.path.exists(model_path)):\n",
    "        os.mkdir(model_path)\n",
    "\n",
    "    ite_num = hypar[\"start_ite\"] # count the total iteration number\n",
    "    ite_num4val = 0 #\n",
    "    running_loss = 0.0 # count the toal loss\n",
    "    running_tar_loss = 0.0 # count the target output loss\n",
    "    last_f1 = [0 for x in range(len(valid_dataloaders))]\n",
    "\n",
    "    train_num = train_datasets[0].__len__()\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    start_last = time.time()\n",
    "    gos_dataloader = train_dataloaders[0]\n",
    "    epoch_num = hypar[\"max_epoch_num\"]\n",
    "    notgood_cnt = 0\n",
    "    for epoch in range(epoch_num): ## set the epoch num as 100000\n",
    "\n",
    "        for i, data in enumerate(gos_dataloader):\n",
    "\n",
    "            if(ite_num >= max_ite):\n",
    "                print(\"Training Reached the Maximal Iteration Number \", max_ite)\n",
    "                exit()\n",
    "\n",
    "            # start_read = time.time()\n",
    "            ite_num = ite_num + 1\n",
    "            ite_num4val = ite_num4val + 1\n",
    "\n",
    "            # get the inputs\n",
    "            labels = data['label']\n",
    "\n",
    "            if(hypar[\"model_digit\"]==\"full\"):\n",
    "                labels = labels.type(torch.FloatTensor)\n",
    "            else:\n",
    "                labels = labels.type(torch.HalfTensor)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            if torch.cuda.is_available():\n",
    "                labels_v = Variable(labels.cuda(), requires_grad=False)\n",
    "            else:\n",
    "                labels_v = Variable(labels, requires_grad=False)\n",
    "\n",
    "            # print(\"time lapse for data preparation: \", time.time()-start_read, ' s')\n",
    "\n",
    "            # y zero the parameter gradients\n",
    "            start_inf_loss_back = time.time()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ds, fs = net(labels_v)#net(inputs_v)\n",
    "            loss2, loss = net.compute_loss(ds, labels_v)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_tar_loss += loss2.item()\n",
    "\n",
    "            # del outputs, loss\n",
    "            del ds, loss2, loss\n",
    "            end_inf_loss_back = time.time()-start_inf_loss_back\n",
    "\n",
    "            print(\"GT Encoder Training>>>\"+model_path.split('/')[-1]+\" - [epoch: %3d/%3d, batch: %5d/%5d, ite: %d] train loss: %3f, tar: %3f, time-per-iter: %3f s, time_read: %3f\" % (\n",
    "            epoch + 1, epoch_num, (i + 1) * batch_size_train, train_num, ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val, time.time()-start_last, time.time()-start_last-end_inf_loss_back))\n",
    "            start_last = time.time()\n",
    "\n",
    "            if ite_num % model_save_fre == 0:  # validate every 2000 iterations\n",
    "                notgood_cnt += 1\n",
    "                # net.eval()\n",
    "                # tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time = valid_gt_encoder(net, valid_dataloaders, valid_datasets, hypar, epoch)\n",
    "                tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time = valid_gt_encoder(net, train_dataloaders_val, train_datasets_val, hypar, epoch)\n",
    "\n",
    "                net.train()  # resume train\n",
    "\n",
    "                tmp_out = 0\n",
    "                print(\"last_f1:\",last_f1)\n",
    "                print(\"tmp_f1:\",tmp_f1)\n",
    "                for fi in range(len(last_f1)):\n",
    "                    if(tmp_f1[fi]>last_f1[fi]):\n",
    "                        tmp_out = 1\n",
    "                print(\"tmp_out:\",tmp_out)\n",
    "                if(tmp_out):\n",
    "                    notgood_cnt = 0\n",
    "                    last_f1 = tmp_f1\n",
    "                    tmp_f1_str = [str(round(f1x,4)) for f1x in tmp_f1]\n",
    "                    tmp_mae_str = [str(round(mx,4)) for mx in tmp_mae]\n",
    "                    maxf1 = '_'.join(tmp_f1_str)\n",
    "                    meanM = '_'.join(tmp_mae_str)\n",
    "                    # .cpu().detach().numpy()\n",
    "                    model_name = \"/GTENCODER-gpu_itr_\"+str(ite_num)+\\\n",
    "                                \"_traLoss_\"+str(np.round(running_loss / ite_num4val,4))+\\\n",
    "                                \"_traTarLoss_\"+str(np.round(running_tar_loss / ite_num4val,4))+\\\n",
    "                                \"_valLoss_\"+str(np.round(val_loss /(i_val+1),4))+\\\n",
    "                                \"_valTarLoss_\"+str(np.round(tar_loss /(i_val+1),4)) + \\\n",
    "                                \"_maxF1_\" + maxf1 + \\\n",
    "                                \"_mae_\" + meanM + \\\n",
    "                                \"_time_\" + str(np.round(np.mean(np.array(tmp_time))/batch_size_valid,6))+\".pth\"\n",
    "                    torch.save(net.state_dict(), model_path + model_name)\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_tar_loss = 0.0\n",
    "                ite_num4val = 0\n",
    "\n",
    "                if(tmp_f1[0]>0.99):\n",
    "                    print(\"GT encoder is well-trained and obtained...\")\n",
    "                    return net\n",
    "\n",
    "                if(notgood_cnt >= hypar[\"early_stop\"]):\n",
    "                    print(\"No improvements in the last \"+str(notgood_cnt)+\" validation periods, so training stopped !\")\n",
    "                    exit()\n",
    "\n",
    "    print(\"Training Reaches The Maximum Epoch Number\")\n",
    "    return net\n",
    "\n",
    "def valid_gt_encoder(net, valid_dataloaders, valid_datasets, hypar, epoch=0):\n",
    "    net.eval()\n",
    "    print(\"Validating...\")\n",
    "    epoch_num = hypar[\"max_epoch_num\"]\n",
    "\n",
    "    val_loss = 0.0\n",
    "    tar_loss = 0.0\n",
    "\n",
    "\n",
    "    tmp_f1 = []\n",
    "    tmp_mae = []\n",
    "    tmp_time = []\n",
    "\n",
    "    start_valid = time.time()\n",
    "    for k in range(len(valid_dataloaders)):\n",
    "\n",
    "        valid_dataloader = valid_dataloaders[k]\n",
    "        valid_dataset = valid_datasets[k]\n",
    "\n",
    "        val_num = valid_dataset.__len__()\n",
    "        mybins = np.arange(0,256)\n",
    "        PRE = np.zeros((val_num,len(mybins)-1))\n",
    "        REC = np.zeros((val_num,len(mybins)-1))\n",
    "        F1 = np.zeros((val_num,len(mybins)-1))\n",
    "        MAE = np.zeros((val_num))\n",
    "\n",
    "        val_cnt = 0.0\n",
    "        i_val = None\n",
    "\n",
    "        for i_val, data_val in enumerate(valid_dataloader):\n",
    "\n",
    "            # imidx_val, inputs_val, labels_val, shapes_val = data_val['imidx'], data_val['image'], data_val['label'], data_val['shape']\n",
    "            imidx_val, labels_val, shapes_val = data_val['imidx'], data_val['label'], data_val['shape']\n",
    "\n",
    "            if(hypar[\"model_digit\"]==\"full\"):\n",
    "                labels_val = labels_val.type(torch.FloatTensor)\n",
    "            else:\n",
    "                labels_val = labels_val.type(torch.HalfTensor)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            if torch.cuda.is_available():\n",
    "                labels_val_v = Variable(labels_val.cuda(), requires_grad=False)\n",
    "            else:\n",
    "                labels_val_v = Variable(labels_val,requires_grad=False)\n",
    "\n",
    "            t_start = time.time()\n",
    "            ds_val = net(labels_val_v)[0]\n",
    "            t_end = time.time()-t_start\n",
    "            tmp_time.append(t_end)\n",
    "\n",
    "            # loss2_val, loss_val = muti_loss_fusion(ds_val, labels_val_v)\n",
    "            loss2_val, loss_val = net.compute_loss(ds_val, labels_val_v)\n",
    "\n",
    "            # compute F measure\n",
    "            for t in range(hypar[\"batch_size_valid\"]):\n",
    "                val_cnt = val_cnt + 1.0\n",
    "                print(\"num of val: \", val_cnt)\n",
    "                i_test = imidx_val[t].data.numpy()\n",
    "\n",
    "                pred_val = ds_val[0][t,:,:,:] # B x 1 x H x W\n",
    "\n",
    "                ## recover the prediction spatial size to the orignal image size\n",
    "                pred_val = torch.squeeze(F.upsample(torch.unsqueeze(pred_val,0),(shapes_val[t][0],shapes_val[t][1]),mode='bilinear'))\n",
    "\n",
    "                ma = torch.max(pred_val)\n",
    "                mi = torch.min(pred_val)\n",
    "                pred_val = (pred_val-mi)/(ma-mi) # max = 1\n",
    "                # pred_val = normPRED(pred_val)\n",
    "\n",
    "                gt = np.squeeze(io.imread(valid_dataset.dataset[\"ori_gt_path\"][i_test])) # max = 255\n",
    "                with torch.no_grad():\n",
    "                    gt = torch.tensor(gt).to(device)\n",
    "\n",
    "                pre,rec,f1,mae = f1_mae_torch(pred_val*255, gt, valid_dataset, i_test, mybins, hypar)\n",
    "\n",
    "                PRE[i_test,:]=pre\n",
    "                REC[i_test,:] = rec\n",
    "                F1[i_test,:] = f1\n",
    "                MAE[i_test] = mae\n",
    "\n",
    "            del ds_val, gt\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # if(loss_val.data[0]>1):\n",
    "            val_loss += loss_val.item()#data[0]\n",
    "            tar_loss += loss2_val.item()#data[0]\n",
    "\n",
    "            print(\"[validating: %5d/%5d] val_ls:%f, tar_ls: %f, f1: %f, mae: %f, time: %f\"% (i_val, val_num, val_loss / (i_val + 1), tar_loss / (i_val + 1), np.amax(F1[i_test,:]), MAE[i_test],t_end))\n",
    "\n",
    "            del loss2_val, loss_val\n",
    "\n",
    "        print('============================')\n",
    "        PRE_m = np.mean(PRE,0)\n",
    "        REC_m = np.mean(REC,0)\n",
    "        f1_m = (1+0.3)*PRE_m*REC_m/(0.3*PRE_m+REC_m+1e-8)\n",
    "        # print('--------------:', np.mean(f1_m))\n",
    "        tmp_f1.append(np.amax(f1_m))\n",
    "        tmp_mae.append(np.mean(MAE))\n",
    "        print(\"The max F1 Score: %f\"%(np.max(f1_m)))\n",
    "        print(\"MAE: \", np.mean(MAE))\n",
    "\n",
    "    # print('[epoch: %3d/%3d, ite: %5d] tra_ls: %3f, val_ls: %3f, tar_ls: %3f, maxf1: %3f, val_time: %6f'% (epoch + 1, epoch_num, ite_num, running_loss / ite_num4val, val_loss/val_cnt, tar_loss/val_cnt, tmp_f1[-1], time.time()-start_valid))\n",
    "\n",
    "    return tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time\n",
    "\n",
    "def train(net, optimizer, train_dataloaders, train_datasets, valid_dataloaders, valid_datasets, hypar,train_dataloaders_val, train_datasets_val): #model_path, model_save_fre, max_ite=1000000):\n",
    "\n",
    "    if hypar[\"interm_sup\"]:\n",
    "        print(\"Get the gt encoder ...\")\n",
    "        featurenet = get_gt_encoder(train_dataloaders, train_datasets, valid_dataloaders, valid_datasets, hypar,train_dataloaders_val, train_datasets_val)\n",
    "        ## freeze the weights of gt encoder\n",
    "        for param in featurenet.parameters():\n",
    "            param.requires_grad=False\n",
    "\n",
    "\n",
    "    model_path = hypar[\"model_path\"]\n",
    "    model_save_fre = hypar[\"model_save_fre\"]\n",
    "    max_ite = hypar[\"max_ite\"]\n",
    "    batch_size_train = hypar[\"batch_size_train\"]\n",
    "    batch_size_valid = hypar[\"batch_size_valid\"]\n",
    "\n",
    "    if(not os.path.exists(model_path)):\n",
    "        os.mkdir(model_path)\n",
    "\n",
    "    ite_num = hypar[\"start_ite\"] # count the toal iteration number\n",
    "    ite_num4val = 0 #\n",
    "    running_loss = 0.0 # count the toal loss\n",
    "    running_tar_loss = 0.0 # count the target output loss\n",
    "    last_f1 = [0 for x in range(len(valid_dataloaders))]\n",
    "\n",
    "    train_num = train_datasets[0].__len__()\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    start_last = time.time()\n",
    "    gos_dataloader = train_dataloaders[0]\n",
    "    epoch_num = hypar[\"max_epoch_num\"]\n",
    "    notgood_cnt = 0\n",
    "    for epoch in range(epoch_num): ## set the epoch num as 100000\n",
    "\n",
    "        for i, data in enumerate(gos_dataloader):\n",
    "\n",
    "            if(ite_num >= max_ite):\n",
    "                print(\"Training Reached the Maximal Iteration Number \", max_ite)\n",
    "                exit()\n",
    "\n",
    "            # start_read = time.time()\n",
    "            ite_num = ite_num + 1\n",
    "            ite_num4val = ite_num4val + 1\n",
    "\n",
    "            # get the inputs\n",
    "            inputs, labels = data['image'], data['label']\n",
    "\n",
    "            if(hypar[\"model_digit\"]==\"full\"):\n",
    "                inputs = inputs.type(torch.FloatTensor)\n",
    "                labels = labels.type(torch.FloatTensor)\n",
    "            else:\n",
    "                inputs = inputs.type(torch.HalfTensor)\n",
    "                labels = labels.type(torch.HalfTensor)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            if torch.cuda.is_available():\n",
    "                inputs_v, labels_v = Variable(inputs.cuda(), requires_grad=False), Variable(labels.cuda(), requires_grad=False)\n",
    "            else:\n",
    "                inputs_v, labels_v = Variable(inputs, requires_grad=False), Variable(labels, requires_grad=False)\n",
    "\n",
    "            # print(\"time lapse for data preparation: \", time.time()-start_read, ' s')\n",
    "\n",
    "            # y zero the parameter gradients\n",
    "            start_inf_loss_back = time.time()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if hypar[\"interm_sup\"]:\n",
    "                # forward + backward + optimize\n",
    "                ds,dfs = net(inputs_v)\n",
    "                _,fs = featurenet(labels_v) ## extract the gt encodings\n",
    "                loss2, loss = net.compute_loss_kl(ds, labels_v, dfs, fs, mode='MSE')\n",
    "            else:\n",
    "                # forward + backward + optimize\n",
    "                ds,_ = net(inputs_v)\n",
    "                loss2, loss = net.compute_loss(ds, labels_v)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running_tar_loss += loss2.item()\n",
    "\n",
    "            # del outputs, loss\n",
    "            del ds, loss2, loss\n",
    "            end_inf_loss_back = time.time()-start_inf_loss_back\n",
    "\n",
    "            print(\">>>\"+model_path.split('/')[-1]+\" - [epoch: %3d/%3d, batch: %5d/%5d, ite: %d] train loss: %3f, tar: %3f, time-per-iter: %3f s, time_read: %3f\" % (\n",
    "            epoch + 1, epoch_num, (i + 1) * batch_size_train, train_num, ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val, time.time()-start_last, time.time()-start_last-end_inf_loss_back))\n",
    "            start_last = time.time()\n",
    "\n",
    "            if ite_num % model_save_fre == 0:  # validate every 2000 iterations\n",
    "                notgood_cnt += 1\n",
    "                net.eval()\n",
    "                tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time = valid(net, valid_dataloaders, valid_datasets, hypar, epoch)\n",
    "                net.train()  # resume train\n",
    "\n",
    "                tmp_out = 0\n",
    "                print(\"last_f1:\",last_f1)\n",
    "                print(\"tmp_f1:\",tmp_f1)\n",
    "                for fi in range(len(last_f1)):\n",
    "                    if(tmp_f1[fi]>last_f1[fi]):\n",
    "                        tmp_out = 1\n",
    "                print(\"tmp_out:\",tmp_out)\n",
    "                if(tmp_out):\n",
    "                    notgood_cnt = 0\n",
    "                    last_f1 = tmp_f1\n",
    "                    tmp_f1_str = [str(round(f1x,4)) for f1x in tmp_f1]\n",
    "                    tmp_mae_str = [str(round(mx,4)) for mx in tmp_mae]\n",
    "                    maxf1 = '_'.join(tmp_f1_str)\n",
    "                    meanM = '_'.join(tmp_mae_str)\n",
    "                    # .cpu().detach().numpy()\n",
    "                    model_name = \"/gpu_itr_\"+str(ite_num)+\\\n",
    "                                \"_traLoss_\"+str(np.round(running_loss / ite_num4val,4))+\\\n",
    "                                \"_traTarLoss_\"+str(np.round(running_tar_loss / ite_num4val,4))+\\\n",
    "                                \"_valLoss_\"+str(np.round(val_loss /(i_val+1),4))+\\\n",
    "                                \"_valTarLoss_\"+str(np.round(tar_loss /(i_val+1),4)) + \\\n",
    "                                \"_maxF1_\" + maxf1 + \\\n",
    "                                \"_mae_\" + meanM + \\\n",
    "                                \"_time_\" + str(np.round(np.mean(np.array(tmp_time))/batch_size_valid,6))+\".pth\"\n",
    "                    torch.save(net.state_dict(), model_path + model_name)\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_tar_loss = 0.0\n",
    "                ite_num4val = 0\n",
    "\n",
    "                if(notgood_cnt >= hypar[\"early_stop\"]):\n",
    "                    print(\"No improvements in the last \"+str(notgood_cnt)+\" validation periods, so training stopped !\")\n",
    "                    exit()\n",
    "\n",
    "    print(\"Training Reaches The Maximum Epoch Number\")\n",
    "\n",
    "def valid(net, valid_dataloaders, valid_datasets, hypar, epoch=0):\n",
    "    net.eval()\n",
    "    print(\"Validating...\")\n",
    "    epoch_num = hypar[\"max_epoch_num\"]\n",
    "\n",
    "    val_loss = 0.0\n",
    "    tar_loss = 0.0\n",
    "    val_cnt = 0.0\n",
    "\n",
    "    tmp_f1 = []\n",
    "    tmp_mae = []\n",
    "    tmp_time = []\n",
    "\n",
    "    start_valid = time.time()\n",
    "\n",
    "    for k in range(len(valid_dataloaders)):\n",
    "\n",
    "        valid_dataloader = valid_dataloaders[k]\n",
    "        valid_dataset = valid_datasets[k]\n",
    "\n",
    "        val_num = valid_dataset.__len__()\n",
    "        mybins = np.arange(0,256)\n",
    "        PRE = np.zeros((val_num,len(mybins)-1))\n",
    "        REC = np.zeros((val_num,len(mybins)-1))\n",
    "        F1 = np.zeros((val_num,len(mybins)-1))\n",
    "        MAE = np.zeros((val_num))\n",
    "\n",
    "        for i_val, data_val in enumerate(valid_dataloader):\n",
    "            val_cnt = val_cnt + 1.0\n",
    "            imidx_val, inputs_val, labels_val, shapes_val = data_val['imidx'], data_val['image'], data_val['label'], data_val['shape']\n",
    "\n",
    "            if(hypar[\"model_digit\"]==\"full\"):\n",
    "                inputs_val = inputs_val.type(torch.FloatTensor)\n",
    "                labels_val = labels_val.type(torch.FloatTensor)\n",
    "            else:\n",
    "                inputs_val = inputs_val.type(torch.HalfTensor)\n",
    "                labels_val = labels_val.type(torch.HalfTensor)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            if torch.cuda.is_available():\n",
    "                inputs_val_v, labels_val_v = Variable(inputs_val.cuda(), requires_grad=False), Variable(labels_val.cuda(), requires_grad=False)\n",
    "            else:\n",
    "                inputs_val_v, labels_val_v = Variable(inputs_val, requires_grad=False), Variable(labels_val,requires_grad=False)\n",
    "\n",
    "            t_start = time.time()\n",
    "            ds_val = net(inputs_val_v)[0]\n",
    "            t_end = time.time()-t_start\n",
    "            tmp_time.append(t_end)\n",
    "\n",
    "            # loss2_val, loss_val = muti_loss_fusion(ds_val, labels_val_v)\n",
    "            loss2_val, loss_val = net.compute_loss(ds_val, labels_val_v)\n",
    "\n",
    "            # compute F measure\n",
    "            for t in range(hypar[\"batch_size_valid\"]):\n",
    "                i_test = imidx_val[t].data.numpy()\n",
    "\n",
    "                pred_val = ds_val[0][t,:,:,:] # B x 1 x H x W\n",
    "\n",
    "                ## recover the prediction spatial size to the orignal image size\n",
    "                pred_val = torch.squeeze(F.upsample(torch.unsqueeze(pred_val,0),(shapes_val[t][0],shapes_val[t][1]),mode='bilinear'))\n",
    "\n",
    "                # pred_val = normPRED(pred_val)\n",
    "                ma = torch.max(pred_val)\n",
    "                mi = torch.min(pred_val)\n",
    "                pred_val = (pred_val-mi)/(ma-mi) # max = 1\n",
    "\n",
    "                if len(valid_dataset.dataset[\"ori_gt_path\"]) != 0:\n",
    "                    gt = np.squeeze(io.imread(valid_dataset.dataset[\"ori_gt_path\"][i_test])) # max = 255\n",
    "                else:\n",
    "                    gt = np.zeros((shapes_val[t][0],shapes_val[t][1]))\n",
    "                with torch.no_grad():\n",
    "                    gt = torch.tensor(gt).to(device)\n",
    "\n",
    "                pre,rec,f1,mae = f1_mae_torch(pred_val*255, gt, valid_dataset, i_test, mybins, hypar)\n",
    "\n",
    "\n",
    "                PRE[i_test,:]=pre\n",
    "                REC[i_test,:] = rec\n",
    "                F1[i_test,:] = f1\n",
    "                MAE[i_test] = mae\n",
    "\n",
    "                del ds_val, gt\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # if(loss_val.data[0]>1):\n",
    "            val_loss += loss_val.item()#data[0]\n",
    "            tar_loss += loss2_val.item()#data[0]\n",
    "\n",
    "            print(\"[validating: %5d/%5d] val_ls:%f, tar_ls: %f, f1: %f, mae: %f, time: %f\"% (i_val, val_num, val_loss / (i_val + 1), tar_loss / (i_val + 1), np.amax(F1[i_test,:]), MAE[i_test],t_end))\n",
    "\n",
    "            del loss2_val, loss_val\n",
    "\n",
    "        print('============================')\n",
    "        PRE_m = np.mean(PRE,0)\n",
    "        REC_m = np.mean(REC,0)\n",
    "        f1_m = (1+0.3)*PRE_m*REC_m/(0.3*PRE_m+REC_m+1e-8)\n",
    "\n",
    "        tmp_f1.append(np.amax(f1_m))\n",
    "        tmp_mae.append(np.mean(MAE))\n",
    "\n",
    "    return tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time\n",
    "\n",
    "def main(train_datasets,\n",
    "         valid_datasets,\n",
    "         hypar): # model: \"train\", \"test\"\n",
    "\n",
    "    ### --- Step 1: Build datasets and dataloaders ---\n",
    "    dataloaders_train = []\n",
    "    dataloaders_valid = []\n",
    "\n",
    "    if(hypar[\"mode\"]==\"train\"):\n",
    "        print(\"--- create training dataloader ---\")\n",
    "        ## collect training dataset\n",
    "        train_nm_im_gt_list = get_im_gt_name_dict(train_datasets, flag=\"train\")\n",
    "        ## build dataloader for training datasets\n",
    "        train_dataloaders, train_datasets = create_dataloaders(train_nm_im_gt_list,\n",
    "                                                             cache_size = hypar[\"cache_size\"],\n",
    "                                                             cache_boost = hypar[\"cache_boost_train\"],\n",
    "                                                             my_transforms = [\n",
    "                                                                             GOSRandomHFlip(), ## this line can be uncommented for horizontal flip augmetation\n",
    "                                                                             # GOSResize(hypar[\"input_size\"]),\n",
    "                                                                             # GOSRandomCrop(hypar[\"crop_size\"]), ## this line can be uncommented for randomcrop augmentation\n",
    "                                                                              GOSNormalize([0.5,0.5,0.5],[1.0,1.0,1.0]),\n",
    "                                                                              ],\n",
    "                                                             batch_size = hypar[\"batch_size_train\"],\n",
    "                                                             shuffle = True)\n",
    "        train_dataloaders_val, train_datasets_val = create_dataloaders(train_nm_im_gt_list,\n",
    "                                                             cache_size = hypar[\"cache_size\"],\n",
    "                                                             cache_boost = hypar[\"cache_boost_train\"],\n",
    "                                                             my_transforms = [\n",
    "                                                                              GOSNormalize([0.5,0.5,0.5],[1.0,1.0,1.0]),\n",
    "                                                                              ],\n",
    "                                                             batch_size = hypar[\"batch_size_valid\"],\n",
    "                                                             shuffle = False)\n",
    "        print(len(train_dataloaders), \" train dataloaders created\")\n",
    "\n",
    "    print(\"--- create valid dataloader ---\")\n",
    "    ## build dataloader for validation or testing\n",
    "    valid_nm_im_gt_list = get_im_gt_name_dict(valid_datasets, flag=\"valid\")\n",
    "    ## build dataloader for training datasets\n",
    "    valid_dataloaders, valid_datasets = create_dataloaders(valid_nm_im_gt_list,\n",
    "                                                          cache_size = hypar[\"cache_size\"],\n",
    "                                                          cache_boost = hypar[\"cache_boost_valid\"],\n",
    "                                                          my_transforms = [\n",
    "                                                                           GOSNormalize([0.5,0.5,0.5],[1.0,1.0,1.0]),\n",
    "                                                                           # GOSResize(hypar[\"input_size\"])\n",
    "                                                                           ],\n",
    "                                                          batch_size=hypar[\"batch_size_valid\"],\n",
    "                                                          shuffle=False)\n",
    "    print(len(valid_dataloaders), \" valid dataloaders created\")\n",
    "    # print(valid_datasets[0][\"data_name\"])\n",
    "\n",
    "    ### --- Step 2: Build Model and Optimizer ---\n",
    "    print(\"--- build model ---\")\n",
    "    net = hypar[\"model\"]#GOSNETINC(3,1)\n",
    "\n",
    "    # convert to half precision\n",
    "    if(hypar[\"model_digit\"]==\"half\"):\n",
    "        net.half()\n",
    "        for layer in net.modules():\n",
    "          if isinstance(layer, nn.BatchNorm2d):\n",
    "            layer.float()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "\n",
    "    if(hypar[\"restore_model\"]!=\"\"):\n",
    "        print(\"restore model from:\")\n",
    "        print(hypar[\"model_path\"]+\"/\"+hypar[\"restore_model\"])\n",
    "        if torch.cuda.is_available():\n",
    "            net.load_state_dict(torch.load(hypar[\"model_path\"]+\"/\"+hypar[\"restore_model\"]))\n",
    "        else:\n",
    "            net.load_state_dict(torch.load(hypar[\"model_path\"]+\"/\"+hypar[\"restore_model\"],map_location=\"cpu\"))\n",
    "\n",
    "    print(\"--- define optimizer ---\")\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "    ### --- Step 3: Train or Valid Model ---\n",
    "    if(hypar[\"mode\"]==\"train\"):\n",
    "        train(net,\n",
    "              optimizer,\n",
    "              train_dataloaders,\n",
    "              train_datasets,\n",
    "              valid_dataloaders,\n",
    "              valid_datasets,\n",
    "              hypar,\n",
    "              train_dataloaders_val, train_datasets_val)\n",
    "    else:\n",
    "        valid(net,\n",
    "              valid_dataloaders,\n",
    "              valid_datasets,\n",
    "              hypar)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ### --------------- STEP 1: Configuring the Train, Valid and Test datasets ---------------\n",
    "    ## configure the train, valid and inference datasets\n",
    "    train_datasets, valid_datasets = [], []\n",
    "    dataset_1, dataset_1 = {}, {}\n",
    "\n",
    "    dataset_tr = {\"name\": \"GS-AMP-TR-1\",\n",
    "                 \"im_dir\": \"/global/cfs/projectdirs/cosmo/work/users/usf_cs690_2022_fall/galaxy_simulated/ArcAlwaysPresent/train/images\",\n",
    "                 \"gt_dir\": \"/global/cfs/projectdirs/cosmo/work/users/usf_cs690_2022_fall/galaxy_simulated/ArcAlwaysPresent/train/arcs\",\n",
    "                 \"im_ext\": \".png\",\n",
    "                 \"gt_ext\": \".png\",\n",
    "                 \"cache_dir\":\"cache\"}\n",
    "\n",
    "    dataset_vd = {\"name\": \"GS-AMP-VD-1\",\n",
    "                 \"im_dir\": \"/global/cfs/projectdirs/cosmo/work/users/usf_cs690_2022_fall/galaxy_simulated/ArcAlwaysPresent/valid/images\",\n",
    "                 \"gt_dir\": \"/global/cfs/projectdirs/cosmo/work/users/usf_cs690_2022_fall/galaxy_simulated/ArcAlwaysPresent/valid/arcs\",\n",
    "                 \"im_ext\": \".png\",\n",
    "                 \"gt_ext\": \".png\",\n",
    "                 \"cache_dir\":\"cache\"}\n",
    "\n",
    "    train_datasets = [dataset_tr] ## users can create mutiple dictionary for setting a list of datasets as training set\n",
    "    # valid_datasets = [dataset_vd] ## users can create mutiple dictionary for setting a list of datasets as vaidation sets or inference sets\n",
    "    valid_datasets = [dataset_vd] # dataset_vd, dataset_te1, dataset_te2, dataset_te3, dataset_te4] # and hypar[\"mode\"] = \"valid\" for inference,\n",
    "\n",
    "    ### --------------- STEP 2: Configuring the hyperparamters for Training, validation and inferencing ---------------\n",
    "    hypar = {}\n",
    "\n",
    "    ## -- 2.1. configure the model saving or restoring path --\n",
    "    hypar[\"mode\"] = \"train\"\n",
    "    ## \"train\": for training,\n",
    "    ## \"valid\": for validation and inferening,\n",
    "    ## in \"valid\" mode, it will calculate the accuracy as well as save the prediciton results into the \"hypar[\"valid_out_dir\"]\", which shouldn't be \"\"\n",
    "    ## otherwise only accuracy will be calculated and no predictions will be saved\n",
    "    hypar[\"interm_sup\"] = False ## in-dicate if activate intermediate feature supervision\n",
    "\n",
    "    if hypar[\"mode\"] == \"train\":\n",
    "        hypar[\"valid_out_dir\"] = \"\" ## for \"train\" model leave it as \"\", for \"valid\"(\"inference\") mode: set it according to your local directory\n",
    "        hypar[\"model_path\"] =\"saved_models/IS-Net-test\" ## model weights saving (or restoring) path\n",
    "        hypar[\"restore_model\"] = \"\" ## name of the segmentation model weights .pth for resume training process from last stop or for the inferencing\n",
    "        hypar[\"start_ite\"] = 0 ## start iteration for the training, can be changed to match the restored training process\n",
    "        hypar[\"gt_encoder_model\"] = \"\"\n",
    "    else: ## configure the segmentation output path and the to-be-used model weights path\n",
    "        hypar[\"valid_out_dir\"] = \"valid_output/\"##\"../DIS5K-Results-test\" ## output inferenced segmentation maps into this fold\n",
    "        hypar[\"model_path\"] = \"saved_models/IS-Net\" ## load trained weights from this path\n",
    "        hypar[\"restore_model\"] = \"isnet.pth\"##\"isnet.pth\" ## name of the to-be-loaded weights\n",
    "\n",
    "    # if hypar[\"restore_model\"]!=\"\":\n",
    "    #     hypar[\"start_ite\"] = int(hypar[\"restore_model\"].split(\"_\")[2])\n",
    "\n",
    "    ## -- 2.2. choose floating point accuracy --\n",
    "    hypar[\"model_digit\"] = \"full\" ## indicates \"half\" or \"full\" accuracy of float number\n",
    "    hypar[\"seed\"] = 0\n",
    "\n",
    "    ## -- 2.3. cache data spatial size --\n",
    "    ## To handle large size input images, which take a lot of time for loading in training,\n",
    "    #  we introduce the cache mechanism for pre-convering and resizing the jpg and png images into .pt file\n",
    "    hypar[\"cache_size\"] = [125, 125] ## cached input spatial resolution, can be configured into different size\n",
    "    hypar[\"cache_boost_train\"] = False ## \"True\" or \"False\", indicates wheather to load all the training datasets into RAM, True will greatly speed the training process while requires more RAM\n",
    "    hypar[\"cache_boost_valid\"] = False ## \"True\" or \"False\", indicates wheather to load all the validation datasets into RAM, True will greatly speed the training process while requires more RAM\n",
    "\n",
    "    ## --- 2.4. data augmentation parameters ---\n",
    "    hypar[\"input_size\"] = [125, 125] ## mdoel input spatial size, usually use the same value hypar[\"cache_size\"], which means we don't further resize the images\n",
    "    hypar[\"crop_size\"] = [110, 110] ## random crop size from the input, it is usually set as smaller than hypar[\"cache_size\"], e.g., [920,920] for data augmentation\n",
    "    hypar[\"random_flip_h\"] = 1 ## horizontal flip, currently hard coded in the dataloader and it is not in use\n",
    "    hypar[\"random_flip_v\"] = 0 ## vertical flip , currently not in use\n",
    "\n",
    "    ## --- 2.5. define model  ---\n",
    "    print(\"building model...\")\n",
    "    hypar[\"model\"] = ISNetDIS() #U2NETFASTFEATURESUP()\n",
    "    hypar[\"early_stop\"] = 20 ## stop the training when no improvement in the past 20 validation periods, smaller numbers can be used here e.g., 5 or 10.\n",
    "    hypar[\"model_save_fre\"] = 2000 ## valid and save model weights every 2000 iterations\n",
    "\n",
    "    hypar[\"batch_size_train\"] = 8 ## batch size for training\n",
    "    hypar[\"batch_size_valid\"] = 1 ## batch size for validation and inferencing\n",
    "    print(\"batch size: \", hypar[\"batch_size_train\"])\n",
    "\n",
    "    hypar[\"max_ite\"] = 1000000 ## if early stop couldn't stop the training process, stop it by the max_ite_num\n",
    "    hypar[\"max_epoch_num\"] = 2000 ## if early stop and max_ite couldn't stop the training process, stop it by the max_epoch_num\n",
    "\n",
    "    main(train_datasets,\n",
    "         valid_datasets,\n",
    "         hypar=hypar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fe45f-602e-4e26-85c3-bd0349d17dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
